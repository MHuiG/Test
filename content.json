{"meta":{"title":"MHuiG","subtitle":"Be Yourself, Make a Difference.","description":"MHuiG","author":"MHuiG","url":"https://MHuiG.github.io","root":"/"},"pages":[{"title":"404 Not Found","date":"2020-08-25T14:45:24.300Z","updated":"2020-08-25T14:45:24.300Z","comments":true,"path":"404.html","permalink":"https://mhuig.github.io/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"关于","date":"2020-08-25T14:45:24.308Z","updated":"2020-08-25T14:45:24.308Z","comments":true,"path":"about/index.html","permalink":"https://mhuig.github.io/about/index.html","excerpt":"","text":"MHuiG 关于我>_ 热爱技术，热爱创造。 极简主义者。 喜欢遥望星星存在过的地方。 Talk With Me On Github Wikipedia在Alone的海洋里有一只孤独的鲸，没有放弃海洋的它终会在最后找到同频率的伙伴。 &mdash;52赫兹的鲸"},{"title":"所有分类","date":"2020-08-25T14:45:24.308Z","updated":"2020-08-25T14:45:24.308Z","comments":true,"path":"categories/index.html","permalink":"https://mhuig.github.io/categories/index.html","excerpt":"","text":""},{"title":"我的朋友们","date":"2020-08-25T14:45:24.308Z","updated":"2020-08-25T14:45:24.308Z","comments":true,"path":"friends/index.html","permalink":"https://mhuig.github.io/friends/index.html","excerpt":"","text":"欢迎互换友链！ 举个栗子辅助工具 name: MHuiG url: https://mhuig.github.io avatar: https://cdn.jsdelivr.net/gh/MHuiG/blog-cdn/assets/avatar/avatar.png tags: 搞事情🤣 desc: 「Be Yourself Make a Difference」 backgroundColor: #D7864C 压缩图片 HTTPS 图床 网络加速工具"},{"title":"所有标签","date":"2020-08-25T14:45:24.308Z","updated":"2020-08-25T14:45:24.308Z","comments":true,"path":"tags/index.html","permalink":"https://mhuig.github.io/tags/index.html","excerpt":"","text":""},{"title":"Time Machine","date":"2020-08-25T14:45:24.308Z","updated":"2020-08-25T14:45:24.308Z","comments":true,"path":"time-machine/index.html","permalink":"https://mhuig.github.io/time-machine/index.html","excerpt":"","text":""}],"posts":[{"title":"基于K均值聚类的网络流量异常检测(pyspark)","slug":"Spark/基于K均值聚类的网络流量异常检测","date":"2020-08-02T10:23:15.000Z","updated":"2020-08-02T10:23:15.000Z","comments":true,"path":"posts/7b55143e.html","link":"","permalink":"https://mhuig.github.io/posts/7b55143e.html","excerpt":"异常检测常用于检测欺诈、网络攻击、服务器及传感设备故障。在这些应用中，我们要能够找出以前从未见过的新型异常，如新欺诈方式、新入侵方法或新服务器故障模式。","text":"异常检测常用于检测欺诈、网络攻击、服务器及传感设备故障。在这些应用中，我们要能够找出以前从未见过的新型异常，如新欺诈方式、新入侵方法或新服务器故障模式。 数据集KDD Cup 1999 数据集 下载 KDD Cup 1999 数据集 数据集为 CSV 格式，每个连接占一行，包含 38 个特征。 单行示例： 10,tcp,http,SF,239,486,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,19,19,1.00,0.00,0.05,0.00,0.00,0.00,0.00,0.00,normal. 最后的字段表示类别标号。大多数标号为 normal.， 但也有一些样本代表各种网络攻击。 算法K均值聚类算法聚类算法是指将一堆没有标签的数据自动划分成几类的方法，这个方法要保证同一类的数据有相似的特征。 算法过程K-Means算法的特点是类别的个数是人为给定的。是一个迭代求解的聚类算法，属于划分型的聚类方法，即首先创建K个划分，然后迭代地将样本从一个划分转移到另一个划分来改善最终聚类的效果。其过程大致如下。 （1）根据给定的K值选取K个样本点作为初始划分中心。 （2）计算所有样本点到每一个划分中心的距离，并将所有样本点划分到距离最近的划分中心。 （3）计算每个划分中样本点的平均值，并将其作为新的中心。 （4）循环进行步骤（2）和步骤（3）直至最大迭代次数，或划分中心的变化小于某一预定义阈值。 伪代码1234567891011function K-Means(输入数据，中心点个数K) 获取输入数据的维度Dim和个数N 随机生成K个Dim维的点 while(算法未收敛) 对N个点：计算每个点属于哪一类。 对于K个中心点： 1，找出所有属于自己这一类的所有数据点 2，把自己的坐标修改为这些数据点的中心点坐标 end 输出结果end K-Means的一个重要的假设是：数据之间的相似度可以使用欧氏距离度量，如果不能使用欧氏距离度量，要先把数据转换到能用欧氏距离度量，这一点很重要。可以使用欧氏距离度量的意思就是欧氏距离越小，两个数据相似度越高。 假设簇划分为（,,…）,则优化目标是最小化平方误差SSE: 其中是簇的均值向量，也称为质心，表达式为： 这是一个NP难题，因此只能采用启发式迭代方法。 K-Means采用的启发式方式很简单，用下面一组图就可以形象的描述: 图a表达了初始的数据集，假设k=2。在图b中，随机选择了两个k类所对应的类别质心，即图中的红色质心和蓝色质心，然后分别求样本中所有点到这两个质心的距离，并标记每个样本的类别为和该样本距离最小的质心的类别，如图c所示，经过计算样本和红色质心和蓝色质心的距离，得到了所有样本点的第一轮迭代后的类别。此时对当前标记为红色和蓝色的点分别求其新的质心，如图d所示，新的红色质心和蓝色质心的位置已经发生了变动。图e和图f重复了在图c和图d的过程，即将所有点的类别标记为距离最近的质心的类别并求新的质心。最终得到的两个类别如图f。 K-means聚类最优k值的选取（手肘法）手肘法的核心指标是SSE(sum of the squared errors，误差平方和),公式见上文。 核心思想是：随着聚类数k的增大，样本划分会更加精细，每个簇的聚合程度会逐渐提高，那么误差平方和SSE自然会逐渐变小。并且，当k小于真实聚类数时，由于k的增大会大幅增加每个簇的聚合程度，故SSE的下降幅度会很大，而当k到达真实聚类数时，再增加k所得到的聚合程度回报会迅速变小，所以SSE的下降幅度会骤减，然后随着k值的继续增大而趋于平缓，也就是说SSE和k的关系图是一个手肘的形状，而这个肘部对应的k值就是数据的真实聚类数。 特征的规范化去除数据的单位限制，将其转化为无量纲的纯数值，便于不同单位或量级的指标能够进行计算和比较。 1、数据的中心化 所谓数据的中心化是指数据集中的各项数据减去数据集的均值。 2、数据的标准化 所谓数据的标准化是指中心化之后的数据在除以数据集的标准差，即数据集中的各项数据减去数据集的均值再除以数据集的标准差。 特征的规范化可以通过将每个特征转换为标准得分来完成。这就是说用对每个特征值求平均，用每个特征值减去平均值，然后除以特征值的标准差，如下标准分计算公式所示：μδ 类别型变量类别型特征可以用 one-hot 编码转换为几个二元特征，这几个二元特征可以看成数值型维度。 使用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候，其中只有一位有效。 解决了分类器不好处理属性数据的问题；在一定程度上也起到了扩充特征的作用。 聚类结果评价指标Entropy（熵）好的聚类应该和人工标签保持一致，大部分情况下，标签相同的数据点应聚在一起，而标签不同的数据点不应该在一起，并且簇内的数据点标签相同。熵值会变得很小。 对于一个聚类i，首先计算聚类 i 中的成员（member）属于类（class）j 的概率其中是在聚类 i 中所有成员的个数，是聚类 i 中的成员属于类 j 的个数。 每个聚类的entropy可以表示为其中L是类（class）的个数。 整个聚类划分的entropy为其中K是聚类（cluster）的数目，m是整个聚类划分所涉及到的成员个数。 Accuracy(准确率)比较每一条聚类结果是否和真的结果一致. 其中N表示文档总数，表示正确聚类的文档数. 实验过程准备数据，上传至HDFSHDFS创建文件夹 hadoop关闭安全模式 上传KDD Cup 1999 数据集 查看上传成功 通过kddcup.names加载列名称123456789names=[]with open(\"/export/work/F/3/data/kddcup.names\") as f: line = f.readline() line = f.readline() while line: names.append(line.split(\":\")[0]) line = f.readline()names.append(\"label\") 输出列名称： 1['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label'] 构建Dataframe1234567891011121314151617181920212223242526names=['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label']from pyspark.sql.types import Rowfrom pyspark.sql.types import StructTypefrom pyspark.sql.types import StructFieldfrom pyspark.sql.types import StringTypefrom pyspark.sql.types import FloatTypefrom pyspark.conf import SparkConffrom pyspark import SparkContextfrom pyspark.sql.session import SparkSession# 构建Dataframeconf = SparkConf().setAppName(\"applicaiton\").set(\"spark.executor.heartbeatInterval\",\"200000\").set(\"spark.network.timeout\",\"300000\")sc = SparkContext.getOrCreate(conf)spark = SparkSession(sc)testRDD = sc.textFile(\"/3/corrected\")fields = list(map( lambda fieldName : StructField(fieldName, StringType(), nullable = True) if fieldName in [\"protocol_type\", \"service\", \"flag\",\"label\"] else StructField(fieldName, FloatType(), nullable = True) , names))schema = StructType(fields)rowRDD = testRDD.map(lambda line : line.split(\",\")).map(lambda attr : Row(float(attr[0]),attr[1],attr[2],attr[3],float(attr[4]),float(attr[5]),float(attr[6]),float(attr[7]),float(attr[8]),float(attr[9]),float(attr[10]),float(attr[11]),float(attr[12]),float(attr[13]),float(attr[14]),float(attr[15]),float(attr[16]),float(attr[17]),float(attr[18]),float(attr[19]),float(attr[20]),float(attr[21]),float(attr[22]),float(attr[23]),float(attr[24]),float(attr[25]),float(attr[26]),float(attr[27]),float(attr[28]),float(attr[29]),float(attr[30]),float(attr[31]),float(attr[32]),float(attr[33]),float(attr[34]),float(attr[35]),float(attr[36]),float(attr[37]),float(attr[38]),float(attr[39]),float(attr[40]),attr[41]))testDF = spark.createDataFrame(rowRDD, schema)dataRDD = sc.textFile(\"/3/kddcup.data\")fields = list(map( lambda fieldName : StructField(fieldName, StringType(), nullable = True) if fieldName in [\"protocol_type\", \"service\", \"flag\",\"label\"] else StructField(fieldName, FloatType(), nullable = True) , names))schema = StructType(fields)rowRDD = dataRDD.map(lambda line : line.split(\",\")).map(lambda attr : Row(float(attr[0]),attr[1],attr[2],attr[3],float(attr[4]),float(attr[5]),float(attr[6]),float(attr[7]),float(attr[8]),float(attr[9]),float(attr[10]),float(attr[11]),float(attr[12]),float(attr[13]),float(attr[14]),float(attr[15]),float(attr[16]),float(attr[17]),float(attr[18]),float(attr[19]),float(attr[20]),float(attr[21]),float(attr[22]),float(attr[23]),float(attr[24]),float(attr[25]),float(attr[26]),float(attr[27]),float(attr[28]),float(attr[29]),float(attr[30]),float(attr[31]),float(attr[32]),float(attr[33]),float(attr[34]),float(attr[35]),float(attr[36]),float(attr[37]),float(attr[38]),float(attr[39]),float(attr[40]),attr[41]))dataDF = spark.createDataFrame(rowRDD, schema) 数据集统计统计数据集中各个类别标号以及每类样本有多少，并展示。 数据集的类别标号以及每类样本数 1234567891011121314151617181920212223242526272829dataDF.groupBy(\"label\").count().show(10000)+----------------+-------+ | label| count|+----------------+-------+| warezmaster.| 20|| smurf.|2807886|| pod.| 264|| imap.| 12|| nmap.| 2316|| guess_passwd.| 53|| ipsweep.| 12481|| portsweep.| 10413|| satan.| 15892|| land.| 21|| loadmodule.| 9|| ftp_write.| 8||buffer_overflow.| 30|| rootkit.| 10|| warezclient.| 1020|| teardrop.| 979|| perl.| 3|| phf.| 4|| multihop.| 7|| neptune.|1072017|| back.| 2203|| spy.| 2|| normal.| 972781|+----------------+-------+ 测试集的类别标号以及每类样本数 1234567891011121314151617181920212223242526272829303132333435363738394041424344testDF.groupBy(\"label\").count().show(10000) +----------------+------+| label| count|+----------------+------+| snmpguess.| 2406|| xlock.| 9|| warezmaster.| 1602|| processtable.| 759|| smurf.|164091|| pod.| 87|| worm.| 2|| snmpgetattack.| 7741|| mscan.| 1053|| nmap.| 84|| imap.| 1|| xterm.| 13|| sqlattack.| 2|| guess_passwd.| 4367|| mailbomb.| 5000|| xsnoop.| 4|| ipsweep.| 306|| portsweep.| 354|| named.| 17|| satan.| 1633|| land.| 9|| loadmodule.| 2|| ftp_write.| 3|| sendmail.| 17||buffer_overflow.| 22|| httptunnel.| 158|| apache2.| 794|| saint.| 736|| rootkit.| 13|| teardrop.| 12|| perl.| 2|| phf.| 2|| multihop.| 18|| udpstorm.| 2|| neptune.| 58001|| back.| 1098|| ps.| 16|| normal.| 60593|+----------------+------+ 尝试聚类12345from pyspark.ml import Pipeline,PipelineModelfrom pyspark.ml.clustering import KMeans,KMeansModelfrom pyspark.ml.feature import VectorAssemblerfrom pyspark.sql import DataFrameimport random 用 VectorAssembler 创建一个特征向量，基于这些特征向量用一个 K 均值实现来创建一个模型，再用一个管道将它们拼接在一起。从得到的模型中，可以提取并检验簇群中心。 1234567numericOnly = dataDF.drop(\"protocol_type\", \"service\", \"flag\").cache()assembler = VectorAssembler(inputCols=numericOnly.drop(\"label\").columns, outputCol=\"featureVector\")kmeans = KMeans().setPredictionCol(\"cluster\").setFeaturesCol(\"featureVector\")pipeline = Pipeline().setStages([assembler, kmeans])pipelineModel = pipeline.fit(numericOnly)kmeansModel = pipelineModel.stages[-1]for i in kmeansModel.clusterCenters():print(i) 输出： 1234567891011121314151617181920[4.83401949e+01 1.83462154e+03 8.26203195e+02 5.71611720e-06 6.48779303e-04 7.96173468e-06 1.24376586e-02 3.20510858e-05 1.43529049e-01 8.08830584e-03 6.81851124e-05 3.67464677e-05 1.29349608e-02 1.18874823e-03 7.43095237e-05 1.02114351e-03 0.00000000e+00 4.08294086e-07 8.35165553e-04 3.34973508e+02 2.95267146e+02 1.77970317e-01 1.78036989e-01 5.76648988e-02 5.77299094e-02 7.89884132e-01 2.11796105e-02 2.82608102e-02 2.32981078e+02 1.89214283e+02 7.53713390e-01 3.07109788e-02 6.05051931e-01 6.46410786e-03 1.78091184e-01 1.77885898e-01 5.79276115e-02 5.76592214e-02][1.09990000e+04 0.00000000e+00 1.30993741e+09 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00 2.55000000e+02 1.00000000e+00 0.00000000e+00 6.49999976e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00] 对这些数字做一个直观的解释并不容易，但是每一个数字都表示模型生成的一个簇群中心，也称为质心（centroid）。就每个数值输入特征而言，这些值是质心的坐标。 k的选择如果每个数据点都紧靠最近的质心，则可认为聚类是较优的。这里的“近”采用欧氏距离定义。这是评估聚类质量的一种简单又常用的方法，使用与所有点之间距离的平均值，有时也可以使用平方距离的平均值。实际上，KMeansModel 提供了一个computeCost 方法来计算平方距离的总和，并且很容易用来计算平方距离的平均值。 1234567891011121314numericOnly = dataDF.drop(\"protocol_type\", \"service\", \"flag\").cache()# computeCost 方法来计算平方距离的总和，并且很容易用来计算平方距离的平均值。def clusteringScore0(data,k): assembler = VectorAssembler(inputCols=data.drop(\"label\").columns, outputCol=\"featureVector\") kmeans = KMeans().setSeed(int(random.random()*10)).setK(k).setPredictionCol(\"cluster\").setFeaturesCol(\"featureVector\") #.setMaxIter(40).setTol(1.0e-5) pipeline = Pipeline().setStages([assembler, kmeans]) pipelineModel = pipeline.fit(data) kmeansModel = pipelineModel.stages[-1] Srore=kmeansModel.computeCost(assembler.transform(data)) / data.count() return Srorefor k in range(20, 100, 20): print([k, clusteringScore0(numericOnly, k)]) 输出结果： 1234[20, 148277112.23861197] [40, 49940659.143821806][60, 18265796.561388526][80, 15313289.324247833] 输出结果显示得分随着 k 的增加而降低。 增加迭代时间可以优化聚类结果。算法提供了 setTol() 来设置一个阈值，该阈值控制聚类过程中簇质心进行有效移动的最小值。降低该阈值能使质心继续移动更长的时间。使用setMaxIter() 增加最大迭代次数也可以防止它过早停止，代价是可能需要更多的计算。 123456789101112def clusteringScore1(data,k): assembler = VectorAssembler(inputCols=data.drop(\"label\").columns, outputCol=\"featureVector\") kmeans = KMeans().setSeed(int(random.random()*10)).setK(k).setPredictionCol(\"cluster\").setFeaturesCol(\"featureVector\").setMaxIter(40).setTol(1.0e-5) pipeline = Pipeline().setStages([assembler, kmeans]) pipelineModel = pipeline.fit(data) kmeansModel = pipelineModel.stages[-1] Srore=kmeansModel.computeCost(assembler.transform(data)) / data.count() return Srorefor k in range(20, 120, 20): print([k, clusteringScore1(numericOnly, k)]) 输出结果： 12345[20, 148277112.23861197] [40, 11564470.915401561][60, 16343181.409780543][80, 22323383.079484705][100, 7572838.84573523] 糟糕的情况是，前面的结果中 k=80 时的距离居然比 k=60 的距离大。这不应该发生，因为 k 取更大值时，聚类的结果应该至少与 k 取一个较小值时的结果一样好。问题的原因在于，这种给定 k 值的 K 均值算法并不一定能得到最优聚类。K 均值的迭代过程是从一个随机点开始的，因此可能收敛于一个局部最小值，这个局部最小值可能还不错，但并不是全局最优的。 在 k 过了 100 这个点之后得分下降还是很明显，所以 k 的拐点值应该大于 100。 特征的规范化特征的规范化可以通过将每个特征转换为标准得分来完成。这就是说用对每个特征值求平均，用每个特征值减去平均值，然后除以特征值的标准差。 由于减去平均值相当于把所有数据点沿相同方法移动相同距离，不影响点之间的欧氏距离，所以实际上减去平均值对聚类结果没有影响。 1234567891011121314from pyspark.ml.feature import StandardScalerdef clusteringScore2(data,k): assembler = VectorAssembler(inputCols=data.drop(\"label\").columns, outputCol=\"featureVector\") scaler = StandardScaler(inputCol=\"featureVector\", outputCol=\"scaledFeatureVector\", withStd=True, withMean=False) kmeans = KMeans().setSeed(int(random.random()*10)).setK(k).setPredictionCol(\"cluster\").setFeaturesCol(\"scaledFeatureVector\").setMaxIter(40).setTol(1.0e-5) pipeline = Pipeline().setStages([assembler,scaler,kmeans]) pipelineModel = pipeline.fit(data) kmeansModel = pipelineModel.stages[-1] Srore=kmeansModel.computeCost(pipelineModel.transform(data)) / data.count() return Srorefor k in range(60, 300, 30): print([k, clusteringScore2(numericOnly, k)]) 这有助于将维度放到更平等的基准上，而且在绝对的意义上，看点之间的绝对距离（也就是代价）要小得多。然而，k 值还没有出现一个明显的点，超过该点后，增加 k 值对于改善代价没有明显的作用： 12345678[60, 1.1611941370693641][90, 0.7236962692254361][120, 0.5581874996147724][150, 0.3886887438817504][180, 0.3333248112741165][210, 0.27497680552057235][240, 0.2556693718314817][270, 0.22710138015576076] 类别型变量归一化使聚类结果有了可贵的进步，但聚类结果还有进一步提升的空间。比如说，几个特征由于不是数值型就被去掉了，于是这些特征里有价值的信息也被丢掉了。如果将这些信息以某种形式加回来，我们应该能得到更好的聚类。 类别型特征可以用 one-hot 编码转换为几个二元特征，这几个二元特征可以看成数值型维度。举个例子，数据集的第二列代表协议类型，取值可能是 tcp、udp 或 icmp。可以把它们看成 3 个特征，分别取名为 is_tcp、is_udp 和 is_icmp。这样，特征值 tcp 就变成1,0,0，udp 对应 0,1,0，icmp 对应 0,0,1，以此类推。 123456789101112131415161718192021222324from pyspark.ml.feature import OneHotEncoder, StringIndexer# 类别型特征可以用 one-hot 编码转换为几个二元特征，这几个二元特征可以看成数值型维度。def oneHotPipeline(inputCol): indexer = StringIndexer(inputCol=inputCol,outputCol=inputCol + \"_indexed\").setHandleInvalid(\"keep\") encoder = OneHotEncoder(inputCol=inputCol + \"_indexed\",outputCol=inputCol + \"_vec\") pipeline = Pipeline().setStages([indexer, encoder]) return (pipeline, inputCol + \"_vec\")def clusteringScore3(data,k): protoTypeEncoder, protoTypeVecCol = oneHotPipeline(\"protocol_type\") serviceEncoder, serviceVecCol = oneHotPipeline(\"service\") flagEncoder, flagVecCol = oneHotPipeline(\"flag\") assembleCols = (set(data.columns)-set([\"label\", \"protocol_type\", \"service\", \"flag\"])).union(set([protoTypeVecCol, serviceVecCol, flagVecCol])) assembler = VectorAssembler(inputCols=list(assembleCols), outputCol=\"featureVector\") scaler = StandardScaler(inputCol=\"featureVector\", outputCol=\"scaledFeatureVector\", withStd=True, withMean=False) kmeans = KMeans().setSeed(int(random.random()*10)).setK(k).setPredictionCol(\"cluster\").setFeaturesCol(\"scaledFeatureVector\").setMaxIter(40).setTol(1.0e-5) pipeline = Pipeline().setStages([protoTypeEncoder, serviceEncoder, flagEncoder, assembler, scaler, kmeans]) pipelineModel = pipeline.fit(data) kmeansModel = pipelineModel.stages[-1] Srore=kmeansModel.computeCost(pipelineModel.transform(data)) / data.count() return Srorefor k in range(60, 300, 30): print([k, clusteringScore3(dataDF, k)]) 输出： 12345678[60, 38.01382297522162][90, 16.419330083446177][120, 3.2093992442174235][150, 2.1454678299121843][180, 1.6142523558430413][210, 1.3533093788147306][240, 1.0616778921723296][270, 0.9068134376554267] 局部放大： 这些样本结果表明，从 k=180 这个点开始，评分值的变化趋于平缓。至少现在聚类使用了所有的输入特征。 利用标号的熵信息标签告诉我们每个数据点的真实性质。好的聚类应该和人工标签保持一致，大部分情况 下，标签相同的数据点应聚在一起，而标签不同的数据点不应该在一起，并且簇内的数据 点标签相同。 良好的聚类结果簇中样本类别大体相同，因而熵值较低。我们可以对各个簇的熵加权平均，将结果作为聚类得分： 12345678910111213141516171819202122232425262728293031323334353637383940414243import numpydef entropy(x): ent = 0.0 x_value_list = [x[i] for i in range(x.shape[0])] n=sum(x_value_list) for x_value in x_value_list: p = float(x_value) / n ent -= p * numpy.log(p) return entdef fitPipeline4(data, k): protoTypeEncoder, protoTypeVecCol = oneHotPipeline(\"protocol_type\") serviceEncoder, serviceVecCol = oneHotPipeline(\"service\") flagEncoder, flagVecCol = oneHotPipeline(\"flag\") assembleCols = (set(data.columns)-set([\"label\", \"protocol_type\", \"service\", \"flag\"])).union(set([protoTypeVecCol, serviceVecCol, flagVecCol])) assembler = VectorAssembler(inputCols=list(assembleCols), outputCol=\"featureVector\") scaler = StandardScaler(inputCol=\"featureVector\", outputCol=\"scaledFeatureVector\", withStd=True, withMean=False) kmeans = KMeans().setSeed(int(random.random()*10)).setK(k).setPredictionCol(\"cluster\").setFeaturesCol(\"scaledFeatureVector\").setMaxIter(40).setTol(1.0e-5) pipeline = Pipeline().setStages([protoTypeEncoder, serviceEncoder, flagEncoder, assembler, scaler, kmeans]) pipelineModel = pipeline.fit(data) return pipelineModel# 良好的聚类结果簇中样本类别大体相同，因而熵值较低。对各个簇的熵加权平均，将结果作为聚类得分def clusteringScore4(data, k): pipelineModel = fitPipeline4(data, k) clusterLabel = pipelineModel.transform(data).select(\"cluster\", \"label\") pd=clusterLabel.toPandas() Sum=0 for name, group in pd.groupby(\"cluster\"): labelsize=group.count()[0] a=numpy.array(group.groupby('label').count()) b=[] for i in range(len(a)): for j in range(len(a[i])): b.append(a[i][j]) One=labelsize*entropy(numpy.array(b)) Sum=Sum+One return Sum/data.count()for k in range(60, 300, 30): print([k, clusteringScore4(dataDF, k)]) 输出结果： 12345678[60, 0.038993775215004474][90, 0.02985377476611417][120, 0.02266161774992263][150, 0.020766076760220943][180, 0.017547365257679748][210, 0.012974819022593053][240, 0.007150061376894767][270, 0.00833981903044443] 跟以前一样，可以根据上面的分析结果大致看出 k 的合适取值。随着 k 的增加，熵不一定会减小，因此我们找到的可能是一个局部最小值。这里结果同样表明，k 取 240 可能比较合理，因为它的得分实际上低于 210 以及 270。 聚类实战取 k=180 123pipelineModel = fitPipeline4(dataDF, 180)countByClusterLabel = pipelineModel.transform(dataDF).select(\"cluster\", \"label\").groupBy(\"cluster\", \"label\").count().orderBy(\"cluster\", \"label\")countByClusterLabel.show() 这里我们同样把每个簇的标号打印出来。聚类的结果中大部分属于同一簇，以及其他的少部分簇。 12345678910111213141516171819202122232425+-------+----------+-------+ |cluster| label| count|+-------+----------+-------+| 0| neptune.| 362876|| 0|portsweep.| 1|| 1| ipsweep.| 40|| 1| nmap.| 6|| 1| normal.| 3421|| 1|portsweep.| 2|| 1| satan.| 11|| 1| smurf.|2807886|| 2| neptune.| 1038|| 2|portsweep.| 13|| 2| satan.| 3|| 3| ipsweep.| 13|| 3| neptune.| 1046|| 3| normal.| 38|| 3|portsweep.| 11|| 3| satan.| 3|| 4| neptune.| 1034|| 4| normal.| 4|| 4|portsweep.| 7|| 4| satan.| 4|+-------+----------+-------+only showing top 20 rows 现在可以建立一个真正的异常检测系统了。异常检测时需要度量新数据点到最近的簇质心 的距离。如果这个距离超过某个阈值，那么就表示这个新数据点是异常的。我们可以把阈 值设为已知数据中离中心最远的第 100 个点到中心的距离。 1234567891011import os, tempfilefrom pyspark.ml.linalg import Vector, VectorspipelineModel = fitPipeline4(dataDF, 180)kmeansModel = pipelineModel.stages[-1]kmeansModel.save(\"/model/3/kmeansModel\")pipelineModel.save(\"/model/3/pipelineModel\")centroids = kmeansModel.clusterCenters()clustered = pipelineModel.transform(dataDF)threshold=clustered.select(\"cluster\", \"scaledFeatureVector\").rdd.map(lambda a:Vectors.squared_distance(centroids[a.cluster], a.scaledFeatureVector)).sortBy(lambda x: x).take(100)[-1]print(threshold) 输出阈值： 13.232811853048799e-05 最后一步就是在新数据点出现的时候使用阈值进行评估。在unlabled数据上进行测试找出异常流量记录，并计算正确率。 123456789clustered = pipelineModel.transform(testDF)anomalies = clustered.rdd.filter(lambda a:Vectors.squared_distance(centroids[a.cluster], a.scaledFeatureVector) &gt;= threshold).collect()n=len(anomalies)v=0for i in anomalies: if i[\"label\"]!='normal.': v=v+1print(\"正确率:\"+str(float(v)/n)) 输出结果： 1正确率:0.8051841158484633 取 k=240 12345678910import os, tempfilefrom pyspark.ml.linalg import Vector, VectorspipelineModel = fitPipeline4(dataDF, 240)kmeansModel = pipelineModel.stages[-1]kmeansModel.save(\"/model/3/test/kmeansModel\")pipelineModel.save(\"/model/3/test/pipelineModel\")centroids = kmeansModel.clusterCenters()clustered = pipelineModel.transform(dataDF)threshold=clustered.select(\"cluster\", \"scaledFeatureVector\").rdd.map(lambda a:Vectors.squared_distance(centroids[a.cluster], a.scaledFeatureVector)).sortBy(lambda x: x).take(100)[-1]print(threshold) 17.665805787851659e-06 123456789clustered = pipelineModel.transform(testDF)anomalies = clustered.rdd.filter(lambda a:Vectors.squared_distance(centroids[a.cluster], a.scaledFeatureVector) &gt;= threshold).collect()n=len(anomalies)v=0for i in anomalies: if i[\"label\"]!='normal.': v=v+1print(\"正确率:\"+str(float(v)/n)) 1正确率:0.8050769488123118 可以看出K=180是在unlabled数据上进行测试找出异常流量记录，计算正确率比K=240有较好的结果。 缩短计算的步长： 12for k in range(150, 220, 10): print([k, clusteringScore3(dataDF, k)]) 得到评分结果： 1234567[150, 2.292921780026778][160, 4.917845778754763][170, 2.0016455721528015][180, 1.7177635513092788][190, 1.5766159846344556][200, 1.5550587983858675][210, 1.2785418817225693] 局部放大： 取 k=190 12345678910import os, tempfilefrom pyspark.ml.linalg import Vector, VectorspipelineModel = fitPipeline4(dataDF, 190)kmeansModel = pipelineModel.stages[-1]kmeansModel.save(\"/model/3/190/kmeansModel\")pipelineModel.save(\"/model/3/190/pipelineModel\")centroids = kmeansModel.clusterCenters()clustered = pipelineModel.transform(dataDF)threshold=clustered.select(\"cluster\", \"scaledFeatureVector\").rdd.map(lambda a:Vectors.squared_distance(centroids[a.cluster], a.scaledFeatureVector)).sortBy(lambda x: x).take(100)[-1]print(threshold) 13.247829147436459e-05 123456789clustered = pipelineModel.transform(testDF)anomalies = clustered.rdd.filter(lambda a:Vectors.squared_distance(centroids[a.cluster], a.scaledFeatureVector) &gt;= threshold).collect()n=len(anomalies)v=0for i in anomalies: if i[\"label\"]!='normal.': v=v+1print(\"正确率:\"+str(float(v)/n)) 1正确率:0.8051841158484633 可以看出K=190是在unlabled数据上进行测试找出异常流量记录，计算正确率比K=180有较好的结果。","categories":[{"name":"spark","slug":"spark","permalink":"https://mhuig.github.io/categories/spark/"}],"tags":[{"name":"spark","slug":"spark","permalink":"https://mhuig.github.io/tags/spark/"}]},{"title":"基于Audioscrobbler数据集的音乐推荐(pyspark)","slug":"Spark/基于Audioscrobbler数据集的音乐推荐","date":"2020-08-02T07:34:13.000Z","updated":"2020-08-02T07:34:13.000Z","comments":true,"path":"posts/1e621a56.html","link":"","permalink":"https://mhuig.github.io/posts/1e621a56.html","excerpt":"根据用户播放次数数据使用协同过滤算法完成音乐推荐。","text":"根据用户播放次数数据使用协同过滤算法完成音乐推荐。 数据集Audioscrobbler数据集 下载 Audioscrobbler 数据集 user_artist_data.txt它包含141000个用户和160万个艺术家，记录了约2420万条用户播放艺术家歌曲的信息，其中包括播放次数信息。播放次数较多意味着该用户更喜欢对应艺术家的作品。 userid artistid playcount 用户ID 艺术家ID 播放次数 1000002 1 55 artist_data.txt该文件包含两列： artistid artist_name 艺术家ID 艺术家名字。文件中给出了每个艺术家的 ID 和对应的名字。此文件用于ID与名字的转换。 artistid artist_name 艺术家ID 艺术家名 1134999 06Crazy Life artist_alias.txt该文件包含两列: badid, goodid 坏ID 好ID 。该文件包含已知错误拼写的艺术家ID及其对应艺术家的正规的，用于将拼写错误的艺术家 ID 或ID 变体对应到该艺术家正确的ID。 badid goodid 坏ID 好ID 1092764 1000311 算法交替最小二乘推荐算法 (Alternating Least Squares，ALS)人们虽然经常听音乐，但很少给音乐评分。因此 Audioscrobbler 数据集覆盖了更多的用户和艺术家，也包含了更多的总体信息，虽然单条记录的信息比较少。这种类型的数据通常被称为隐式反馈数据，因为用户和艺术家的关系是通过其他行动隐含体现出来的，而不是通过显式的评分或点赞得到的。 根据两个用户的相似行为判断他们有相同的偏好，学习算法不需要用户和艺术家的属性信息。这类算法通常称为协同过滤算法。 潜在因素模型：试图通过数据相对少的未被观察到的底层原因，来解释大量用户和产品之间可观察到的交互。因子分析方法背后的理论是，有关观测变量之间的相互依赖性的信息可以稍后用于减少数据集中的变量集。 矩阵分解模型：数学上，算法把用户和产品数据当成一个大矩阵 R，矩阵第 i 行和第 j 列上的元素有值，代表用户 i 播放过艺术家 j 的音乐。矩阵 R 是稀疏的：R中大多数元素都是 0，因为相对于所有可能的用户 - 艺术家组合，只有很少一部分组合会出现在数据中。算法将 R 分解为两个小矩阵 U 和P的乘积。矩阵 U 和矩阵P非常“瘦”。因为 A 有很多行和列，但 U 和 P 的行很多而列很少（列数用 k 表示）。这 k 个列就是潜在因素，用于解释数据中的交互关系。由于 k 的值小，矩阵分解算法只能是某种近似。 为了使低秩矩阵P和U尽可能的逼近R，可以通过最小化如下损失函数L来完成。 λ 损失函数公式与上图对应：表示用户i的偏好隐含向量，表示艺术家j包含的隐含特征向量，表示用户i对艺术家j的评分，是用户i对艺术家j评分的近似。其中λ是正则化项的系数，损失函数一般需要加入正则化项来避免过拟合等问题。 于是就简化为一个最小化损失函数L的优化问题。用户-特征矩阵和特征-艺术家矩阵的乘积的结果是对整个稠密的用户-艺术家相互关系矩阵的完整估计。该乘积可以理解成艺术家与其属性之间的一个映射，然后按用户属性进行加权。 通常没有确切的解，因为U和P通常不够大，不足以完全表示R， 应该尽可能逼近R。然而不幸的是，想直接同时得到 U 和 P 的最优解是不可能的。 如果 P 已知，求U的最优解是非常容易的，反之亦然。但 P 和 U事先都是未知的。 虽然 P 是未知的，但可以把P初始化为随机行向量矩阵。接着运用简单的线性代数，就能在给定 R 和 P 的条件下求出 U 的最优解。实际上，U 的第 i 行是 R 的第 i 行和 P 的函数。因此可以很容易分开计算 U 的每一行。因为 U 的每一行可以分开计算，所以我们可以将其并行化，而并行化是大规模计算的一大优点。 ALS是求解的著名算法，固定P或U对其对应的隐含向量求偏导数并令导数为0，得到求解公式：λ λ 随机对P、Q初始化，随后交替进行优化直到收敛。收敛标准是均方误差小于预定义阈值，或者到达最大迭代次数。 推荐质量评价指标AUCAUC指标是一个[0,1]之间的实数，代表如果随机挑选一个正样本和一个负样本，分类算法将这个正样本排在负样本前面的概率。值越大，表示分类算法更有可能将正样本排在前面，也即算法准确性越好。 随机抽出一对样本（一个正样本，一个负样本），然后用训练得到的分类器来对这两个样本进行预测，预测得到正样本的概率大于负样本概率的概率。正样本负样本在有M个正样本,N个负样本的数据集里。一共有M×N对样本（一对样本，一个正样本与一个负样本）。统计这M×N对样本里，正样本的预测概率大于负样本的预测概率的个数。正样本负样本其中， 实验过程数据预处理artist_data.txt文件 数据最终处理成以逗号分割 artist_data.txt文件 两列之间的间隔有的是空格有的是Tab，第二列数据中包含空格 因第二列数据中含有逗号和空格，数据最终处理成以Tab分割 去除第一列不是数字的行 artist_alias.txt 文件 将拼写错误的艺术家 ID 或 ID 变体对应到该艺术家的规范 ID 两列之间的间隔有的是空格有的是Tab 包含数据缺失的列 在数据处理时对拼写错误ID进行映射，用别名数据集将所有的艺术家 ID 转换成正规 ID。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748aa={}with open(\"/export/work/F/1/data/artist_alias.txt\") as f: line = f.readline() while line: if len(line.split())==2: aa[line.split()[0]]=line.split()[1] line = f.readline()f3=open(\"/export/work/F/1/data/user_artist_data.txt.data\",\"w+\")with open(\"/export/work/F/1/data/user_artist_data.txt\") as f2: line = f2.readline() while line: it=line.split() if it[1] in aa: it[1]=aa[it[1]] print(it[0]+\",\"+it[1]+\",\"+it[2],file=f3) line = f2.readline()f3.close()f5=open(\"/export/work/F/1/data/artist_data.txt.data\",\"w+\")with open(\"/export/work/F/1/data/artist_data.txt\") as f4: line = f4.readline() while line: it=line.split() s=\"\" for i in range(len(it)): s+=it[i] if i==0: s+=\" \" elif i==len(it)-1: s+=\"\" else: s+=\" \" print(s,file=f5) line = f4.readline()f7=open(\"/export/work/F/1/data/artist_data.txt.data2\",\"w+\")with open(\"/export/work/F/1/data/artist_data.txt.data\") as f6: line = f6.readline() while line: it=line.split(\" \") try: a=int(it[0]) print(str(a)+\" \"+it[1],file=f7,end=\"\") except: pass line = f6.readline() 预处理后得到的数据集 artist_data user_artist_data 获取数据文件，并上传至HDFS 读入数据，转换成DataFrame备用1234567891011121314151617181920212223242526from pyspark.sql.types import Rowfrom pyspark.sql.types import StructTypefrom pyspark.sql.types import StructFieldfrom pyspark.sql.types import StringType,IntegerTypefrom pyspark.conf import SparkConffrom pyspark import SparkContextfrom pyspark.sql.session import SparkSession# 转换成DataFramename1=[\"user\", \"item\", \"rating\"]name2=[\"id\",\"name\"]conf = SparkConf().setAppName(\"applicaiton\").set(\"spark.executor.heartbeatInterval\",\"500000\").set(\"spark.network.timeout\",\"500000\")sc = SparkContext.getOrCreate(conf)spark = SparkSession(sc)uaRDD = sc.textFile(\"/1/user_artist_data.txt.data\")fields = list(map( lambda fieldName : StructField(fieldName, IntegerType(), nullable = True), name1))schema = StructType(fields)rowRDD = uaRDD.map(lambda line : line.split(\",\")).map(lambda attr : Row(int(attr[0]),int(attr[1]),int(attr[2])))uaDF = spark.createDataFrame(rowRDD, schema)aRDD = sc.textFile(\"/1/artist_data.txt.data2\")fields = list(map( lambda fieldName : StructField(fieldName, IntegerType(), nullable = True) if fieldName==\"id\" else StructField(fieldName, StringType(), nullable = True) , name2))schema = StructType(fields)rowRDD =aRDD.map(lambda line : line.split(\" \")).map(lambda attr : Row(int(attr[0]),attr[1]))aDF = spark.createDataFrame(rowRDD, schema) 展示数据格式基本统计信息数据格式 123456789101112131415161718192021222324252627uaDF.show()+-------+-------+------+| user| item|rating|+-------+-------+------+|1000002| 1| 55||1000002|1000006| 33||1000002|1000007| 8||1000002|1000009| 144||1000002|1000010| 314||1000002|1000013| 8||1000002|1000014| 42||1000002|1000017| 69||1000002|1000024| 329||1000002|1000025| 1||1000002|1000028| 17||1000002|1000031| 47||1000002|1000033| 15||1000002|1000042| 1||1000002|1000045| 1||1000002|1000054| 2||1000002|1000055| 25||1000002|1000056| 4||1000002|1000059| 2||1000002|1000062| 71|+-------+-------+------+only showing top 20 rows 基本统计信息用户数 1234a=uaDF.select(uaDF.user).distinct().count()print(a)148111 艺术家数目 1234b=uaDF.select(uaDF.item).distinct().count()print(b)1568126 每用户平均播放次数 123456789101112131415161718192021222324252627uaDF.drop(\"item\").groupBy(\"user\").agg({\"rating\":\"mean\"}).show()+-------+------------------+| user| avg(rating)|+-------+------------------+|1000190|55.355432780847146||1001043|6.0131578947368425||1001129| 12.32748538011696||1001139| 8.652557319223986||1002431|12.833333333333334||1002605|3.5392670157068062||1004666| 9.79409594095941||1005158|1.9245283018867925||1005439|28.333333333333332||1005697|11.733333333333333||1005853| 2.5||1007007| 2.443396226415094||1007847|14.333333333333334||1008081|31.232876712328768||1008233| 90.0||1008804| 9.0||1009408| 4.666666666666667||1012261|3.2887640449438202||1015587| 9.46||1016416| 8.241935483870968|+-------+------------------+only showing top 20 rows 每艺术家平均播放次数 123456789101112131415161718192021222324252627uaDF.drop(\"user\").groupBy(\"item\").agg({\"rating\":\"mean\"}).show()+-------+------------------+| item| avg(rating)|+-------+------------------+|1001129|10.578309692671395||1003373|2.3333333333333335||1007972|18.156831042845596||1029443| 20.54196642685851||1076507| 2.969264544456641||1318111|5.6902654867256635|| 833| 9.483282674772036||1239413| 3.821794871794872||1000636| 2.0||1002431|1.7142857142857142||1005697| 3.5||1040360| 1.0||1043263|1.9166666666666667||1245208|19.613390928725703|| 463| 34.3479262672811||1043126|14.580645161290322||1001601| 3.573529411764706||1091589| 2.5||1004021| 6.96403785488959||1012885| 4.744927536231884|+-------+------------------+only showing top 20 rows 构建ALS模型构建ALS模型，并记录所耗时间。初始参数：Rank 10, maxiter 15, RegParm 0.01 Alpha 1.0。 123456789from pyspark.ml.recommendation import ALS,ALSModelimport randomimport timestart = time.time()als = ALS(rank=10,maxIter=15,regParam=0.01,alpha=1.0,seed=int(random.random()*100))model=als.fit(uaDF)end = time.time()print (\"时间:\"+str(end-start)) 输出结果： 1时间:785.1817960739136 这样我们就构建了一个ALSModel 模型。 模型用两个不同的DataFrame，它们分别表示“用户 - 特征”和“产品 - 特征”这两个大型矩阵。 检查推荐结果依据构建的模型，选择部分ID检查推荐结果。 看看模型给出的艺术家推荐直观上是否合理，检查一下用户播放过的艺术家，然后看看模型向用户推荐的艺术家。具体来看看用户 2093760 的例子。 12userID = 2093760a=uaDF.rdd.filter(lambda x:x[0]==userID).collect() 查看用户输出结果： 1234567[Row(user=2093760, item=1180, rating=1), Row(user=2093760, item=1255340, rating=3), Row(user=2093760, item=378, rating=1), Row(user=2093760, item=813, rating=2), Row(user=2093760, item=942, rating=7)] 获取艺术家ID： 123artistid=[]for i in a: artistid.append(i.item) 输出结果： 1[1180, 1255340, 378, 813, 942] 要提取该用户收听过的艺术家 ID 并打印他们的名字，这意味着先在输入数据中搜索该用户收听过的艺术家的 ID，然后用这些 ID 对艺术家集合进行过滤，这样我们就可以获取并按序打印这些艺术家的名字： 1b=aDF.rdd.filter(**lambda** x: x[0] **in** artistid).collect() 输出结果： 123456789[Row(id=1180, name='David Gray'), Row(id=378, name='Blackalicious'), Row(id=813, name='Jurassic 5'), Row(id=1255340, name='The Saw Doctors'), Row(id=942, name='Xzibit')] 用户播放过的艺术家既有大众流行音乐风格的也有嘻哈风格的。 使用Spark2.4.6自带的recommendForUserSubset方法，对所有艺术家评分，并返回向用户2093760推荐其中分值最高的前5位。 12345d=sc.parallelize([(2093760,1)]).toDF(['user']) t=model.recommendForUserSubset(d,5) t.show() 输出结果： 12345+-------+--------------------+ | user| recommendations|+-------+--------------------+|2093760|[[6674945, 4997.0...|+-------+--------------------+ 遍历打印一下： 1t.select(\"recommendations\").rdd.foreach(**lambda** x:**print**(x)) 输出： 1234567Row(recommendations=[ Row(item=6674945, rating=4997.056640625), Row(item=1170225, rating=1805.596435546875), Row(item=1153293, rating=1753.0908203125), Row(item=6730413, rating=1233.61767578125), Row(item=183, rating=1169.90234375)]) 结果全部是嘻哈风格。能看出，这些推荐都不怎么样。虽然推荐的艺术家都受人欢迎，但好像并没有针对用户的收听习惯进行个性化。 训练-验证切分训练-验证切分，采用初始参数，重新训练模型。 为了利用输入数据，需要把它分成训练集和验证集。训练集只用于训练 ALS 模型，验证集用于评估模型。这里将 90% 的数据用于训练，剩余的 10% 用于交叉验证： 12345train,test=uaDF.randomSplit([0.9,0.1])als = ALS(rank=10,maxIter=15,regParam=0.01,alpha=1.0,seed=int(random.random()*100),implicitPrefs=True)model=als.fit(train)train.cache()test.cache() 计算AUC接受一个交叉验证集和一个预测函数，交叉验证集代表每个用户对应的“正面的”或“好的”艺术家。预测函数把每个包含“用户 - 艺术家”对的 DataFrame 转换为一个同时包含“用户 - 艺术家”和“预测”的 DataFrame，“预测”表示“用户”与“艺术家”之间关联的强度值，这个值越高，代表推荐的排名越高。 1234567891011121314151617181920212223242526272829303132333435363738394041424344allArtistIDs = uaDF.select(\"item\").distinct().collect()import numpyallArtistID = []for i in range(len(allArtistIDs)): allArtistID.append(allArtistIDs[i][\"item\"])def f(a,b): posItemIDSet = set(list(b)) negative = [] i = 0 while (i &lt; len(allArtistID)) and (len(negative) &lt; len(posItemIDSet)): artistID = allArtistID[numpy.random.randint(1, high=len(allArtistID), size=None, dtype='l')] if artistID not in posItemIDSet: negative.append(artistID) i += 1 s=list() for i in negative: s.append((a,i)) return s# 计算AUCimport pyspark.sql.functions as funcdef areaUnderCurve(positiveData,allArtistIDs,predictFunction): positivePredictions = predictFunction(positiveData.select(\"user\", \"item\")).withColumnRenamed(\"prediction\", \"positivePrediction\") negativeDatatmp = positiveData.select(\"user\", \"item\").rdd.groupByKey().map(lambda x: f(x[0],x[1])).collect() negativeDatalist=[] for i in negativeDatatmp: for j in i: negativeDatalist.append(j) negativeData=spark.createDataFrame(negativeDatalist,['user','item']) negativePredictions = predictFunction(negativeData.select(\"user\", \"item\")).withColumnRenamed(\"prediction\", \"negativePrediction\") joinedPredictions = positivePredictions.join(negativePredictions, \"user\").select(\"user\", \"positivePrediction\", \"negativePrediction\") allCounts = joinedPredictions.groupBy(\"user\").agg(func.count(func.lit(1)).alias(\"total\")).select(\"user\", \"total\") correctCounts = joinedPredictions.filter(joinedPredictions[\"positivePrediction\"] &gt; joinedPredictions[\"negativePrediction\"]).groupBy(\"user\").agg(func.count(\"user\").alias(\"correct\")).select(\"user\", \"correct\") meanAUCtemp = allCounts.join(correctCounts, \"user\", \"left_outer\") meanAUC = meanAUCtemp.select(\"user\", (meanAUCtemp[\"correct\"] / meanAUCtemp[\"total\"]).alias(\"auc\")).agg(func.mean(\"auc\")).first() try: joinedPredictions.unpersist() except: pass return meanAUC mostListenedAUC = areaUnderCurve(test, allArtistIDs, model.transform)print(mostListenedAUC) 输出结果： 1Row(avg(auc)=0.9098560946043145) 有必要把上述方法和一个更简单方法做一个基准比对。举个例子，考虑下面的推荐方法：向每个用户推荐播放最多的艺术家。这个策略一点儿都不个性化，但它很简单，也可能有效。定义这个简单预测函数并评估它的 AUC 得分： 1234567def predictMostListened(data): listenCounts = train.groupBy(\"item\").agg({\"rating\":\"sum\"}).withColumnRenamed(\"sum(rating)\", \"prediction\").select(\"item\", \"prediction\") uaDF.join(listenCounts, [\"item\"], \"left_outer\").select(\"user\", \"item\", \"prediction\") listenCounts = uaDF.groupBy(\"item\").agg({\"rating\":\"sum\"}).withColumnRenamed(\"sum(rating)\", \"prediction\").select(\"item\", \"prediction\") return data.join(listenCounts, [\"item\"], \"left_outer\").select(\"user\", \"item\", \"prediction\")mostListenedAUC = areaUnderCurve(test, allArtistIDs, predictMostListened)print(mostListenedAUC) 输出结果： 1Row(avg(auc)=0.9578054887285846) 结果得分大约是 0.96。这意味着，对 AUC 这个指标，非个性化的推荐表现已经不错了。然而，我们想要的是得分更高，也就是更为“个性化”的推荐。显然这个模型还有待改进。调整超参数，使推荐结果更合理。 选择超参数Rank可选（5,30）RegParam可选（4.0,0.0001）,alpha可选（1.0,40.0）。合计8种参数组合。 可以把 rank、regParam 和 alpha 看作模型的超参数。（maxIter 更像是对分解过程使用的资源的一种约束。）这些值不会体现在 ALSModel 的内部矩阵中，这些矩阵只是参数，其值由算法选定。超参数则是构建过程本身的参数。 123456789def TrainALS(rank,regParam,alpha,dir): als = ALS(rank=rank,maxIter=15,regParam=regParam,alpha=alpha,seed=int(random.random()*100),implicitPrefs=True) model=als.fit(train) model.save(\"/model/ALS/Try2/\"+str(dir)) try: model.userFactors.unpersist() model.itemFactors.unpersist() except: pass 构建模型 123456dir=0for rank in [5,30]: for regParam in [4.0,0.0001]: for alpha in [1.0,40.0]: dir=dir+1 TrainALS(rank,regParam,alpha,dir) 加载模型计算AUC 得分： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748try: model=ALSModel.load(\"/model/ALS/Try2/1\") mostListenedAUC = areaUnderCurve(test, allArtistIDs, model.transform) print((mostListenedAUC,(5,4.0,1.0)))except: print((\"ERROR\",(5,4.0,1.0)))try: model=ALSModel.load(\"/model/ALS/Try2/2\") mostListenedAUC = areaUnderCurve(test, allArtistIDs, model.transform) print((mostListenedAUC,(5,4.0,40.0)))except: print((\"ERROR\",(5,4.0,40.0)))try: model=ALSModel.load(\"/model/ALS/Try2/3\") mostListenedAUC = areaUnderCurve(test, allArtistIDs, model.transform) print((mostListenedAUC,(5,0.0001,1.0)))except: print((\"ERROR\",(5,0.0001,1.0)))try: model=ALSModel.load(\"/model/ALS/Try2/4\") mostListenedAUC = areaUnderCurve(test, allArtistIDs, model.transform) print((mostListenedAUC,(5,0.0001,40.0)))except: print((\"ERROR\",(5,0.0001,40.0)))try: model=ALSModel.load(\"/model/ALS/Try2/5\") mostListenedAUC = areaUnderCurve(test, allArtistIDs, model.transform) print((mostListenedAUC,(30,4.0,1.0)))except: print((\"ERROR\",(30,4.0,1.0)))try: model=ALSModel.load(\"/model/ALS/Try2/6\") mostListenedAUC = areaUnderCurve(test, allArtistIDs, model.transform) print((mostListenedAUC,(30,4.0,40.0)))except: print((\"ERROR\",(30,4.0,40.0)))try: model=ALSModel.load(\"/model/ALS/Try2/7\") mostListenedAUC = areaUnderCurve(test, allArtistIDs, model.transform) print((mostListenedAUC,(30,0.0001,1.0)))except: print((\"ERROR\",(30,0.0001,1.0)))try: model=ALSModel.load(\"/model/ALS/Try2/8\") mostListenedAUC = areaUnderCurve(test, allArtistIDs, model.transform) print((mostListenedAUC,(30,0.0001,40.0)))except: print((\"ERROR\",(30,0.0001,40.0))) 输出结果： 12345678(Row(avg(auc)=0.9122637924972641), (5, 4.0, 1.0))(Row(avg(auc)=0.9154223563144587), (5, 4.0, 40.0))(Row(avg(auc)=0.9057761909633262), (5, 0.0001, 1.0))(Row(avg(auc)=0.9146676967584815), (5, 0.0001, 40.0))(Row(avg(auc)=0.9230010545570864), (30, 4.0, 1.0))(Row(avg(auc)=0.9275148741094371), (30, 4.0, 40.0))(Row(avg(auc)=0.9125799456221803), (30, 0.0001, 1.0))(Row(avg(auc)=0.9265221600644649), (30, 0.0001, 40.0)) 可以看出rank=30，regParam=4.0，alpha=40.0时取得了最优的结果avg(auc)=0.9275148741094371. 虽然这些值的绝对差很小，但对于 AUC 值来说，仍然具有一定的意义。有意思的是，参数 alpha 取 40 的时候看起来总是比取 1 表现好。这说明了模型在强调用户听过什么时的表现要比强调用户没听过什么时要好。 产生推荐选取10个用户展示推荐结果 1234model=ALSModel.load(\"/model/ALS/Try2/6\")d=sc.parallelize([(2093760,1),(1000002,1),(1006277,1),(1006282,1),(1006283,1),(1006285,1),(1041207,1),(1071489,1),(2025005,1),(2025007,1),]).toDF(['user'])t=model.recommendForUserSubset(d,5)t.select(\"recommendations\").rdd.foreach(lambda x:print(x)) 输出推荐结果： 12345678910Row(recommendations=[Row(item=1010991, rating=1.1815389394760132), Row(item=1245226, rating=1.139704942703247), Row(item=4629, rating=1.1092422008514404), Row(item=1113701, rating=1.1066040992736816), Row(item=1019715, rating=1.10056471824646)])Row(recommendations=[Row(item=1010921, rating=1.225757122039795), Row(item=1166169, rating=1.1972994804382324), Row(item=1183949, rating=1.184556007385254), Row(item=1082446, rating=1.178223729133606), Row(item=3892, rating=1.1580229997634888)])Row(recommendations=[Row(item=1028958, rating=1.146733283996582), Row(item=1086774, rating=1.1434733867645264), Row(item=1037761, rating=1.1272671222686768), Row(item=1184419, rating=1.1093372106552124), Row(item=1148170, rating=1.1065270900726318)])Row(recommendations=[Row(item=1010295, rating=1.2554553747177124), Row(item=3722, rating=1.2187168598175049), Row(item=1024674, rating=1.2044183015823364), Row(item=1009445, rating=1.099776268005371), Row(item=1018746, rating=1.0894378423690796)])Row(recommendations=[Row(item=1002068, rating=0.9575374126434326), Row(item=1005288, rating=0.9533681273460388), Row(item=2430, rating=0.9476644992828369), Row(item=1002270, rating=0.9428261518478394), Row(item=3909, rating=0.9334102869033813)])Row(recommendations=[Row(item=1034635, rating=0.606441080570221), Row(item=1000107, rating=0.6010327935218811), Row(item=1000024, rating=0.59807950258255), Row(item=4154, rating=0.5966558456420898), Row(item=1000157, rating=0.5944067239761353)])Row(recommendations=[Row(item=1034635, rating=0.290438175201416), Row(item=930, rating=0.2857869565486908), Row(item=4267, rating=0.2853849530220032), Row(item=1205, rating=0.2830250561237335), Row(item=1000113, rating=0.2829856276512146)])Row(recommendations=[Row(item=1002909, rating=1.2324668169021606), Row(item=1653, rating=1.1938585042953491), Row(item=988, rating=1.1880080699920654), Row(item=1003367, rating=1.1807997226715088), Row(item=1009545, rating=1.1761128902435303)])Row(recommendations=[Row(item=1017017, rating=0.8724791407585144), Row(item=1032349, rating=0.8424116373062134), Row(item=1028433, rating=0.8259942531585693), Row(item=1240603, rating=0.8185747265815735), Row(item=1029602, rating=0.8147093653678894)])Row(recommendations=[Row(item=1013187, rating=1.2516499757766724), Row(item=1098360, rating=1.2394661903381348), Row(item=1289948, rating=1.2353206872940063), Row(item=1129243, rating=1.2332189083099365), Row(item=1245184, rating=1.1997216939926147)]) 按照用户顺序将最喜欢的推荐结果输出到文件 123456def getp(x): f=open(\"/export/work/result\",\"a+\") print(x,file=f)u=uaDF.select(\"user\").distinct()t=model.recommendForUserSubset(u,1)t.rdd.foreach(lambda x:getp(x)) 输出详见result文件，以下为部分输出： 12345Row(user=1000092, recommendations=[Row(item=1002400, rating=1.2386927604675293)]) Row(user=1000144, recommendations=[Row(item=5221, rating=1.1728830337524414)]) Row(user=3175, recommendations=[Row(item=1022207, rating=0.282743901014328)]) Row(user=1000164, recommendations=[Row(item=1034635, rating=0.36578264832496643)]) Row(user=7340, recommendations=[Row(item=1007903, rating=0.8722475171089172)])","categories":[{"name":"spark","slug":"spark","permalink":"https://mhuig.github.io/categories/spark/"}],"tags":[{"name":"spark","slug":"spark","permalink":"https://mhuig.github.io/tags/spark/"}]},{"title":"Spark RDD编程","slug":"yuquebank/Spark RDD编程","date":"2020-05-20T07:45:29.000Z","updated":"2020-05-20T07:45:29.000Z","comments":true,"path":"posts/32971e43.html","link":"","permalink":"https://mhuig.github.io/posts/32971e43.html","excerpt":"Spark RDD 编程","text":"Spark RDD 编程 RDD 编程基础RDD 创建从文件系统中加载数据创建 RDDSpark 采用 textFile()方法来从文件系统中加载数据创建 RDD该方法把文件的 URI 作为参数，这个 URI 可以是 本地文件系统的地址 分布式文件系统 HDFS 的地址 AmazonS3 的地址 等等 从本地文件系统中加载数据创建 RDD123456&gt;&gt;&gt; lines = sc.textFile(&quot;file:///usr/local/spark/mycode/rdd/word.txt&quot;)&gt;&gt;&gt; lines.foreach(print)Hadoop is goodSpark is fastSpark is better 从分布式文件系统 HDFS 中加载数据123&gt;&gt;&gt; lines = sc.textFile(&quot;hdfs://localhost:9000/user/hadoop/word.txt&quot;)&gt;&gt;&gt; lines = sc.textFile(&quot;/user/hadoop/word.txt&quot;)&gt;&gt;&gt; lines = sc.textFile(&quot;word.txt&quot;) 通过并行集合（列表）创建 RDD可以调用 SparkContext 的 parallelize 方法，在 Driver 中一个已经存在的集合（列表）上创建。 12345678&gt;&gt;&gt; array = [1,2,3,4,5]&gt;&gt;&gt; rdd = sc.parallelize(array)&gt;&gt;&gt; rdd.foreach(print)12345 RDD 操作转换操作对于 RDD 而言，每一次转换操作都会产生不同的 RDD，供给下一个“转换”使用.转换得到的 RDD 是惰性求值的，也就是说，整个转换过程只是记录了转换的轨迹，并不会发生真正的计算，只有遇到行动操作时，才会发生真正的计算，开始从血缘关系源头开始，进行物理的转换操作. 操作 含义 filter(func) 筛选出满足函数 func 的元素，并返回一个新的数据集 map(func) 将每个元素传递到函数 func 中，并将结果返回为一个新的数据集 flatMap(func) 与 map()相似，但每个输入元素都可以映射到 0 或多个输出结果 groupByKey() 应用于(K,V)键值对的数据集时，返回一个新的(K,Iterable)形式的数据集 reduceByKey(func) 应用于(K,V)键值对的数据集时，返回一个新的(K,V)形式的数据集，其中每个值是将每个 key 传递到函数 func 中进行聚合后的结果 filter(func)筛选出满足函数 func 的元素，并返回一个新的数据集 12345&gt;&gt;&gt; lines = sc.textFile(&quot;file:///usr/local/spark/mycode/rdd/word.txt&quot;)&gt;&gt;&gt; linesWithSpark = lines.filter(lambda line: &quot;Spark&quot; in line)&gt;&gt;&gt; linesWithSpark.foreach(print)Spark is betterSpark is fast map(func)map(func)操作将每个元素传递到函数 func 中，并将结果返回为一个新的数据集 123456789&gt;&gt;&gt; data = [1,2,3,4,5]&gt;&gt;&gt; rdd1 = sc.parallelize(data)&gt;&gt;&gt; rdd2 = rdd1.map(lambda x:x+10)&gt;&gt;&gt; rdd2.foreach(print)1113121415 flatMap(func)12&gt;&gt;&gt; lines = sc.textFile(&quot;file:///usr/local/spark/mycode/rdd/word.txt&quot;)&gt;&gt;&gt; words = lines.flatMap(lambda line:line.split(&quot; &quot;)) groupByKey()应用于(K,V)键值对的数据集时，返回一个新的(K, Iterable)形式的数据集 12345678910&gt;&gt;&gt; words = sc.parallelize([(&quot;Hadoop&quot;,1),(&quot;is&quot;,1),(&quot;good&quot;,1), \\... (&quot;Spark&quot;,1),(&quot;is&quot;,1),(&quot;fast&quot;,1),(&quot;Spark&quot;,1),(&quot;is&quot;,1),(&quot;better&quot;,1)])&gt;&gt;&gt; words1 = words.groupByKey()&gt;&gt;&gt; words1.foreach(print)(&#x27;Hadoop&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fb210552c88&gt;)(&#x27;better&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fb210552e80&gt;)(&#x27;fast&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fb210552c88&gt;)(&#x27;good&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fb210552c88&gt;)(&#x27;Spark&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fb210552f98&gt;)(&#x27;is&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fb210552e10&gt;) reduceByKey(func)应用于(K,V)键值对的数据集时，返回一个新的(K, V)形式的数据集，其中的每个值是将每个 key 传递到函数 func 中进行聚合后得到的结果 12345678910&gt;&gt;&gt; words = sc.parallelize([(&quot;Hadoop&quot;,1),(&quot;is&quot;,1),(&quot;good&quot;,1),(&quot;Spark&quot;,1), \\... (&quot;is&quot;,1),(&quot;fast&quot;,1),(&quot;Spark&quot;,1),(&quot;is&quot;,1),(&quot;better&quot;,1)])&gt;&gt;&gt; words1 = words.reduceByKey(lambda a,b:a+b)&gt;&gt;&gt; words1.foreach(print) (&#x27;good&#x27;, 1)(&#x27;Hadoop&#x27;, 1)(&#x27;better&#x27;, 1)(&#x27;Spark&#x27;, 2)(&#x27;fast&#x27;, 1)(&#x27;is&#x27;, 3) 行动操作行动操作是真正触发计算的地方。Spark 程序执行到行动操作时，才会执行真正的计算，从文件中加载数据，完成一次又一次转换操作，最终，完成行动操作得到结果。 操作 含义 count() 返回数据集中的元素个数 collect() 以数组的形式返回数据集中的所有元素 first() 返回数据集中的第一个元素 take(n) 以数组的形式返回数据集中的前 n 个元素 reduce(func) 通过函数 func（输入两个参数并返回一个值）聚合数据集中的元素 foreach(func) 将数据集中的每个元素传递到函数 func 中运行 惰性机制所谓的“惰性机制”是指，整个转换过程只是记录了转换的轨迹，并不会发生真正的计算，只有遇到行动操作时，才会触发“从头到尾”的真正的计算这里给出一段简单的语句来解释 Spark 的惰性机制 1234&gt;&gt;&gt; lines = sc.textFile(&quot;file:///usr/local/spark/mycode/rdd/word.txt&quot;)&gt;&gt;&gt; lineLengths = lines.map(lambda s:len(s))&gt;&gt;&gt; totalLength = lineLengths.reduce(lambda a,b:a+b)&gt;&gt;&gt; print(totalLength) 持久化在 Spark 中，RDD 采用惰性求值的机制，每次遇到行动操作，都会从头开始执行计算。每次调用行动操作，都会触发一次从头开始的计算。这对于迭代计算而言，代价是很大的，迭代计算经常需要多次重复使用同一组数据 123456&gt;&gt;&gt; list = [&quot;Hadoop&quot;,&quot;Spark&quot;,&quot;Hive&quot;]&gt;&gt;&gt; rdd = sc.parallelize(list)&gt;&gt;&gt; print(rdd.count()) //行动操作，触发一次真正从头到尾的计算3&gt;&gt;&gt; print(&#x27;,&#x27;.join(rdd.collect())) //行动操作，触发一次真正从头到尾的计算Hadoop,Spark,Hive 可以通过持久化（缓存）机制避免这种重复计算的开销 可以使用 persist()方法对一个 RDD 标记为持久化 之所以说“标记为持久化”，是因为出现 persist()语句的地方，并不会马上计算生成 RDD 并把它持久化，而是要等到遇到第一个行动操作触发真正计算以后，才会把计算结果进行持久化 持久化后的 RDD 将会被保留在计算节点的内存中被后面的行动操作重复使用 1234567&gt;&gt;&gt; list = [&quot;Hadoop&quot;,&quot;Spark&quot;,&quot;Hive&quot;]&gt;&gt;&gt; rdd = sc.parallelize(list)&gt;&gt;&gt; rdd.cache() #会调用persist(MEMORY_ONLY)，但是，语句执行到这里，并不会缓存rdd，因为这时rdd还没有被计算生成&gt;&gt;&gt; print(rdd.count()) #第一次行动操作，触发一次真正从头到尾的计算，这时上面的rdd.cache()才会被执行，把这个rdd放到缓存中3&gt;&gt;&gt; print(&#x27;,&#x27;.join(rdd.collect())) #第二次行动操作，不需要触发从头到尾的计算，只需要重复使用上面缓存中的rddHadoop,Spark,Hive 分区RDD 是弹性分布式数据集，通常 RDD 很大，会被分成很多个分区，分别保存在不同的节点上RDD 分区的一个原则是使得分区的个数尽量等于集群中的 CPU 核心（core）数目 键值对 RDD键值对 RDD 的创建从文件中加载可以采用多种方式创建键值对 RDD，其中一种主要方式是使用 map()函数来实现 1234567&gt;&gt;&gt; lines = sc.textFile(&quot;file:///usr/local/spark/mycode/pairrdd/word.txt&quot;)&gt;&gt;&gt; pairRDD = lines.flatMap(lambda line:line.split(&quot; &quot;)).map(lambda word:(word,1))&gt;&gt;&gt; pairRDD.foreach(print)(&#x27;I&#x27;, 1)(&#x27;love&#x27;, 1)(&#x27;Hadoop&#x27;, 1)…… 通过并行集合（列表）创建 RDD12345678&gt;&gt;&gt; list = [&quot;Hadoop&quot;,&quot;Spark&quot;,&quot;Hive&quot;,&quot;Spark&quot;]&gt;&gt;&gt; rdd = sc.parallelize(list)&gt;&gt;&gt; pairRDD = rdd.map(lambda word:(word,1))&gt;&gt;&gt; pairRDD.foreach(print)(Hadoop,1)(Spark,1)(Hive,1)(Spark,1) 常用的键值对 RDD 转换操作reduceByKey(func)使用 func 函数合并具有相同键的值 12345&gt;&gt;&gt; pairRDD = sc.parallelize([(&quot;Hadoop&quot;,1),(&quot;Spark&quot;,1),(&quot;Hive&quot;,1),(&quot;Spark&quot;,1)])&gt;&gt;&gt; pairRDD.reduceByKey(lambda a,b:a+b).foreach(print)(&#x27;Spark&#x27;, 2)(&#x27;Hive&#x27;, 1)(&#x27;Hadoop&#x27;, 1) groupByKey()对具有相同键的值进行分组 1234567&gt;&gt;&gt; list = [(&quot;spark&quot;,1),(&quot;spark&quot;,2),(&quot;hadoop&quot;,3),(&quot;hadoop&quot;,5)]&gt;&gt;&gt; pairRDD = sc.parallelize(list)&gt;&gt;&gt; pairRDD.groupByKey()PythonRDD[27] at RDD at PythonRDD.scala:48&gt;&gt;&gt; pairRDD.groupByKey().foreach(print)(&#x27;hadoop&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f2c1093ecf8&gt;)(&#x27;spark&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f2c1093ecf8&gt;) sortByKey()返回一个根据键排序的 RDD 123456789101112&gt;&gt;&gt; list = [(&quot;Hadoop&quot;,1),(&quot;Spark&quot;,1),(&quot;Hive&quot;,1),(&quot;Spark&quot;,1)]&gt;&gt;&gt; pairRDD = sc.parallelize(list)&gt;&gt;&gt; pairRDD.foreach(print)(&#x27;Hadoop&#x27;, 1)(&#x27;Spark&#x27;, 1)(&#x27;Hive&#x27;, 1)(&#x27;Spark&#x27;, 1)&gt;&gt;&gt; pairRDD.sortByKey().foreach(print)(&#x27;Hadoop&#x27;, 1)(&#x27;Hive&#x27;, 1)(&#x27;Spark&#x27;, 1)(&#x27;Spark&#x27;, 1) mapValues(func)对键值对 RDD 中的每个 value 都应用一个函数，但是，key 不会发生变化 12345678&gt;&gt;&gt; list = [(&quot;Hadoop&quot;,1),(&quot;Spark&quot;,1),(&quot;Hive&quot;,1),(&quot;Spark&quot;,1)]&gt;&gt;&gt; pairRDD = sc.parallelize(list)&gt;&gt;&gt; pairRDD1 = pairRDD.mapValues(lambda x:x+1)&gt;&gt;&gt; pairRDD1.foreach(print)(&#x27;Hadoop&#x27;, 2)(&#x27;Spark&#x27;, 2)(&#x27;Hive&#x27;, 2)(&#x27;Spark&#x27;, 2) joinjoin 就表示内连接。对于内连接，对于给定的两个输入数据集(K,V1)和(K,V2)，只有在两个数据集中都存在的 key 才会被输出，最终得到一个(K,(V1,V2))类型的数据集。 1234567&gt;&gt;&gt; pairRDD1 = sc. \\... parallelize([(&quot;spark&quot;,1),(&quot;spark&quot;,2),(&quot;hadoop&quot;,3),(&quot;hadoop&quot;,5)])&gt;&gt;&gt; pairRDD2 = sc.parallelize([(&quot;spark&quot;,&quot;fast&quot;)])&gt;&gt;&gt; pairRDD3 = pairRDD1.join(pairRDD2)&gt;&gt;&gt; pairRDD3.foreach(print)(&#x27;spark&#x27;, (1, &#x27;fast&#x27;))(&#x27;spark&#x27;, (2, &#x27;fast&#x27;))","categories":[{"name":"spark","slug":"spark","permalink":"https://mhuig.github.io/categories/spark/"}],"tags":[{"name":"spark","slug":"spark","permalink":"https://mhuig.github.io/tags/spark/"}]},{"title":"Spark环境部署（Ubuntu20.04）","slug":"yuquebank/Spark环境部署（Ubuntu20.04）","date":"2020-05-07T11:06:38.000Z","updated":"2020-05-07T11:06:38.000Z","comments":true,"path":"posts/e846a0cc.html","link":"","permalink":"https://mhuig.github.io/posts/e846a0cc.html","excerpt":"Spark 在 Ubuntu20.04 中的配置","text":"Spark 在 Ubuntu20.04 中的配置 实验环境 实验环境 Ubuntu20.04 LTSHadoop 2.6.0-cdh5.14.0Java 1.8.0_141Python3.8.2(default)Spark 3.0.0-preview2 配置 java 环境解压安装 jdk 1tar -zxvf jdk-8u141-linux-x64.tar.gz -C ../servers/ 配置环境变量 123nano /etc/profileexport JAVA_HOME=/export/servers/jdk1.8.0_141export PATH=:$JAVA_HOME/bin:$PATH 修改完成之后记得 reboot -h now 或 source/etc/profile 生效 验证 1jps 配置 Hadoop 环境下载解压Hadoop 2 可以通过 https://mirrors.cnnic.cn/apache/hadoop/common/ 下载 将 Hadoop 安装至 /usr/local/ 中： 1234sudo tar -zxf hadoop-2.6.0.tar.gz -C /usr/local # 解压到/usr/local中cd /usr/local/sudo mv ./hadoop-2.6.0/ ./hadoop # 将文件夹名改为hadoopsudo chown -R hadoop ./hadoop # 修改文件权限 Hadoop 伪分布式配置伪分布式需要修改 2 个配置文件 core-site.xml 和 hdfs-site.xml core-site.xml1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置 JAVA_HOME到 hadoop 的安装目录修改配置文件“/usr/local/hadoop/etc/hadoop/hadoop-env.sh”，在里面找到“export JAVA_HOME=${JAVA_HOME}”这行，然后，把它修改成 JAVA 安装路径的具体地址 NameNode 格式化12cd /usr/local/hadoop./bin/hdfs namenode -format 开启 NameNode 和 DataNode 守护进程12cd /usr/local/hadoop./sbin/start-dfs.sh 安装 Spark打开浏览器，访问Spark 官方下载地址由于我们已经自己安装了 Hadoop，所以，在“Choose a package type”后面需要选择“Pre-build with user-provided Hadoop将 spark 解压到/usr/local,并重命名为 spark修改 Spark 的配置文件 spark-env.sh 12cd /usr/local/sparkcp ./conf/spark-env.sh.template ./conf/spark-env.sh 编辑 spark-env.sh 文件，在第一行添加以下配置信息: 1export SPARK_DIST_CLASSPATH&#x3D;$(&#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;bin&#x2F;hadoop classpath) 修改环境变量 12345export HADOOP_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoopexport SPARK_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;sparkexport PYTHONPATH&#x3D;$SPARK_HOME&#x2F;python:$SPARK_HOME&#x2F;python&#x2F;lib&#x2F;py4j-0.10.4-src.zip:$PYTHONPATHexport PYSPARK_PYTHON&#x3D;python3export PATH&#x3D;$HADOOP_HOME&#x2F;bin:$SPARK_HOME&#x2F;bin:$PATH 运行 Spark 自带的示例，验证 Spark 是否安装成功 使用 Spark 计算 PI（3.1415926….） 12cd /usr/local/sparkbin/run-example SparkPi grep 命令进行过滤 1bin/run-example SparkPi 2&gt;&amp;1 | grep &quot;Pi is&quot;","categories":[{"name":"Spark","slug":"spark","permalink":"https://mhuig.github.io/categories/spark/"}],"tags":[{"name":"Spark","slug":"spark","permalink":"https://mhuig.github.io/tags/spark/"}]},{"title":"Ubuntu环境安装","slug":"Linux/Ubuntu环境安装","date":"2020-05-06T08:30:53.000Z","updated":"2020-05-06T08:30:53.000Z","comments":true,"path":"posts/2844bf39.html","link":"","permalink":"https://mhuig.github.io/posts/2844bf39.html","excerpt":"Ubuntu 20.04 LTS 在虚拟机中的安装配置","text":"Ubuntu 20.04 LTS 在虚拟机中的安装配置 Ubuntu 20.04 LTS 的支持周期长达 5 年，同时适用于 Ubuntu Desktop、Ubuntu Server、Ubuntu Cloud 和 Ubuntu Core，其安全和维护更新直到 2025 年 4 月才到期。其余 flavour 的支持也长达 3 年，更多详细信息请参考 Ubuntu 20.04 LTS 发行说明。 下载Ubuntu镜像文件官方下载地址（不推荐） https://www.ubuntu.com/download 中国官网（推荐） https://cn.ubuntu.com/ VMware 安装配置 创建新的虚拟机 桌面版系统安装配置 安装过程完成后，单击「现在重启」以完成整个过程，然后卸下安装介质并按「回车」键以重新引导系统。 服务器版系统安装配置 选择系统语言-English键盘设置-English网卡设置，默认。代理服务设置，无代理不填写镜像地址设置，建议换成国内镜像：http://mirrors.aliyun.com/ubuntu/空格选中SSH安装。环境，无需选择。开始安装，等待出现重启选项。安装完成，选择重启。 启用root用户 启用root用户 设置root用户使用sudo passwd root来设置root密码设置root密码1sudo passwd root然后使用su root命令，再输入密码，测试是否可以进入root用户进入root1su root修改/root/.profile文件运行vim /root/.profile命令修改文件，但是发现系统没有安装vim，可以使用apt install vim命令自动安装vim安装成功后，使用vim /root/.profile打开该文件（你也可以使用nano）找到最后一行：mesg n || true，先注释掉，增加tty -s &amp;&amp; mesg n || true这行修改/etc/pam.d/目录下文件运行cd /etc/pam.d/，里面有两个要修改的文件，即gdm-autologin和gdm-password运行vim gdm-autologin，注释掉下面一行运行vim gdm-password，注释掉下面一行重启系统或者虚拟机输入用户名root，然后输入设置的root密码，使完成用root登录 更换国内源 更换国内源 备份/etc/apt/sources.list1sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak修改Ubuntu的源列表修改 /etc/apt/sources.list 文件下的列表清华大学开源软件镜像站更新apt1sudo apt-get update 安装SSH、配置SSH无密码登陆 配置SSH 集群、单节点模式都需要用到 SSH 登陆（类似于远程登陆，你可以登录某台 Linux 主机，并且在上面运行命令），Ubuntu 默认已安装了 SSH client，此外还需要安装 SSH server：1sudo apt-get install openssh-server安装后，可以使用如下命令登陆本机：1ssh localhost利用 ssh-keygen 生成密钥，并将密钥加入到授权中：123cd ~&#x2F;.ssh&#x2F;ssh-keygen -t rsa # 会有提示，都按回车就可以cat .&#x2F;id_rsa.pub &gt;&gt; .&#x2F;authorized_keys # 加入授权如果没有问题可能是ssh-server的配置文件设置了拒绝以root用户登录的模式：1nano &#x2F;etc&#x2F;ssh&#x2F;sshd_config1PermitRootLogin yes重启ssh-server1sudo &#x2F;etc&#x2F;init.d&#x2F;ssh restart","categories":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"},{"name":"Ubuntu","slug":"linux/ubuntu","permalink":"https://mhuig.github.io/categories/linux/ubuntu/"}],"tags":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/tags/linux/"},{"name":"Ubuntu","slug":"ubuntu","permalink":"https://mhuig.github.io/tags/ubuntu/"}]},{"title":"Travellings 开往下一个地方","slug":"Travellings开往下一个地方","date":"2020-05-04T11:47:43.000Z","updated":"2020-05-04T11:47:43.000Z","comments":true,"path":"posts/4bd2472f.html","link":"","permalink":"https://mhuig.github.io/posts/4bd2472f.html","excerpt":"互联网将人与人之间的距离大大减小，却还是形成了大大小小的孤岛。只有熟人间才知道彼此，而陌生人永远只能是陌生人。","text":"互联网将人与人之间的距离大大减小，却还是形成了大大小小的孤岛。只有熟人间才知道彼此，而陌生人永远只能是陌生人。 什么是开往-友链接力开往-友链助力是传统友链的增强，我们不必互相知道了解彼此，标准的审查让友好的朋友加入我们，只需要一个徽标，占用一块位置，我们所有人都联系在了一起，简单而又强大。 开往-友链接力 旅行愉快日常大家可以点击banner或者footer栏中的“Travellings”图标去参观其他博主的博客，祝大家旅行愉快。 站台这里是下一站的站台，来场星际旅行吧~。","categories":[{"name":"笔录","slug":"笔录","permalink":"https://mhuig.github.io/categories/%E7%AC%94%E5%BD%95/"}],"tags":[{"name":"笔录","slug":"笔录","permalink":"https://mhuig.github.io/tags/%E7%AC%94%E5%BD%95/"}]},{"title":"哈勃望远镜在你生日那天看到了啥","slug":"哈勃望远镜在你生日那天看到了啥","date":"2020-05-04T08:50:43.000Z","updated":"2020-05-04T08:50:43.000Z","comments":true,"path":"posts/6af346a8.html","link":"","permalink":"https://mhuig.github.io/posts/6af346a8.html","excerpt":"","text":"About1990年，NASA将哈勃望远镜送进太空。多年来哈勃望远镜一直在探索宇宙，拍摄了许多珍贵的图像。 2020年是哈勃望远镜服役的第30年，为此NASA公开了哈勃望远镜拍摄的366张珍贵图像。 哈勃望远镜每周 7 天，每天 24 小时不间断地探索宇宙。 这意味着它在一年中的每一天都观察到了一些迷人的宇宙奇观。 What did Hubble look at on your birthday? 可以在 NASA 网站 中输入月份和日期来查找。 What Did Hubble See on Your Birthday?大图警告 点击查看","categories":[{"name":"笔录","slug":"笔录","permalink":"https://mhuig.github.io/categories/%E7%AC%94%E5%BD%95/"}],"tags":[{"name":"笔录","slug":"笔录","permalink":"https://mhuig.github.io/tags/%E7%AC%94%E5%BD%95/"}]},{"title":"PDF测试","slug":"Test/PDF测试","date":"2020-05-02T13:02:43.000Z","updated":"2020-05-02T13:02:43.000Z","comments":true,"path":"posts/323ed1b8.html","link":"","permalink":"https://mhuig.github.io/posts/323ed1b8.html","excerpt":"","text":"PDF测试 源码 源码文件","categories":[{"name":"实验性","slug":"实验性","permalink":"https://mhuig.github.io/categories/%E5%AE%9E%E9%AA%8C%E6%80%A7/"}],"tags":[{"name":"实验性","slug":"实验性","permalink":"https://mhuig.github.io/tags/%E5%AE%9E%E9%AA%8C%E6%80%A7/"}]},{"title":"大数据技术概述","slug":"bigdata/大数据技术概述","date":"2020-05-01T00:02:39.000Z","updated":"2020-05-01T00:02:39.000Z","comments":true,"path":"posts/376025fe.html","link":"","permalink":"https://mhuig.github.io/posts/376025fe.html","excerpt":"","text":"大数据时代 第三次信息化浪潮根据IBM前首席执行官郭士纳的观点，IT领域每隔十五年就会迎来一次重大变革 信息化浪潮 发生时间 标志 解决问题 代表企业 第一次浪潮 1980年前后 个人计算机 信息处理 Intel、AMD、IBM、苹果、微软、联想、戴尔、惠普等 第二次浪潮 1995年前后 互联网 信息传输 雅虎、谷歌、阿里巴巴、百度、腾讯等 第三次浪潮 2010年前后 物联网、云计算和大数据 信息爆炸 将涌现出一批新的市场标杆企业 信息科技为大数据时代提供技术支撑 存储设备容量不断增加 CPU处理能力大幅提升 网络带宽不断增加 数据产生方式的变革促成大数据时代的来临 大数据的特征及数据科学面临的挑战 大数据概念 数据量大 数据类型繁多 处理速度快 价值密度低 大数据的影响图灵奖获得者、著名数据库专家Jim Gray 博士观察并总结人类自古以来，在科学研究上，先后历经了实验、理论、计算和数据四种范式 在思维方式方面，大数据完全颠覆了传统的思维方式： 全样而非抽样 效率而非精确 相关而非因果 大数据关键技术 技术层面 功能 数据采集 利用ETL工具将分布的、异构数据源中的数据如关系数据、平面数据文件等，抽取到临时中间层后进行清洗、转换、集成，最后加载到数据仓库或数据集市中，成为联机分析处理、数据挖掘的基础；或者也可以把实时采集的数据作为流计算系统的输入，进行实时处理分析 数据存储和管理 利用分布式文件系统、数据仓库、关系数据库、NoSQL数据库、云数据库等，实现对结构化、半结构化和非结构化海量数据的存储和管理 数据处理与分析 利用分布式并行编程模型和计算框架，结合机器学习和数据挖掘算法，实现对海量数据的处理和分析；对分析结果进行可视化呈现，帮助人们更好地理解数据、分析数据 数据隐私和安全 在从大数据中挖掘潜在的巨大商业价值和学术价值的同时，构建隐私数据保护体系和数据安全体系，有效保护个人隐私和数据安全 两大核心技术 大数据计算模式 代表性大数据技术Hadoop Hadoop—MapReduce MapReduce将复杂的、运行于大规模集群上的并行计算过程高度地抽象到了两个函数：Map和Reduce 编程容易，不需要掌握分布式并行编程细节，也可以很容易把自己的程序运行在分布式系统上，完成海量数据的计算 MapReduce采用“分而治之”策略，一个存储在分布式文件系统中的大规模数据集，会被切分成许多独立的分片（split），这些分片可以被多个Map任务并行处理 Hadoop—YARNYARN的目标就是实现“一个集群多个框架”，为什么？ 一个企业当中同时存在各种不同的业务应用场景，需要采用不同的计算框架 MapReduce实现离线批处理 使用Impala实现实时交互式查询分析 使用Storm实现流式数据实时分析 使用Spark实现迭代计算 这些产品通常来自不同的开发团队，具有各自的资源调度管理机制为了避免不同类型应用之间互相干扰，企业就需要把内部的服务器拆分成多个集群，分别安装运行不同的计算框架，即“一个框架一个集群” 导致问题 集群资源利用率低 数据无法共享 维护代价高 YARN的目标就是实现“一个集群多个框架”，即在一个集群上部署一个统一的资源调度管理框架YARN，在YARN之上可以部署其他各种计算框架由YARN为这些计算框架提供统一的资源调度管理服务，并且能够根据各种计算框架的负载需求，调整各自占用的资源，实现集群资源共享和资源弹性收缩可以实现一个集群上的不同应用负载混搭，有效提高了集群的利用率不同计算框架可以共享底层存储，避免了数据集跨集群移动 Spark Flink Beam","categories":[{"name":"BigData","slug":"bigdata","permalink":"https://mhuig.github.io/categories/bigdata/"}],"tags":[{"name":"BigData","slug":"bigdata","permalink":"https://mhuig.github.io/tags/bigdata/"}]},{"title":"Mac Code Test","slug":"Test/macCodeTest","date":"2020-04-30T06:06:43.000Z","updated":"2020-04-30T06:06:43.000Z","comments":true,"path":"posts/91953e39.html","link":"","permalink":"https://mhuig.github.io/posts/91953e39.html","excerpt":"","text":"代码块全屏测试 How To Use? 导入库文件即可12&lt;link rel&#x3D;&#39;stylesheet&#39; href&#x3D;&#39;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;MHuiG&#x2F;blog-cdn@1.1.12&#x2F;css&#x2F;me.css&#39;&gt;&lt;script src&#x3D;&#39;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;MHuiG&#x2F;blog-cdn@1.1.12&#x2F;js&#x2F;me.js&#39;&gt;&lt;&#x2F;script&gt; cpp code12345678#include &lt;iostream&gt;using namespace std; int main() &#123; cout &lt;&lt; &quot;Hello, World!&quot;; return 0;&#125; python code123#!/usr/bin/pythonprint (&quot;Hello, Python!&quot;) code1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;cstdio&gt;#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;const int SIZE = 5e6 + 1;struct edge&#123; int to_node, id; edge(int t, int i): to_node(t), id(i) &#123;&#125; ~edge() = default;&#125;;vector&lt;int&gt; edges[SIZE];vector&lt;edge&gt; querys[SIZE];int father[SIZE], mark[SIZE], ans[SIZE];int n, m, s;int getfa(int x)&#123; if (father[x] == x) return x; else return father[x] = getfa(father[x]);&#125;void tarjan(int x)&#123; mark[x] = 1; for (auto i = edges[x].begin(); i != edges[x].end(); i++) &#123; if (mark[*i]) continue; tarjan(*i); father[*i] = x; &#125; for (auto i = querys[x].begin(); i != querys[x].end(); i++) &#123; int y = (*i).to_node, id = (*i).id; if (mark[y] == 2) ans[id] = getfa(y); &#125; mark[x] = 2;&#125;int main()&#123; int u, v; scanf(&quot;%d%d%d&quot;, &amp;n, &amp;m, &amp;s); for (int i = 1; i &lt;= n; i++) &#123; father[i] = i; mark[i] = 0; &#125; for (int i = 1; i &lt; n; i++) &#123; scanf(&quot;%d%d&quot;, &amp;u, &amp;v); edges[u].emplace_back(v); edges[v].emplace_back(u); &#125; int x, y; for (int i = 1; i &lt;= m; i++) &#123; scanf(&quot;%d%d&quot;, &amp;x, &amp;y); if (x == y) ans[i] = 0; else &#123; querys[x].emplace_back(edge(y, i)); querys[y].emplace_back(edge(x, i)); &#125; &#125; tarjan(s); for (int i = 1; i &lt;= m; i++) printf(&quot;%d\\n&quot;, ans[i]); return 0;&#125;","categories":[{"name":"实验性","slug":"实验性","permalink":"https://mhuig.github.io/categories/%E5%AE%9E%E9%AA%8C%E6%80%A7/"}],"tags":[{"name":"实验性","slug":"实验性","permalink":"https://mhuig.github.io/tags/%E5%AE%9E%E9%AA%8C%E6%80%A7/"}]},{"title":"图片墙","slug":"Test/图片墙","date":"2020-04-28T04:05:43.000Z","updated":"2020-04-28T04:05:43.000Z","comments":false,"path":"posts/e9fadccb.html","link":"","permalink":"https://mhuig.github.io/posts/e9fadccb.html","excerpt":"","text":"* { margin: 0; padding: 0;} .list { width: 100%; margin: 0 auto; overflow: hidden; zoom: 1;} .list .ul { float: left; width: calc((100% - 100px)/4); margin: 0 10px;} .list .li { margin-bottom: 20px;} .list img { width: 100%; border-radius: 5px; vertical-align: top;} function URL(d){ d+=new Date().getTime() var s = \"https://picsum.photos/seed/\"+d+\"/200/300\" return s } var i=0; function WriteHtml(){ document.getElementsByClassName('list')[0].innerHTML+=` ` } WriteHtml(); WriteHtml(); WriteHtml(); WriteHtml(); $(window).scroll(function(){ var scrollTop = $(this).scrollTop(); var scrollHeight = $(document).height(); var windowHeight = $(this).height(); if(scrollTop + windowHeight > scrollHeight - 2000){ WriteHtml() } });","categories":[{"name":"笔录","slug":"笔录","permalink":"https://mhuig.github.io/categories/%E7%AC%94%E5%BD%95/"}],"tags":[{"name":"笔录","slug":"笔录","permalink":"https://mhuig.github.io/tags/%E7%AC%94%E5%BD%95/"}]},{"title":"时间之箭","slug":"yuquebank/时间之箭","date":"2020-04-22T01:42:43.000Z","updated":"2020-04-22T01:42:43.000Z","comments":true,"path":"posts/564714f9.html","link":"","permalink":"https://mhuig.github.io/posts/564714f9.html","excerpt":"时间就像一只箭，射向未知的前方，把过去永远留在后面。Time is like an arrow, shooting towards the unknown, leaving the past behind forever.","text":"时间就像一只箭，射向未知的前方，把过去永远留在后面。Time is like an arrow, shooting towards the unknown, leaving the past behind forever. 每个人 你所热爱的一切Every piece of everyone, of everything you love, 你所憎恨的一切 of everything you hate, 你所拥有的最宝贵的东西 of everything you hold most precious, 在宇宙生命中最为伊始的几分钟内 was assembled by the forces of nature 由自然的力量合成 in the first few minutes of the universe, 在恒星的中心转化 transformed in the hearts of starts 或者在它们燃烧的消亡中诞生 or created in their fiery deaths 而当你去世的时候 And when you die, 这些碎片将回到宇宙中 those pieces will be returned to the universe 进入无限的死亡又重生的轮回之中 in the endless cycle of death and rebirth. 太阳的命运也是所有恒星的命运 The fate of the sun is the same as for all starts. 终有一天 他们都会消亡 One day, they must all eventually die 宇宙将会陷入永无止境的黑暗之中 and the cosmos will be plunged into eternal night. 这便是时间箭头最深远的影响 And this is the most profound consequence of the arrow of time. 我刚用相机捕捉到的 The light that I’ve just captured 这个光点二百五十万年前踏上了旅程 in my camera began its journey 2.5 million years ago. 那时地球上还没有人类 At that time, on Earth, there were no humans. 远古的祖先能人 Homo habilis, our distant ancestors, 正在非洲广袤的平原上漫步 wereroaming the plaints of Africa, 就是在那些光线 and as those light rays travelled 平行于无垠宇宙的同时 through the vastness of space. 人类不断进化 our species evolved,and thousands 一代又一代的生老病死 and thousands and thousands of qenerations of humans lived 周而复始 and died, 旅途开始的二百五十万年后 and then 2.5 million years after their journey began, 这些远道而来的信使 these messengers from the depths of space 穿越漫长的时间 and from way back in our past, 映入现在我们的眼帘 arrived here on Earth. 我们与那些遥远星系息息相关 we are in a very real sense connected to these qalaxies, 无论它们是如何与我们天各一方 no matter how far away they are across the universe, 那些经历过数十亿年旅行到达地球的光线 connected by the light 终究会把我们联系在一起 that’s journeved billions of ears to reach us. “生星时代” The Stelliferous Era - 恒星漫天的时代 the age of the starts. 我们的太阳只是银河系两千亿颗恒星中的一颗 Our sun is just one of 200 billion starts in our qalaxy. 我们的星系也只是可观测的宇宙范围内的 Our qalaxy is one of 100 bllion 一百亿个星系中的一个 in the observable universe. 数不尽的星球上有数不胜数的岛屿 And countless islands of countless stars. 当我们注意太空的时候 When we look out into space, 我们也是在寻找自己的起源 we are looking into our own origins. 我们的故事就是宇宙的故事 Our story is the story of the universe. 因为我们是恒星真正的孩子 Beacuse we are truly children of the starts. 注入进我们的身体的 and written into every atom 每一个原子和分子 and every molecule of our bodies 就是宇宙从大爆炸 is the entire history of the universe 到现在全部的历史 from the Big Bang to the present day. 对我们来说 像婚戒黄金一样的珍宝 It’s quite a thought that something as 实际上也可以在一颗遥远的 数百万光年 precious to us as the gold in a wedding ring was 甚至数十亿光年远的恒星上产生actually forged in the death of a distant star. 从宇宙起源到最后一个黑洞消失的这个过程中 as measured from its beainning to the evappration of the last black hole. 生命 正如我们所知life as we konw it, is only possible 只有百分之千亿分之for one thousandth of a billion billion billionth 千亿分之千分之一的可能性billion billion billionth billion billion billionth of a percent. 所以对于我来说 And that’s why for me 宇宙中最迷人的奇迹不是恒星 the most astonishing wonder of the universe isn’t a star 不是行星 也不是星系 or a planet or a galaxy 甚至根本不是一个物质 It isn’t a thing at all 而是时间里的一瞬间 It’s an instant in time 那个瞬间 就是现在 And that time is now. 当我们仰望天空 You see, when we look up into the sky, 望向遥远的恒星和星系时 at distant starts and galaxies, 我们其实是在仰望过去 then we’re looking back in time 因为光从那些遥远天体到达地球需要时间 because the light takes time to journey from them to us. 而光从那个红点处传播到我们这里 And the light from that red dot has been travelling to us 差不多经历了整个宇宙史 for almost the entire history of the universe. 我们看到的是一百三十亿年前 You see, what we’re looking at here is an event that happened 发生的事件 13 billion years ago. 我们看到的是宇宙初期的一颗恒星 What we’re looking at here is the explosive death 爆炸灭亡的景象 of one of the first starts in the universe. 一日为二十四个小时 A day on Earth is the 24 hours 即地球绕轴自转一周 it takes our planet to rotate once on its axis. 一月为二十九天半 Our months are based on the 29-and-a-half days 即月亮在夜空完成盈亏圆缺 it takes the moon to wax and wane in the night sky. 一年为三百六十五天又四分之一天 And a year is the 365-and-a-quarter days 即地球绕太阳公转一周 it takes us to orbit once around the sun. 人类的生命便消逝在这些熟悉的时间量程之内 These familiar timescales mark the passing of our lives. 这是宇宙无法避免的真相 It’s an inescapable fact of the universe, 也被写入了物理学基本定律 written into the fundamental laws of physics, 整个宇宙将消亡 The entire cosmos will die, 银河系中的两千亿恒星将全部消亡 Every single one of the 200 billion starts in our galaxy will go out. 如同太阳末日 便是地球末日 And just as the death of the sun means the end of life on our planet, 每一颗恒星的灭亡 so the death of every star 都可能预示着宇宙中其他某种生命的灭亡 will extinguish any possibility of life in the universe. 永恒的变化是人类生命中最基本的部分 Permanent change is a fundamental part of what it means to be human. 随着时间流逝 我们都会变老We all age as the years pass by. 人们出生 成长 死亡People are born, they live, they die. 我想这只是生命中悲悲喜喜的一部分I suppose it’s part of the joy and tragedy of our lives. 但纵观宇宙But out there in the universe, 那些宏伟的如史诗般的循环好像永恒不变those grand and epic cycles appear eternal and unchanging. 然而这只是错觉But that’s an illlusion. 宇宙长河就如同我们的生命一样You see, in the life of the universe, just in our lives, 一切都在不可逆转地变化everything is irreversibly changing. 我们从没见过浪花离开过湖面We never see waves travelling across lakes. 聚集在一起 组成巨大的冰块重回冰川coming together and bouncing chunks of ice back onto glaciers. 我们被迫前往将来We are compelled to travel into the future. 那是因为And that’s because 时间箭头规定 随着时间流逝the arrow of time dictates that as each moment passes, 万物也在发生变化things change. 变化一旦发生 就无法更改And once these changes have happend, they are never undone. 这些循环看似永恒不变These cycles seem eternal and unchanging, 但随着时间之书徐徐展开but as the story of time unfolds, 一条真理跃然眼前afundamental truth is revealed. 没有什么能够永恒Nothing lates forever.","categories":[{"name":"Time","slug":"time","permalink":"https://mhuig.github.io/categories/time/"}],"tags":[{"name":"Time","slug":"time","permalink":"https://mhuig.github.io/tags/time/"}]},{"title":"Hello World","slug":"yuquebank/Hello World","date":"2020-04-19T06:24:29.000Z","updated":"2020-04-19T06:24:29.000Z","comments":true,"path":"posts/4a17b156.html","link":"","permalink":"https://mhuig.github.io/posts/4a17b156.html","excerpt":"你好，世界！","text":"你好，世界！ 全新的主题，熟悉的代码，怎能不再次心动？ 这是 MHuiG 的又一个博客！ 原博客数据不再迁移此处，将其作为该博客的子站我的 NoteBook: https://mhuig.github.io/NoteBook/","categories":[{"name":"Hello","slug":"hello","permalink":"https://mhuig.github.io/categories/hello/"}],"tags":[{"name":"Hello","slug":"hello","permalink":"https://mhuig.github.io/tags/hello/"}]},{"title":"理解卷积","slug":"ml/理解卷积","date":"2020-03-09T12:05:42.000Z","updated":"2020-03-09T12:05:42.000Z","comments":true,"path":"posts/xa6297acc.html","link":"","permalink":"https://mhuig.github.io/posts/xa6297acc.html","excerpt":"本文的目的是深入的理解卷积,通过一些示例,卷积将会成为一个非常简单的想法.","text":"本文的目的是深入的理解卷积,通过一些示例,卷积将会成为一个非常简单的想法. 抛球的经验想象一下，我们将一个球从某个高度掉落到地面上，球在该地面只能在一个方向上运动,如果您将球放下然后从其着陆点上方再次放下,球可能会前进的距离是多少?让我们分解一下。在第一次下落之后，它将以概率降落距起点个单位，其中是概率分布。现在，在第一次下落之后，我们将球捡起并从其首次着陆点上方的另一个高度下落。球从新起点滚动单位的概率为,其中如果从不同高度掉落，则可能是不同的概率分布。 如果我们确定了第一个的结果，我们就知道了球的移动距离，对于球的总距离为，第二个球的移动距离也固定为，其中。因此发生这种情况的可能性就是。 让我们考虑一个具体的离散示例。 我们希望总距离为。如果它第一次滚动，则第二次它必须滚动,才能达到我们的总距离。 这个概率是。 但是，这不是我们达到的总距离的唯一方法。球第一次可以滚动个单位，第二次可以滚动个单位。 或第一次为，第二次为。 只要将和加和等于，它就可以取任意值。 这个概率分别是和。 为了找出球到达总距离的总可能性，我们不能仅考虑一种到达的可能方式。 相反，我们考虑将划分为两个球和的所有可能方法，并对每种方法的概率求和。我们已经知道，对于每种情况，的概率就是。 因此，对的每个解求和，我们可以将总似然表示为：事实证明，我们正在做卷积! 特别地，定义在处的和的卷积定义为：如果我们用代替，我们得到：这是卷积的标准定义。为了更具体一点，我们可以考虑球可能着陆的位置。 在第一次下降之后，它将以概率降落在中间位置。 如果它降落在处，则它有概率降落在位置处。 为了得到卷积，我们考虑所有中间位置。 可视化卷积有一个很好的技巧，可以帮助人们更轻松地思考卷积。 首先，观察。 假设一个球从其起点降落一定距离的概率为。 然后，此后，它从着陆点开始的距离为的概率为。 如果我们知道球在第二次下降后落在位置上，那么前一个位置是的概率是多少？ 因此，先前位置为的概率为。 现在，考虑每个中间位置有助于球最终降落在的概率。 我们知道第一滴将球放到中间位置的概率是。 我们还知道，如果它降落在上，它进入的概率为。 对所有求和，我们得到了卷积。 这种方法的优点是，它使我们可以在单个图片中可视化卷积在值处的评估。 通过移动下半部分，我们可以评估其他值的卷积。 这使我们能够从整体上理解卷积。 例如，我们可以看到分布对齐时达到峰值。 且随着分布之间的交点变小而缩小。 过在动画中使用此技巧，实际上可以从视觉上理解卷积。 下面，我们可以看到两个框函数的卷积： 有了这种观点，很多事情就会变得更加直观。 让我们考虑一个非概率示例。 卷积有时在音频处理中使用。 例如，一个函数可能会使用其中有两个尖峰但在其他所有地方为零的函数来创建回波。 当我们的双尖峰功能滑动时，一个尖峰首先击中一个时间点，将该信号添加到输出声音中，然后又出现另一个尖峰，并添加第二个延迟副本。 高维卷积卷积是一个非常笼统的想法。我们还可以将它们用于更大的尺寸。让我们再次考虑一个落球的例子。现在，随着位置的下降，它的位置不仅在一维，而在二维。 卷积与以前相同：除了，现在，和是向量。更明确地说， 或在标准定义中：就像一维卷积一样，我们可以将二维卷积视为将一个函数滑动到另一个函数之上，相乘和相加。一种常见的应用是图像处理。我们可以将图像视为二维函数。许多重要的图像转换都是卷积，您可以在其中将图像函数与一个非常小的局部函数（称为“卷积核”）进行卷积。 卷积核滑动到图像的每个位置，并计算一个新像素作为其浮动像素的加权和。例如，通过平均3x3像素矩阵，我们可以使图像模糊。 为此，我们的内核在框中的每个像素上取值， 我们还可以通过在两个相邻像素上取值和，在其他所有位置取零来检测边缘。 也就是说，我们减去两个相邻像素。 当并排像素相似时，这大约等于零。 然而，在边缘上，相邻像素在垂直于边缘的方向上有很大不同。 卷积神经网络那么，卷积与卷积神经网络有何关系？ 考虑一个具有输入和输出的一维卷积层，就像这样： 正如我们观察到的，我们可以用输入来描述输出：通常，A将是多个神经元。 但是假设它只是一个神经元。回想一下，神经网络中的典型神经元描述为：其中，是输入。 权重，描述了神经元如何连接到其输入。 负权重表示输入抑制神经元的激活，而正权重则鼓励神经元激活。 权重是神经元的心脏，控制神经元的行为。说多个神经元是相同的，这与说权重相同是一回事。卷积将为我们处理的是神经元的这种连线，描述了所有权重以及哪些权重相同。通常，我们一次而不是单独描述一个层中的所有神经元。 诀窍是要有一个权重矩阵：例如，我们得到：矩阵的每一行都描述了将神经元连接到其输入的权重。但是，返回到卷积层，因为同一神经元有多个副本，所以许多权重出现在多个位置。 对应于等式：因此，通常，权重矩阵会将每个输入连接到具有不同权重的每个神经元：像上面的卷积层的矩阵看起来很不一样。 相同的权重出现在多个位置中。 而且由于神经元没有连接到许多可能的输入，因此存在很多零。与上述矩阵相乘与与，，卷积相同。 滑动到不同位置的功能对应于在那些位置具有神经元。二维卷积层呢？ 二维卷积层的布线对应于二维卷积。考虑上面的示例，通过使用卷积来检测图像边缘，方法是在周围滑动一个内核并将其应用于每个面片。 就像这样，卷积层会将神经元应用于图像的每个patch。 结论我们在此博客文章中介绍了许多数学机制，但是获得的结果可能并不明显。 卷积显然是概率论和计算机图形学中的有用工具，但是从卷积的角度说卷积神经网络有什么好处呢？ 第一个优点是我们拥有一些非常强大的语言来描述网络的布线。 到目前为止，我们所处理的示例还不够复杂，以至于无法清楚地看到这种好处，但是通过卷积可以使我们摆脱大量令人不快的簿记工作。 其次，卷积具有明显的实施优势。 许多库提供高效的卷积例程。 此外，尽管卷积天真地看起来是运算，但使用一些相当深的数学见解，就有可能创建实现。 我们将在以后的文章中对此进行更详细的讨论。 实际上，在GPU上使用高效并行卷积实现对于计算机视觉的最新进展至关重要。 参考文献[English] Understanding Convolutions","categories":[{"name":"Math","slug":"math","permalink":"https://mhuig.github.io/categories/math/"},{"name":"概率","slug":"math/概率","permalink":"https://mhuig.github.io/categories/math/%E6%A6%82%E7%8E%87/"}],"tags":[{"name":"Math","slug":"math","permalink":"https://mhuig.github.io/tags/math/"},{"name":"概率","slug":"概率","permalink":"https://mhuig.github.io/tags/%E6%A6%82%E7%8E%87/"},{"name":"神经网络","slug":"神经网络","permalink":"https://mhuig.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}]},{"title":"JavaScript反调试","slug":"web/JavaScript反调试","date":"2020-02-26T02:36:40.000Z","updated":"2020-02-26T02:36:40.000Z","comments":true,"path":"posts/bfe2ff2a.html","link":"","permalink":"https://mhuig.github.io/posts/bfe2ff2a.html","excerpt":"总结一下关于JavaScript反调试技巧方面的内容。本文的目的是收集与JavaScript中的反调试有关的小窍门（其中一些已经被恶意软件或商业产品使用）。","text":"总结一下关于JavaScript反调试技巧方面的内容。本文的目的是收集与JavaScript中的反调试有关的小窍门（其中一些已经被恶意软件或商业产品使用）。 对于JavaScript来说，你只需要花一点时间进行调试和分析，你就能够了解到JavaScript代码段的功能逻辑。而我们所要讨论的内容，可以给那些想要分析你JavaScript代码的人增加一定的难度。不过我们的技术跟代码混淆无关，我们主要针对的是如何给代码主动调试增加困难。本文所要介绍的技术方法大致如下： 检测未知的执行环境（我们的代码只想在浏览器中被执行）； 检测调试工具（例如DevTools）； 代码完整性控制； 流完整性控制； 反模拟； 简而言之，如果我们检测到了“不正常”的情况，程序的运行流程将会改变，并跳转到伪造的代码块，并“隐藏”真正的功能代码。 函数重定义这是一种最基本也是最常用的代码反调试技术了。在JavaScript中，我们可以对用于收集信息的函数进行重定义。比如说，**console.log()**函数可以用来收集函数和变量等信息，并将其显示在控制台中。如果我们重新定义了这个函数，我们就可以修改它的行为，并隐藏特定信息或显示伪造的信息。我们可以直接在DevTools中运行这个函数来了解其功能： 1234console.log(&quot;HelloWorld&quot;);var fake = function() &#123;&#125;;window[&#x27;console&#x27;][&#x27;log&#x27;]= fake;console.log(&quot;Youcan&#x27;t see me!&quot;); 运行后我们将会看到： 1VM127:1 HelloWorld 你会发现第二条信息并没有显示，因为我们重新定义了这个函数，即“禁用”了它原本的功能。但是我们也可以让它显示伪造的信息。比如说这样： 123456789101112131415161718192021console.log(&quot;Normalfunction&quot;);//First we save a reference to the original console.log functionvar original = window[&#x27;console&#x27;][&#x27;log&#x27;];//Next we create our fake function//Basicly we check the argument and if match we call original function with otherparam.// If there is no match pass the argument to the original functionvar fake = function(argument) &#123; if (argument === &quot;Ka0labs&quot;) &#123; original(&quot;Spoofed!&quot;); &#125; else &#123; original(argument); &#125;&#125;// We redefine now console.log as our fake functionwindow[&#x27;console&#x27;][&#x27;log&#x27;]= fake;//Then we call console.log with any argumentconsole.log(&quot;Thisis unaltered&quot;);//Now we should see other text in console different to &quot;Ka0labs&quot;console.log(&quot;Ka0labs&quot;);//Aaaand everything still OKconsole.log(&quot;Byebye!&quot;); 如果一切正常的话： 1234VM84:1 NormalfunctionVM84:11 Thisis unalteredVM84:9 Spoofed!VM84:11 Byebye! 实际上，为了控制代码的执行方式，我们还能够以更加聪明的方式来修改函数的功能。比如说，我们可以基于上述代码来构建一个代码段，并重定义eval函数。我们可以把JavaScript代码传递给eval函数，接下来代码将会被计算并执行。如果我们重定义了这个函数，我们就可以运行不同的代码了： 123456789101112131415161718//Just a normal evaleval(&quot;console.log(&#x27;1337&#x27;)&quot;);//Now we repat the process...var original = eval;var fake = function(argument) &#123; // If the code to be evaluated contains1337... if (argument.indexOf(&quot;1337&quot;) !==-1) &#123; // ... we just execute a different code original(&quot;for (i = 0; i &lt; 10;i++) &#123; console.log(i);&#125;&quot;); &#125; else &#123; original(argument); &#125;&#125;eval= fake;eval(&quot;console.log(&#x27;Weshould see this...&#x27;)&quot;);//Now we should see the execution of a for loop instead of what is expectedeval(&quot;console.log(&#x27;Too1337 for you!&#x27;)&quot;); 运行结果如下： 123456789101112VM171:1 1337VM172:1 Weshould see this...VM173:1 0VM173:1 1VM173:1 2VM173:1 3VM173:1 4VM173:1 5VM173:1 6VM173:1 7VM173:1 8VM173:1 9 通过这种方式修改程序流是一个很酷的技巧，但是正如我们在一开始所说的那样，它是最基本的技巧，很容易被发现并被击败。这是因为在JavaScript中，每个函数都有一个方法toString（或Firefox中的toSource）返回其自己的代码。因此，仅需要检查所需函数的代码是否已更改。当然，我们可以重新定义方法toString / toSource，但是我们陷入了同样的情况：**function.toString.toString()**。 断点为了帮助我们了解代码的功能，JavaScript调试工具（例如DevTools）都可以通过设置断点的方式阻止脚本代码执行，而断点也是代码调试中最基本的了。如果你研究过调试器或者x86架构，你可能会比较熟悉0xCC指令。在JavaScript中，我们有一个名叫debugger的类似指令。当我们在代码中声明了debugger函数后，脚本代码将会在debugger指令这里停止运行。比如说： 123console.log(&quot;Seeme!&quot;);debugger;console.log(&quot;Seeme!&quot;); 很多商业产品会在代码中定义一个无限循环的debugger指令，不过某些浏览器会屏蔽这种代码，而有些则不会。这种方法的主要目的就是让那些想要调试你代码的人感到厌烦，因为无限循环意味着代码会不断地弹出窗口来询问你是否要继续运行脚本代码： 1setTimeout(function()&#123;while (true) &#123;eval(&quot;debugger&quot;) 1setInterval(function() &#123;var a = new Date(); debugger; return new Date() - a &gt; 100;&#125;, 100); 时间差异这是一种从传统反逆向技术那里借鉴过来的基于时间的反调试技巧。当脚本在DevTools等工具环境下执行时，运行速度会非常慢（时间久），所以我们就可以根据运行时间来判断脚本当前是否正在被调试。比如说，我们可以通过测量代码中两个设置点之间的运行时间，然后用这个值作为参考，如果运行时间超过这个值，说明脚本当前在调试器中运行。演示代码如下： 1234567891011setInterval(function()&#123; var startTime = performance.now(), check,diff; for (check = 0; check &lt; 1000; check++)&#123; console.log(check); console.clear(); &#125; diff = performance.now() - startTime; if (diff &gt; 200)&#123; alert(&quot;Debugger detected!&quot;); &#125;&#125;,500); DevTools检测（I）[Chrome]：getter这项技术利用的是div元素中的id属性，当div元素被发送至控制台（例如console.log(div)**）时，浏览器会自动尝试获取其中的元素id。如果代码在调用了console.log之后又调用了getter**方法，说明控制台当前正在运行。简单的概念验证代码如下： 123456789let div = document.createElement(&#x27;div&#x27;);let loop = setInterval(() =&gt; &#123; console.log(div); console.clear();&#125;);Object.defineProperty(div,&quot;id&quot;, &#123;get: () =&gt; &#123; clearInterval(loop); alert(&quot;Dev Tools detected!&quot;);&#125;&#125;); DevTools检测（II）[Chrome]：大小更改如果打开了DevTools（除非将其取消对接打开），则window.outerWidth / Height和window.innerWidth / Height之间的差异将发生变化，因此可以循环检测。Devtools-detect使用此技巧： 123const widthThreshold = window.outerWidth - window.innerWidth &gt; threshold;const heightThreshold = window.outerHeight - window.innerHeight &gt; threshold;const orientation = widthThreshold ? &#x27;vertical&#x27; : &#x27;horizontal&#x27;; 隐式流完整性控制当我们尝试对JavaScript代码段进行模糊处理时，第一步就是开始重命名一些变量和函数，以阐明源代码。您只需将代码拆分为较小的代码块，然后开始在此处和此处重命名。在JavaScript中，我们可以检查函数名称是否已更改或保持相同的名称。或更准确地说，我们可以检查堆栈跟踪是否包含原始名称和原始顺序。使用arguments.callee.caller，我们可以创建堆栈跟踪，以保存先前执行的函数。我们可以使用此信息来生成一个哈希，该哈希将成为用于生成用于解密JavaScript其他部分的密钥的种子。这样，我们就可以对流的完整性进行隐式控制，因为如果重命名功能或要执行的功能顺序稍有不同，则创建的哈希将完全不同。如果哈希不同，则生成的密钥也将不同。如果密钥不同，则无法解密代码。为了更好地理解它，请参见下一个示例： 123456789101112131415161718192021function getCallStack() &#123; var stack = &quot;#&quot;, total = 0, fn =arguments.callee; while ( (fn = fn.caller) ) &#123; stack = stack + &quot;&quot; +fn.name; total++ &#125; return stack&#125;function test1() &#123; console.log(getCallStack());&#125;function test2() &#123; test1();&#125;function test3() &#123; test2();&#125;function test4() &#123; test3();&#125;test4(); 执行此代码时，您将看到字符串**#test1test2test3test4**。如果我们修改（我邀请您这样做）任何函数的名称，返回的字符串也将不同。我们可以使用该字符串计算安全哈希，然后将其用作种子，以得出用于解密其他代码块的密钥。有趣的是，如果由于密钥无效（分析人员更改了函数名称）而无法解密下一个代码块，则可以捕获异常并将执行流重定向到伪路径。 1VM50:10 #test1test2test3test4 请记住，此技巧需要与强大的混淆功能结合在一起才能使用。 隐式代码完整性控制 在“ 函数重新定义”部分的结尾，我们提到可以使用toString（）方法检索JavaScript中函数的代码。就像我们说过的那样，这对于检查函数是否已重新定义很有用，实际上，可以使用相同的想法来知道函数的代码是否被修改。 效果较差的方法是计算函数或代码块的哈希并将其与已知表进行比较。但是这种方法确实很愚蠢。一种更现实，更有效的方法可以重复使用我们之前在堆栈跟踪中使用的相同策略。我们可以计算代码块的哈希值，并将其用作解密其他代码块的密钥。 创建隐式完整性控件的最漂亮方法是在md5中使用冲突。基本上，我们可以创建在自己的函数中测试其自己的md5的函数。为了在功能内执行检查，我们需要进行碰撞处理（我们想创建类似的东西function(){ if (md5(arguments.callee.toString() === ‘‘) code_function; }。 该技术背后的概念与用于生成图像文件的概念相同，在自己的图片中显示了md5校验和。这是一个经典示例：显示自己的md5校验和的gif。 (注:本站的图片处理策略更改了图片md5值,点击查看原图=&gt; 显示自己的md5校验和的gif) 关于如何产生这种冲突，有大量的文章（甚至在PoC || GTFO中出现了一些示例），但是我阅读并可以复制的第一个文章是使用PHP编写的。您可以非常快速地预先计算生成碰撞所需的块。实际上，这是@cgvwzq创建的示例，通过这种方式检查了函数内容的完整性。 如前所述，我们需要对这种技术进行强力混淆。 代理对象(old,已弃用)代理对象是目前JavaScript中最有用的一个工具，这种对象可以帮助我们了解代码中的其他对象，包括修改其行为以及触发特定环境下的对象活动。比如说，我们可以创建一个嗲哩对象并跟踪每一次document.createElement调用，然后记录下相关信息： 123456789const handler = &#123; // Our hook to keep the track apply: function (target, thisArg, args)&#123; console.log(&quot;Intercepted a call tocreateElement with args: &quot; + args); return target.apply(thisArg, args) &#125;&#125; document.createElement= new Proxy(document.createElement, handler) // Create our proxy object withour hook ready to interceptdocument.createElement(&#x27;div&#x27;); 接下来，我们可以在控制台中记录下相关参数和信息： 1VM216:3 Intercepted a call tocreateElement with args: div 我们可以利用这些信息并通过拦截某些特定函数来调试代码，但是本文的主要目的是为了介绍反调试技术，那么我们如何检测“对方”是否使用了代理对象呢？其实这就是一场“猫抓老鼠”的游戏，比如说，我们可以使用相同的代码段，然后尝试调用toString方法并捕获异常： 123456//Call a &quot;virgin&quot; createElement:try &#123; document.createElement.toString();&#125;catch(e)&#123; console.log(&quot;I saw your proxy!&quot;);&#125; 信息如下： 1&quot;function createElement() &#123; [native code] &#125;&quot; 但是当我们使用了代理之后： 123456789101112131415//Then apply the hookconst handler = &#123; apply: function (target, thisArg, args)&#123; console.log(&quot;Intercepted a call tocreateElement with args: &quot; + args); return target.apply(thisArg, args) &#125;&#125;document.createElement= new Proxy(document.createElement, handler); //Callour not-so-virgin-after-that-party createElementtry &#123; document.createElement.toString();&#125;catch(e) &#123; console.log(&quot;I saw your proxy!&quot;);&#125; 没错，我们确实可以检测到代理： 1VM391:13 I saw your proxy! 我们还可以添加toString方法： 1234567891011121314const handler = &#123; apply: function (target, thisArg, args)&#123; console.log(&quot;Intercepted a call tocreateElement with args: &quot; + args); return target.apply(thisArg, args) &#125;&#125;document.createElement= new Proxy(document.createElement, handler);document.createElement= Function.prototype.toString.bind(document.createElement); //Add toString//Callour not-so-virgin-after-that-party createElementtry &#123; document.createElement.toString();&#125;catch(e) &#123; console.log(&quot;I saw your proxy!&quot;);&#125; 现在我们就没办法检测到了： 1&quot;function createElement() &#123; [native code] &#125;&quot; 代理对象异常把戏不能再使用了。幸运的是，我们仍然可以通过toString长度检测代理对象的使用。例如，document.createElement的大小为42（Chrome）： 12document.createElement.toString().length42 另一方面，当我们创建代理时，此值将更改： 1234567891011const handler = &#123; apply: function(target, thisArg, args) &#123; console.log(&quot;Intercepted call&quot;); return target.apply(thisArg, args); &#125;&#125;document.createElement = new Proxy(document.createElement, handler);document.createElement.toString().length29 因此，我们可以执行以下操作： 123456if (document.createElement.toString().length &lt; 30) &#123; console.log(&quot;I saw your proxy&quot;);&#125;else &#123; console.log(&quot;Not a proxy&quot;);&#125; 此技巧不能在windoww对象中使用，但仍然有用。 限制环境如引言中所述，我们想要做的一件事就是尝试检测代码是否在正确的环境中执行。我们所谓的“正确的环境”是： 该代码正在浏览器（不是仿真器，不是NodeJS等）中执行。 该代码正在指定给它的域/资源中执行（不是本地服务器） 例如，我们可以用来证明代码是否在本地执行的简单检查是： 1234// Pretty stupid idea found in commercial softwareif (location.hostname === &quot;localhost&quot; || location.hostname === &quot;127.0.0.1&quot; || location.hostname === &quot;&quot;) &#123; console.log(&quot;Don&#x27;t run me here!&quot;)&#125; 如果我们在本地html中运行此JavaScript代码段，则会看到以下消息： 1VM28:3 Don&#x27;t run me here! 按照这个想法，另一个检查选项是用于打开文档的处理程序（类似if (location.protocol == ‘file:’){…}），或者尝试通过HTTP请求进行测试，以确定是否有其他资源（图像，css等）可用。当然，所有这些方法都非常容易被绕过。 如果代码是在NodeJS中执行的（或者正如我们在本文中提到的：将流更改为伪造的路径），则可以避免执行代码。这很危险，但是我在野外看到使用NodeJS来解决JavaScript挑战并绕过反暴力缓解措施。我们可以尝试检测仅存在于浏览器上下文中的对象的存在： 12345678//Under NodeJS try &#123; console.log(window); &#125; catch(e)&#123; console.log(&quot;NodeJS detected!!!!&quot;); &#125; NodeJS detected!!!! 反之亦然：在NodeJS中，我们具有浏览器上下文中不存在的对象。 1234567891011//Under the browserconsole.log(global)VM104:1 Uncaught ReferenceError: global is not defined at &lt;anonymous&gt;:1:13//Under NodeJS console.log(global)&#123; console: Console &#123; log: [Function: bound log],... ... 我们可以搜索仅存在于浏览器中的大量元数据。我们可以检索到的一些此类想法可以在Panopticlick Project中看到。 相关文献javascript-antidebugging","categories":[{"name":"JavaScript","slug":"javascript","permalink":"https://mhuig.github.io/categories/javascript/"}],"tags":[{"name":"JavaScript","slug":"javascript","permalink":"https://mhuig.github.io/tags/javascript/"},{"name":"反调试","slug":"反调试","permalink":"https://mhuig.github.io/tags/%E5%8F%8D%E8%B0%83%E8%AF%95/"}]},{"title":"Python如何调用C","slug":"Python/Python如何调用C","date":"2020-02-24T07:45:30.000Z","updated":"2020-02-24T07:45:30.000Z","comments":true,"path":"posts/b6ffaac2.html","link":"","permalink":"https://mhuig.github.io/posts/b6ffaac2.html","excerpt":"Python语言特点：简单，明确，优雅，高效率，同时Python语言的可扩展性和可嵌入性很强，又被成为“胶水语言”。但是Python语言有一个最大的缺点，便是运行速度慢，所以当你对速度有要求时，你可以用C语言来编写你的关键代码，或者当你希望某些算法不公开时，也可以把你的程序用C编写，然后在你的Python程序中使用它们。本文将介绍在Python程序中如何调用C…","text":"Python语言特点：简单，明确，优雅，高效率，同时Python语言的可扩展性和可嵌入性很强，又被成为“胶水语言”。但是Python语言有一个最大的缺点，便是运行速度慢，所以当你对速度有要求时，你可以用C语言来编写你的关键代码，或者当你希望某些算法不公开时，也可以把你的程序用C编写，然后在你的Python程序中使用它们。本文将介绍在Python程序中如何调用C… 编写C语言代码一个简单的c语言程序，实现了两个整数的加法运算 12345#include &lt;stdio.h&gt;int sum(int a,int b)&#123; return a + b;&#125; 生成so库文件使用命令： 1gcc -fPIC -shared main.c -o lib.so so库文件不能跨平台使用，如果你在Windows下面生成的，便只能够在Windows下面使用，使用命令以后，生成后缀为.so的库文件 编写Python程序来调用C语言 把so库文件放入我们的Python项目中 使用ctypes库中的CDLL来加载库 lib_main = CDLL(‘so库文件路径’) 调用C sum_value = lib_main.sum(10, 20) 123456789# ctypes的库from ctypes import *# 加载so库lib_main = CDLL(&#x27;./lib.so&#x27;) # CDLL加载库sum_value = lib_main.sum(10, 20)print(sum_value) 最终得到结果30 ctypes库是Python提供的一个外部函数库，提供C语言兼容集中数据类型，可以允许调用C编译好的库，已下附上ctypes库官方文档：https://docs.python.org/3/library/ctypes.html","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"}]},{"title":"Npm更换源","slug":"web/npm更换源","date":"2020-02-23T11:02:43.000Z","updated":"2020-02-23T11:02:43.000Z","comments":true,"path":"posts/ba036091.html","link":"","permalink":"https://mhuig.github.io/posts/ba036091.html","excerpt":"由于npm的源在国外，所以国内用户使用起来有很多不方便，比如拖慢下载速度。","text":"由于npm的源在国外，所以国内用户使用起来有很多不方便，比如拖慢下载速度。 如何使用有很多方法来配置npm registry地址，下面根据不同情境列出几种比较常用的方法。以淘宝npm为例 临时使用1npm --registry https://registry.npm.taobao.org install express 持久使用1npm config set registry https://registry.npm.taobao.org 配置后可通过下面方式来验证是否成功： 1npm config get registry 或者 1npm info express 更换为淘宝npm源1npm install -g cnpm --registry=https://registry.npm.taobao.org 通过cnpm更新模块 1cnpm install expresstall express 使用官方镜像1npm config set registry https://registry.npmjs.org/","categories":[{"name":"npm","slug":"npm","permalink":"https://mhuig.github.io/categories/npm/"}],"tags":[{"name":"npm","slug":"npm","permalink":"https://mhuig.github.io/tags/npm/"}]},{"title":"LBS 球面距离公式","slug":"math/LBS 球面距离公式","date":"2020-02-23T01:40:32.000Z","updated":"2020-02-23T01:40:32.000Z","comments":true,"path":"posts/5e7ad437.html","link":"","permalink":"https://mhuig.github.io/posts/5e7ad437.html","excerpt":"","text":"维基百科推荐使用公式，理由是公式用到了大量余弦函数， 而两点间距离很短时（比如地球表面上相距几百米的两点），余弦函数会得出0.999…的结果， 会导致较大的舍入误差。而公式采用了正弦函数，即使距离很小，也能保持足够的有效数字。 以前采用三角函数表计算时的确会有这个问题，但经过实际验证，采用计算机来计算时，两个公式的区别不大。 稳妥起见，这里还是采用公式。 Haversine公式φφφφ⊿λ 其中 θθθ 为地球半径，可取平均值φ, φ 表示两点的纬度；λ 表示两点经度的差值。 距离计算函数下面就是计算球面间两点之间距离的函数。 12345678910111213141516171819202122from math import sin, asin, cos, radians, fabs, sqrt EARTH_RADIUS=6371 # 地球平均半径，6371km def hav(theta): s = sin(theta / 2) return s * s def get_distance_hav(lat0, lng0, lat1, lng1): \"用haversine公式计算球面两点间的距离。\" # 经纬度转换成弧度 lat0 = radians(lat0) lat1 = radians(lat1) lng0 = radians(lng0) lng1 = radians(lng1) dlng = fabs(lng0 - lng1) dlat = fabs(lat0 - lat1) h = hav(dlat) + cos(lat0) * cos(lat1) * hav(dlng) distance = 2 * EARTH_RADIUS * asin(sqrt(h)) return distance 相关文献LBS 球面距离公式","categories":[{"name":"Math","slug":"math","permalink":"https://mhuig.github.io/categories/math/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"Math","slug":"math","permalink":"https://mhuig.github.io/tags/math/"},{"name":"距离","slug":"距离","permalink":"https://mhuig.github.io/tags/%E8%B7%9D%E7%A6%BB/"}]},{"title":"NoSQL-Neo4j","slug":"NoSql/NoSQLNeo4j","date":"2020-02-09T02:41:51.000Z","updated":"2020-02-09T02:41:51.000Z","comments":true,"path":"posts/9b624d43.html","link":"","permalink":"https://mhuig.github.io/posts/9b624d43.html","excerpt":"NoSQL Neo4j PDF","text":"NoSQL Neo4j PDF GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"NoSQL","slug":"大数据/nosql","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/nosql/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"NoSQL","slug":"nosql","permalink":"https://mhuig.github.io/tags/nosql/"},{"name":"Neo4j","slug":"neo4j","permalink":"https://mhuig.github.io/tags/neo4j/"}]},{"title":"NoSQL-MongoDB","slug":"NoSql/NoSQLMongoDB","date":"2020-02-09T02:41:50.000Z","updated":"2020-02-09T02:41:50.000Z","comments":true,"path":"posts/ec477027.html","link":"","permalink":"https://mhuig.github.io/posts/ec477027.html","excerpt":"NoSQL MongoDB PDF","text":"NoSQL MongoDB PDF GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"NoSQL","slug":"大数据/nosql","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/nosql/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"NoSQL","slug":"nosql","permalink":"https://mhuig.github.io/tags/nosql/"},{"name":"MongoDB","slug":"mongodb","permalink":"https://mhuig.github.io/tags/mongodb/"}]},{"title":"NoSQL-HBase","slug":"NoSql/NoSQLHBase","date":"2020-02-09T02:41:49.000Z","updated":"2020-02-09T02:41:49.000Z","comments":true,"path":"posts/cdec63d.html","link":"","permalink":"https://mhuig.github.io/posts/cdec63d.html","excerpt":"NoSQL HBase PDF","text":"NoSQL HBase PDF GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"NoSQL","slug":"大数据/nosql","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/nosql/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"NoSQL","slug":"nosql","permalink":"https://mhuig.github.io/tags/nosql/"},{"name":"HBase","slug":"hbase","permalink":"https://mhuig.github.io/tags/hbase/"}]},{"title":"NoSQL-Cassandra","slug":"NoSql/NoSQLCassandra","date":"2020-02-09T02:41:48.000Z","updated":"2020-02-09T02:41:48.000Z","comments":true,"path":"posts/e3dcc811.html","link":"","permalink":"https://mhuig.github.io/posts/e3dcc811.html","excerpt":"NoSQL Cassandra PDF","text":"NoSQL Cassandra PDF GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"NoSQL","slug":"大数据/nosql","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/nosql/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"NoSQL","slug":"nosql","permalink":"https://mhuig.github.io/tags/nosql/"},{"name":"Cassandra","slug":"cassandra","permalink":"https://mhuig.github.io/tags/cassandra/"}]},{"title":"NoSQL","slug":"NoSql/NoSQL","date":"2020-02-09T02:41:47.000Z","updated":"2020-02-09T02:41:47.000Z","comments":true,"path":"posts/f0940727.html","link":"","permalink":"https://mhuig.github.io/posts/f0940727.html","excerpt":"NoSQL PDF","text":"NoSQL PDF GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"NoSQL","slug":"大数据/nosql","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/nosql/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"NoSQL","slug":"nosql","permalink":"https://mhuig.github.io/tags/nosql/"}]},{"title":"如何加密你的 Python 代码","slug":"Python/如何加密你的 Python 代码","date":"2020-02-05T05:08:17.000Z","updated":"2020-02-05T05:08:17.000Z","comments":true,"path":"posts/b190dcb.html","link":"","permalink":"https://mhuig.github.io/posts/b190dcb.html","excerpt":"讲述了如何通过修改 Python 解释器达到加解密 Python 代码的目的。","text":"讲述了如何通过修改 Python 解释器达到加解密 Python 代码的目的。 前言本文将首先介绍下现有源码加密方案的思路、方法、优点与不足，进而介绍如何通过定制 Python 解释器来达到更好地加解密源码的目的。 现有加密方案由于 Python 的动态特性和开源特点，导致 Python 代码很难做到很好的加密。社区中的一些声音认为这样的限制是事实，应该通过法律手段而不是加密源码达到商业保护的目的；而还有一些声音则是不论如何都希望能有一种手段来加密。于是乎，人们想出了各种或加密、或混淆的方案，借此来达到保护源码的目的。 常见的源码保护手段有如下几种： 发行 .pyc 文件 代码混淆 使用 py2exe 使用 Cython 下面来简单说说这些方案。 发行 .pyc 文件思路大家都知道，Python 解释器在执行代码的过程中会首先生成 .pyc 文件，然后解释执行 .pyc 文件中的内容。当然了，Python 解释器也能够直接执行 .pyc 文件。而 .pyc 文件是二进制文件，无法直接看出源码内容。如果发行代码到客户环境时都是 .pyc 而非 .py 文件的话，那岂不是能达到保护 Python 代码的目的？ 方法把 .py 文件编译为 .pyc 文件，是件非常轻松地事情，可不需要把所有代码跑一遍，然后去捞生成的 .pyc 文件。 事实上，Python 标准库中提供了一个名为 compileall 的库，可以轻松地进行编译。 执行如下命令能够将遍历 目录下的所有 .py 文件，将之编译为 .pyc 文件： 1python -m compileall &lt;src&gt; 然后删除 目录下所有 .py 文件就可以打包发布了： 1find &lt;src&gt; -name &#39;*.py&#39; -type f -print -exec rm &#123;&#125; \\; 优点 简单方便，提高了一点源码破解门槛 平台兼容性好，.py 能在哪里运行，.pyc 就能在哪里运行 不足 解释器兼容性差，.pyc 只能在特定版本的解释器上运行 有现成的反编译工具，破解成本低 python-uncompyle6 就是这样一款反编译工具，效果出众。 执行如下命令，即可将 .pyc 文件反编译为 .py 文件： 1uncompyle6 *compiled-python-file-pyc-or-pyo* 代码混淆如果代码被混淆到一定程度，连作者看着都费劲的话，是不是也能达到保护源码的目的呢？ 思路既然我们的目的是混淆，就是通过一系列的转换，让代码逐渐不那么让人容易明白，那就可以这样下手： 移除注释和文档。没有这些说明，在一些关键逻辑上就没那么容易明白了。 改变缩进。完美的缩进看着才舒服，如果缩进忽长忽短，看着也一定闹心。 在tokens中间加入一定空格。这就和改变缩进的效果差不多。 重命名函数、类、变量。命名直接影响了可读性，乱七八糟的名字可是阅读理解的一大障碍。 在空白行插入无效代码。这就是障眼法，用无关代码来打乱阅读节奏。 方法方法一：使用 oxyry 进行混淆http://pyob.oxyry.com/ 是一个在线混淆 Python 代码的网站，使用它可以方便地进行混淆。 假定我们有这样一段 Python 代码，涉及到了类、函数、参数等内容： 1234567891011121314151617181920212223# coding: utf-8class A(object): &quot;&quot;&quot; Description &quot;&quot;&quot; def __init__(self, x, y, default=None): self.z = x + y self.default = default def name(self): return &#x27;No Name&#x27;def always(): return Truenum = 1a = A(num, 999, 100)a.name()always() 经过 Oxyry 的混淆，得到如下代码： 12345678910111213class A (object ):#line:4 &quot;&quot;#line:7 def __init__ (O0O0O0OO00OO000O0 ,OO0O0OOOO0000O0OO ,OO0OO00O00OO00OOO ,OO000OOO0O000OOO0 =None ):#line:9 O0O0O0OO00OO000O0 .z =OO0O0OOOO0000O0OO +OO0OO00O00OO00OOO #line:10 O0O0O0OO00OO000O0 .default =OO000OOO0O000OOO0 #line:11 def name (O000O0O0O00O0O0OO ):#line:13 return &#x27;No Name&#x27;#line:14def always ():#line:17 return True #line:18num =1 #line:21a =A (num ,999 ,100 )#line:22a .name ()#line:23always () 混淆后的代码主要在注释、参数名称和空格上做了些调整，稍微带来了点阅读上的障碍。 方法二：使用 pyobfuscate 库进行混淆pyobfuscate 算是一个颇具年头的 Python 代码混淆库了，但却是“老当益壮”了。 对上述同样一段 Python 代码，经 pyobfuscate 混淆后效果如下： 123456789101112131415161718192021222324# coding: utf-8if 64 - 64: i11iIiiIiiif 65 - 65: O0 / iIii1I11I1II1 % OoooooooOO - i1IIiclass o0OO00 ( object ) : if 78 - 78: i11i . oOooOoO0Oo0O if 10 - 10: IIiI1I11i11 if 54 - 54: i11iIi1 - oOo0O0Ooo if 2 - 2: o0 * i1 * ii1IiI1i % OOooOOo / I11i / Ii1I def __init__ ( self , x , y , default = None ) : self . z = x + y self . default = default if 48 - 48: iII111i % IiII + I1Ii111 / ooOoO0o * Ii1I def name ( self ) : return &#x27;No Name&#x27; if 46 - 46: ooOoO0o * I11i - OoooooooOO if 30 - 30: o0 - O0 % o0 - OoooooooOO * O0 * OoooooooOOdef Oo0o ( ) : return True if 60 - 60: i1 + I1Ii111 - I11i / i1IIi if 40 - 40: oOooOoO0Oo0O / O0 % ooOoO0o + O0 * i1IIiI1Ii11I1Ii1i = 1Ooo = o0OO00 ( I1Ii11I1Ii1i , 999 , 100 )Ooo . name ( )Oo0o ( ) # dd678faae9ac167bc83abf78e5cb2f3f0688d3a3 相比于方法一，方法二的效果看起来更好些。除了类和函数进行了重命名、加入了一些空格，最明显的是插入了若干段无关的代码，变得更加难读了。 优点 简单方便，提高了一点源码破解门槛 兼容性好，只要源码逻辑能做到兼容，混淆代码亦能 不足 只能对单个文件混淆，无法做到多个互相有联系的源码文件的联动混淆 代码结构未发生变化，也能获取字节码，破解难度不大 使用 py2exe思路py2exe 是一款将 Python 脚本转换为 Windows 平台上的可执行文件的工具。其原理是将源码编译为 .pyc 文件，加之必要的依赖文件，一起打包成一个可执行文件。 如果最终发行由 py2exe 打包出的二进制文件，那岂不是达到了保护源码的目的？ 方法使用 py2exe 进行打包的步骤较为简便。 1.编写入口文件。本示例中取名为 hello.py： 1print &#x27;Hello World&#x27; 2.编写 setup.py： 1234from distutils.core import setupimport py2exesetup(console=[&#x27;hello.py&#x27;]) 3.生成可执行文件 1python setup.py py2exe 生成的可执行文件位于 dist\\hello.exe。 优点 能够直接打包成 exe，方便分发和执行 破解门槛比 .pyc 更高一些 不足 兼容性差，只能运行在 Windows 系统上 生成的可执行文件内的布局是明确、公开的，可以找到源码对应的 .pyc 文件，进而反编译出源码 使用 Cython思路虽说 Cython 的主要目的是带来性能的提升，但是基于它的原理：将 .py/.pyx 编译为 .c 文件，再将 .c 文件编译为 .so(Unix) 或 .pyd(Windows)，其带来的另一个好处就是难以破解。 方法使用 Cython 进行开发的步骤也不复杂。 1.编写文件 hello.pyx 或 hello.py： 12def hello(): print(&#x27;hello&#x27;) 2.编写 setup.py： 12345from distutils.core import setupfrom Cython.Build import cythonizesetup(name=&#x27;Hello World app&#x27;, ext_modules=cythonize(&#x27;hello.pyx&#x27;)) 3.编译为 .c，再进一步编译为 .so 或 .pyd： 1python setup.py build_ext --inplace 执行 python -c “from hello import hello;hello()” 即可直接引用生成的二进制文件中的 hello() 函数。 优点 生成的二进制 .so 或 .pyd 文件难以破解 同时带来了性能提升 不足 兼容性稍差，对于不同版本的操作系统，可能需要重新编译 虽然支持大多数 Python 代码，但如果一旦发现部分代码不支持，完善成本较高 定制 Python 解释器考虑前文所述的几个方案，均是从源码的加工入手，或多或少都有些不足。假设我们从解释器的改造入手，会不会能够更好的保护代码呢？ 由于发行商业 Python 程序到客户环境时通常会包含一个 Python 解释器，如果改造解释器能解决源码保护的问题，那么也是可选的一条路。 假定我们有一个算法，能够加密原始的 Python 代码，这些加密后代码随发行程序一起，可被任何人看到，却难以破解。另一方面，有一个定制好的 Python 解释器，它能够解密这些被加密的代码，然后解释执行。而由于 Python 解释器本身是二进制文件，人们也就无法从解释器中获取解密的关键数据。从而达到了保护源码的目的。 要实现上述的设想，我们首先需要掌握基本的加解密算法，其次探究 Python 执行代码的方式从而了解在何处进行加解密，最后禁用字节码用以防止通过 .pyc 反编译。 加解密算法对称密钥加密算法对称密钥加密（Symmetric-key algorithm）又称为对称加密、私钥加密、共享密钥加密，是密码学中的一类加密算法。这类算法在加密和解密时使用相同的密钥，或是使用两个可以简单地相互推算的密钥。 对称加密算法的特点是算法公开、计算量小、加密速度快、加密效率高。 常见的对称加密算法有：DES、3DES、AES、Blowfish、IDEA、RC5、RC6 等。 对称密钥加解密过程如下： 明文通过密钥加密成密文，密文也可通过相同的密钥解密为明文。 通过 openssl 工具，我们能够方便选择对称加密算法进行加解密。下面我们以 AES 算法为例，介绍其用法。 AES 加密指定密码进行对称加密 1openssl enc -aes-128-cbc -in test.py -out entest.py -pass pass:123456 指定文件进行对称加密 1openssl enc -aes-128-cbc -in test.py -out entest.py -pass file:passwd.txt 指定环境变量进行对称加密 1openssl enc -aes-128-cbc -in test.py -out entest.py -pass env:passwd AES 解密指定密码进行对称解密 1openssl enc -aes-128-cbc -d -in entest.py -out test.py -pass pass:123456 指定文件进行对称解密 1openssl enc -aes-128-cbc -d -in entest.py -out test.py -pass file:passwd.txt 指定环境变量进行对称解密 1openssl enc -aes-128-cbc -d -in entest.py -out test.py -pass env:passwd 非对称密钥加密算法密钥加密（英语：public-key cryptography，又译为公开密钥加密），也称为非对称加密（asymmetric cryptography），一种密码学算法类型，在这种密码学方法中，需要一对密钥，一个是私钥，另一个则是公钥。这两个密钥是数学相关，用某用户公钥加密后所得的信息，只能用该用户的私钥才能解密。 非对称加密算法的特点是算法强度复杂、安全性依赖于算法与密钥但是由于其算法复杂，而使得加密解密速度没有对称加密解密的速度快。 常见的对称加密算法有：RSA、Elgamal、背包算法、Rabin、D-H、ECC 等。 非对称密钥加解密过程如下： 明文通过公钥加密成密文，密文通过与公钥对应的私钥解密为明文。 通过 openssl 工具，我们能够方便选择非对称加密算法进行加解密。下面我们以 RSA 算法为例，介绍其用法。 生成私钥、公钥辅以 AES-128 算法，生成 2048 比特长度的私钥 1openssl genrsa -aes128 -out private.pem 2048 根据私钥来生成公钥 1openssl rsa -in private.pem -outform PEM -pubout -out public.pem RSA 加密使用公钥进行加密 1openssl rsautl -encrypt -in passwd.txt -inkey public.pem -pubin -out enpasswd.txt RSA 解密使用私钥进行解密 1openssl rsautl -decrypt -in enpasswd.txt -inkey private.pem -out passwd.txt 基于加密算法实现源码保护对称加密适合加密源码文件，而非对称加密适合加密密钥。如果将两者结合，就能达到加解密源码的目的。 在构建环境进行加密我们发行出去安装包中，源码应该是被加密过的，那么就需要在构建阶段对源码进行加密。加密的过程如下： 1.随机生成一个密钥。这个密钥实际上是一个用于对称加密的密码。 2.使用该密钥对源代码进行对称加密，生成加密后的代码。 3.使用公钥（生成方法见 非对称密钥加密算法）对该密钥进行非对称加密，生成加密后的密钥。 不论是加密后的代码还是加密后的密钥，都会放在安装包中。它们能够被用户看到，却无法被破译。而 Python 解释器该如何执行加密后的代码呢？ Python 解释器进行解密假定我们发行的 Python 解释器中内置了与公钥相对应的私钥，有了它就有了解密的可能。而由于 Python 解释器本身是二进制文件，所以不需要担心内置的私钥会被看到。解密的过程如下： 1.Python 解释器执行加密代码时需要被传入指示加密密钥的参数，通过这个参数，解释器获取到了加密密钥 2.Python 解释器使用内置的私钥，对该加密密钥进行非对称解密，得到原始密钥 3.Python 解释器使用原始密钥对加密代码进行对称解密，得到原始代码 4.Python 解释器执行这段原始代码 可以看到，通过改造构建环节、定制 Python 解释器的执行过程，便可以实现保护源码的目的。改造构建环节是容易的，但是如何定制 Python 解释器呢？我们需要深入了解解释器执行脚本和模块的方式，才能在特定的入口进行控制。 脚本、模块的执行与解密执行 Python 代码的几种方式为了找到 Python 解释器执行 Python 代码时的所有入口，我们需要首先执行 Python 解释器都能以怎样的方式执行代码。 直接运行脚本1python test.py 直接运行语句1python -c &quot;print &#39;hello&#39;&quot; 直接运行模块1python -m test 导入、重载模块123python&gt;&gt;&gt; import test # 导入模块&gt;&gt;&gt; reload(test) # 重载模块 直接运行语句 的方式接收的就是明文的代码，我们也无需对这种方式做额外处理。直接运行模块和导入、重载模块这两种方式在流程上是殊途同归的，所以接下来会一起来看。因此我们将分两种情况：运行脚本和加载模块来进一步探究各自的过程和解密方式。 运行脚本时解密运行脚本的过程Python 解释器在运行脚本时的代码调用逻辑如下： 12345678910 main WinMain[Modules&#x2F;python.c] [PC&#x2F;WinMain.c] \\ &#x2F; \\ &#x2F; \\ &#x2F; \\ &#x2F; \\ &#x2F; Py_Main [Moduls&#x2F;main.c] Python 解释器运行脚本的入口函数因操作系统而异，在 Linux/Unix 系统上，主入口函数是 Modules/python.c 中的 main 函数，在 Windows系统上，则是 PC/WinMain.c 中的 WinMain 函数。不过这两个函数最终都会调用 Moduls/main.c 中的 Py_Main 函数。 我们不妨来看看 Py_Main 函数中的相关逻辑： 1234567891011121314151617[Modules/Main.c]--------------------------------------intPy_Main(int argc, char **argv)&#123; if (command) &#123; // 处理 python -c &lt;command&gt; &#125; else if (module) &#123; // 处理 python -m &lt;module&gt; &#125; else &#123; // 处理 python &lt;file&gt; ... fp = fopen(filename, &quot;r&quot;); ... &#125; 处理和的部分我们暂且先不管，在处理文件（通过直接运行脚本的方式）的逻辑中，可以看到解释打开了文件，获得了文件指针。那么如果我们把这里的 fopen 换成是自定义的 decrypt_open 函数，这个函数用来打开一个加密文件，然后进行解密，并返回一个文件指针，这个指针指向解密后的文件。那么，不就可以实现解密脚本的目的了吗？ 自定义 decrypt_open我们不妨新增一个 Modules/crypt.c 文件，用来存放一些自定义的加解密函数。 decrypt_open 函数大概实现如下： 123456789101112131415161718192021222324[Modules/crypt.c]--------------------------------------/* 以解密方式打开文件 */FILE *decrypt_open(const char *filename, const char *mode)&#123; int plainlen = -1; char *plaintext = NULL; FILE *fp = NULL; if (aes_passwd == NULL) fp = fopen(filename, &quot;r&quot;); else &#123; plainlen = aes_decrypt(filename, aes_passwd, &amp;plaintext); // 如果无法解密，返回源文件描述符 if (plainlen &lt; 0) fp = fopen(filename, &quot;r&quot;); // 否则，转换为内存文件描述符 else fp = fmemopen(plaintext, plainlen, &quot;r&quot;); &#125; return fp;&#125; 这里的 aes_passwd 是一个全局变量，代表对称加密算法中的密钥。我们暂时假定已经获取该密钥了，后文会说明如何获得。而 aes_decrypt 是自定义的一个使用AES算法进行对称解密的函数，限于篇幅，此函数的实现不再贴出。 decrypt_open 逻辑如下： 判断是否获得了对称密钥，如果没获得，直接打开该文件并返回文件指针 如果获得了，则尝试使用对称算法进行解密 如果解密失败，可能就是一段非加密的脚本，直接打开该文件并返回文件指针 如果解密成功，我们通过解密后的内容创建一个内存文件对象，并返回该文件指针实现了上述这些函数后，我们就能够实现在直接运行脚本时，解密执行被加密代码的目的。 加载模块时解密加载模块的过程加载模块的逻辑主要实现在 Python/import.c 文件中，其过程如下： 1234567891011121314 Py_Main [Moduls&#x2F;main.c] | builtin___import__ RunModule | |PyImport_ImportModuleLevel &lt;----┐ PyImport_ImportModule | | | import_module_level └------- PyImport_Import | load_next builtin_reload | | import_submodule PyImport_ReloadModule | | find_module &lt;---------------------------┘ 通过 python -m 的方式来加载模块时，其入口函数是 Py_Main 函数 通过 import 的方式来加载模块时，其入口函数是 builtin___import__ 函数 通过 reload() 的方式来加载模块时，其入口函数是 builtin_reload 函数 但不论是哪种方式，最终都会调用 find_module 函数，我们看看这个函数中是否暗藏乾坤呢？ 1234567891011[Python/import.c]--------------------------------------static struct filedescr *find_module(char *fullname, char *subname, PyObject *path, char *buf, size_t buflen, FILE **p_fp, PyObject **p_loader)&#123; ... fp = fopen(buf, filemode); ...&#125; 我们在 find_module 函数中找到了打开文件的逻辑，如果直接改成前文实现的 decrypt_open，岂不是就能达成加载模块时解密的目的了？ 总体思路是这样的，但有个细节需要注意，buf 不一定就是 .py 文件，也可能是 .pyc 文件，我们只对 .py 文件做改动，则可以这么写： 12345678910111213141516[Python/import.c]--------------------------------------static struct filedescr *find_module(char *fullname, char *subname, PyObject *path, char *buf, size_t buflen, FILE **p_fp, PyObject **p_loader)&#123; ... if (fdp-&gt;type == PY_SOURCE) &#123; fp = decrypt_open(buf, filemode); &#125; else &#123; fp = fopen(buf, filemode); &#125; ...&#125; 经过上述改动，就实现了加载模块时解密的目的了。 支持指定密钥文件前文中还留有一个待解决的问题：我们一开始是假定解释器已获取到了密钥内容并存放在了全局变量 aes_passwd 中，那么密钥内容怎么获取呢？ 我们需要 Python 解释器能支持一个新的参数选项，通过它来指定已加密的密钥文件，然后再通过非对称算法进行解密，得到 aes_passed。 假定这个参数选项是 -k ，则可使用如 python -k enpasswd.txt 的方式来告知解释器加密密钥的文件路径。其实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[Modules/main.c]--------------------------------------/* 命令行选项，注意k:是新增的内容 */#define BASE_OPTS &quot;3bBc:dEhiJk:m:OQ:RsStuUvVW:xX?&quot;.../* Long usage message, split into parts &lt; 512 bytes */static char *usage_1 = &quot;\\...-k key : decrypt source file by using key file\\n\\...&quot;;...intPy_Main(int argc, char **argv)&#123; ... char *keyfilename = NULL; ... while ((c = _PyOS_GetOpt(argc, argv, PROGRAM_OPTS)) != EOF) &#123; ... case &#x27;k&#x27;: keyfilename = (char *)malloc(strlen(_PyOS_optarg) + 1); if (keyfilename == NULL) Py_FatalError( &quot;not enough memory to copy -k argument&quot;); strcpy(keyfilename, _PyOS_optarg); keyfilename[strlen(_PyOS_optarg)] = &#x27;\\0&#x27;; break; ... &#125; ... if (keyfilename != NULL) &#123; int passwdlen; char *passwd = NULL; passwdlen = rsa_decrypt(keyfilename, &amp;passwd); set_aes_passwd(passwd); if (passwdlen &lt; 0) &#123; fprintf(stderr, &quot;%s: parsing key file &#x27;%s&#x27; error\\n&quot;, argv[0], keyfilename); free(keyfilename); return 2; &#125; else &#123; free(keyfilename); &#125; &#125; ...&#125; 其逻辑如下： k:中的 k 表示支持 -k 选项；: 表示选项后跟一个参数，即这里的已加密密钥文件的路径 解释器在处理到 -k 参数时，获取其后所跟的文件路径，记录在 keyfilename 中 使用自定义的 rsa_decrypt 函数（限于篇幅，不列出如何实现的逻辑）对已加密密钥文件进行非对称解密，获得密钥的原始内容 将该密钥内容写入到 aes_passwd 中 由此，通过显示地指定已加密密钥文件，解释器获得了原始密钥，进而通过该密钥解密已加密代码，再执行原始代码。但是，这里面还潜藏着一个风险：执行代码的过程中会生成 .pyc 文件，通过它反编译出的 .py 文件是未加密的。换句话说，恶意用户可以通过这种手段绕过限制。所以，我们需要禁用字节码 禁用字节码不生成 .pyc 文件首先要做的就是不生成 .pyc 文件，这样，恶意用户就没法直接根据 .pyc 文件来得到源码。 我们知道，通过 -B 选项可以告知 Python 解释器不生成 .pyc 文件。既然定制的 Python 解释器就不生成 .pyc 我们干脆禁用这个选项： 123456789101112131415161718192021[Modules/main.c]--------------------------------------/* 命令行选项，注意移除了B */#define BASE_OPTS &quot;3bc:dEhiJm:OQ:RsStuUvVW:xX?&quot;.../* Long usage message, split into parts &lt; 512 bytes */static char *usage_1 = &quot;\\...//-B : don&#x27;t write .py[co] files on import; also PYTHONDONTWRITEBYTECODE=x\\n\\...&quot;;...intPy_Main(int argc, char **argv)&#123; ... // 不生成 py[co] Py_DontWriteBytecodeFlag++; ...&#125; 除此以外，Python 解释器还会从环境变量中获取是否不生成 .pyc 文件，因此也需要做处理： 123456789101112131415161718[Python/pythonrun.c]--------------------------------------voidPy_InitializeEx(int install_sigs)&#123; ... f ((p = Py_GETENV(&quot;PYTHONDEBUG&quot;)) &amp;&amp; *p != &#x27;\\0&#x27;) Py_DebugFlag = add_flag(Py_DebugFlag, p); if ((p = Py_GETENV(&quot;PYTHONVERBOSE&quot;)) &amp;&amp; *p != &#x27;\\0&#x27;) Py_VerboseFlag = add_flag(Py_VerboseFlag, p); if ((p = Py_GETENV(&quot;PYTHONOPTIMIZE&quot;)) &amp;&amp; *p != &#x27;\\0&#x27;) Py_OptimizeFlag = add_flag(Py_OptimizeFlag, p); // 移除对 PYTHONDONTWRITEBYTECODE 的处理 if ((p = Py_GETENV(&quot;PYTHONDONTWRITEBYTECODE&quot;)) &amp;&amp; *p != &#x27;\\0&#x27;) Py_DontWriteBytecodeFlag = add_flag(Py_DontWriteBytecodeFlag, p); ...&#125; 禁止访问字节码对象 co_code仅仅是不生成 .pyc 文件还是不够的，恶意用户已然可以访问对象的 co_code 属性来获取字节码，进而通过反编译的手段获取到源码。因此，我们也需要禁止用户访问字节码对象： 1234567891011121314151617181920[Objects/codeobject.c]--------------------------------------static PyMemberDef code_memberlist[] = &#123; &#123;&quot;co_argcount&quot;, T_INT, OFF(co_argcount), READONLY&#125;, &#123;&quot;co_nlocals&quot;, T_INT, OFF(co_nlocals), READONLY&#125;, &#123;&quot;co_stacksize&quot;,T_INT, OFF(co_stacksize), READONLY&#125;, &#123;&quot;co_flags&quot;, T_INT, OFF(co_flags), READONLY&#125;, // &#123;&quot;co_code&quot;, T_OBJECT, OFF(co_code), READONLY&#125;, &#123;&quot;co_consts&quot;, T_OBJECT, OFF(co_consts), READONLY&#125;, &#123;&quot;co_names&quot;, T_OBJECT, OFF(co_names), READONLY&#125;, &#123;&quot;co_varnames&quot;, T_OBJECT, OFF(co_varnames), READONLY&#125;, &#123;&quot;co_freevars&quot;, T_OBJECT, OFF(co_freevars), READONLY&#125;, &#123;&quot;co_cellvars&quot;, T_OBJECT, OFF(co_cellvars), READONLY&#125;, &#123;&quot;co_filename&quot;, T_OBJECT, OFF(co_filename), READONLY&#125;, &#123;&quot;co_name&quot;, T_OBJECT, OFF(co_name), READONLY&#125;, &#123;&quot;co_firstlineno&quot;, T_INT, OFF(co_firstlineno), READONLY&#125;, &#123;&quot;co_lnotab&quot;, T_OBJECT, OFF(co_lnotab), READONLY&#125;, &#123;NULL&#125; /* Sentinel */&#125;; 到此，一个定制的 Python 解释器完成了。 演示运行脚本通过 -k 选项执行已加密密钥文件，Python 解释器可以运行已加密和未加密的 Python 文件。 加载模块可以通过 -m 的方式加载已加密和未加密的模块，也可以通过 import 的方式来加载已加密和未加密的模块。 禁用字节码通过禁用字节码，我们达到以下效果： 不会生成 .pyc 文件 可以访问函数的 func_code 无法访问代码对象的 co_code，即本示例中的 f.func_code.co_code 无法使用dis模块来获取字节码 异常堆栈信息尽管代码是加密的，但是不会影响异常时的堆栈信息。 调试加密的代码也是允许调试的，但是输出的代码内容会是加密的，这正是我们所期望的。 思考 1.如何防止通过内存操作的方式找到对象的co_code? 2.如何进一步提升私钥被逆向工程探知的难度？ 3.如何能在调试并希望看到源码的时候看到? 参考文献5种方法，加密你的Python代码 如何加密你的Python 代码","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"解释器","slug":"python/解释器","permalink":"https://mhuig.github.io/categories/python/%E8%A7%A3%E9%87%8A%E5%99%A8/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"加解密","slug":"加解密","permalink":"https://mhuig.github.io/tags/%E5%8A%A0%E8%A7%A3%E5%AF%86/"},{"name":"解释器","slug":"解释器","permalink":"https://mhuig.github.io/tags/%E8%A7%A3%E9%87%8A%E5%99%A8/"},{"name":"源码保护","slug":"源码保护","permalink":"https://mhuig.github.io/tags/%E6%BA%90%E7%A0%81%E4%BF%9D%E6%8A%A4/"}]},{"title":"Windows安装gcc","slug":"win/windows安装gcc","date":"2020-02-05T04:57:02.000Z","updated":"2020-02-05T04:57:02.000Z","comments":true,"path":"posts/e6f6b883.html","link":"","permalink":"https://mhuig.github.io/posts/e6f6b883.html","excerpt":"最近测试一下windows上vs编译和gcc编译的区别，同时比较ubuntu上gcc编译的却别，主要在内存上，做了一个小测试，现在写下安装gcc的过程。","text":"最近测试一下windows上vs编译和gcc编译的区别，同时比较ubuntu上gcc编译的却别，主要在内存上，做了一个小测试，现在写下安装gcc的过程。 下载先去官网下载安装包，http://www.mingw.org， 进入官网找到download： 单击就可以直接下载了。 安装双击运行下载的exe，然后点install，然后就是下一步到底就行了，最后选择安装gcc-g++的就可以了。 注意下面这个要选中 其他需要的也可以自行选择，安装完之后，也可以通过安装目录下bin目录的 安装其他东西，可以自行去了解。 配置安装完成后就是配置环境变量了 然后打开控制台，输入: 1gcc -v 1gcc --version 我们可以写一个例子试一下，经典例子hello world出来吧！ 123456#include &lt;stdio.h&gt;int main()&#123; printf(&quot;Hello world!&quot;); return 0;&#125; 1gcc -o test main.cpp MinGW-w64Window系统下的MinGW，总是编译为32位代码。因为MinGW只支持32位代码。 Window系统下的MinGW-w64（例如安装了TDM-GCC，选择MinGW-w64），默认是编译为64位代码，包括在32位的Windows系统下。","categories":[{"name":"windows","slug":"windows","permalink":"https://mhuig.github.io/categories/windows/"},{"name":"gcc","slug":"windows/gcc","permalink":"https://mhuig.github.io/categories/windows/gcc/"}],"tags":[{"name":"windows","slug":"windows","permalink":"https://mhuig.github.io/tags/windows/"},{"name":"gcc","slug":"gcc","permalink":"https://mhuig.github.io/tags/gcc/"}]},{"title":"AES加解密","slug":"Python/AES加解密","date":"2020-02-03T05:14:17.000Z","updated":"2020-02-03T05:14:17.000Z","comments":true,"path":"posts/357dc334.html","link":"","permalink":"https://mhuig.github.io/posts/357dc334.html","excerpt":"AES加密解密实现","text":"AES加密解密实现 Python语言实现直接安装Crypto是不好使的。因为历史原因导致的比较混乱，引用外部博友的解释内容如下： pycrypto、pycrytodome和crypto是一个东西，crypto在python上面的名字是pycrypto，它是一个第三方库，但是已经停止更新三年了，所以不建议安装这个库；这个时候pycryptodome就来了，它是pycrypto的延伸版本，用法和pycrypto是一模一样的；所以，我现在告诉大家一种解决方法–直接安装：pip install pycryptodome但是，在使用的时候导入模块是有问题的，这个时候只要修改一个文件夹的名称就可以完美解决这个问题，Python\\Python36\\Lib\\site-packages，找到这个路径，下面有一个文件夹叫做crypto,将小写c改成大写C就ok了。 为了安装方便，可以直接使用下面的命令： 123pip install crypto pycryptodomepip uninstall crypto pycryptodomepip install pycryptodome 而如果你是linux环境，则直接安装pycryptodome即可： 1pip install pycryptodome 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import base64from Crypto.Cipher import AESdef pkcs7padding(text): bs = AES.block_size # 16 length = len(text) bytes_length = len(bytes(text, encoding=&#x27;utf-8&#x27;)) # tips：utf-8编码时，英文占1个byte，而中文占3个byte padding_size = length if(bytes_length == length) else bytes_length padding = bs - padding_size % bs # tips：chr(padding)看与其它语言的约定，有的会使用&#x27;\\0&#x27; padding_text = chr(padding) * padding return text + padding_textdef pkcs7unpadding(text): length = len(text) unpadding = ord(text[length-1]) return text[0:length-unpadding]def encrypt(key, content): &quot;&quot;&quot; AES加密 key,iv使用同一个 模式cbc 填充pkcs7 :param key: 密钥 :param content: 加密内容 :return: &quot;&quot;&quot; key_bytes = bytes(key, encoding=&#x27;utf-8&#x27;) iv = key_bytes cipher = AES.new(key_bytes, AES.MODE_CBC, iv) # 处理明文 content_padding = pkcs7padding(content) # 加密 encrypt_bytes = cipher.encrypt(bytes(content_padding, encoding=&#x27;utf-8&#x27;)) # 重新编码 result = str(base64.b64encode(encrypt_bytes), encoding=&#x27;utf-8&#x27;) return resultdef decrypt(key, content): &quot;&quot;&quot; AES解密 key,iv使用同一个 模式cbc 去填充pkcs7 :param key: :param content: :return: &quot;&quot;&quot; key_bytes = bytes(key, encoding=&#x27;utf-8&#x27;) iv = key_bytes cipher = AES.new(key_bytes, AES.MODE_CBC, iv) # base64解码 encrypt_bytes = base64.b64decode(content) # 解密 decrypt_bytes = cipher.decrypt(encrypt_bytes) # 重新编码 result = str(decrypt_bytes, encoding=&#x27;utf-8&#x27;) # 去除填充内容 result = pkcs7unpadding(result) return resultaes_key = &#x27;1234567812345678&#x27;# 加密source_en = &#x27;1111111111111111&#x27;encrypt_en = encrypt(aes_key, source_en)print(encrypt_en)# 解密decrypt_en = decrypt(aes_key, encrypt_en)print(decrypt_en)print(source_en == decrypt_en) C语言实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336#include &lt;stdio.h&gt;#include &lt;ctype.h&gt;void aes(char*, char*, char*, int);void aes_detail(int[4][4], int[4][4], int);void subBytes(int [4][4], int);void shiftRows(int [4][4], int);void mixColumns(int [4][4], int);void addRoundKey(int [4][4], int[4][4]);int aes_multiple(int, int);void keyExpansion(int key[4][4], int w[11][4][4]);int c2i(char );/** * S盒 */static const int S_BOX[16][16] = &#123; 0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5, 0x30, 0x01, 0x67, 0x2b, 0xfe, 0xd7, 0xab, 0x76, 0xca, 0x82, 0xc9, 0x7d, 0xfa, 0x59, 0x47, 0xf0, 0xad, 0xd4, 0xa2, 0xaf, 0x9c, 0xa4, 0x72, 0xc0, 0xb7, 0xfd, 0x93, 0x26, 0x36, 0x3f, 0xf7, 0xcc, 0x34, 0xa5, 0xe5, 0xf1, 0x71, 0xd8, 0x31, 0x15, 0x04, 0xc7, 0x23, 0xc3, 0x18, 0x96, 0x05, 0x9a, 0x07, 0x12, 0x80, 0xe2, 0xeb, 0x27, 0xb2, 0x75, 0x09, 0x83, 0x2c, 0x1a, 0x1b, 0x6e, 0x5a, 0xa0, 0x52, 0x3b, 0xd6, 0xb3, 0x29, 0xe3, 0x2f, 0x84, 0x53, 0xd1, 0x00, 0xed, 0x20, 0xfc, 0xb1, 0x5b, 0x6a, 0xcb, 0xbe, 0x39, 0x4a, 0x4c, 0x58, 0xcf, 0xd0, 0xef, 0xaa, 0xfb, 0x43, 0x4d, 0x33, 0x85, 0x45, 0xf9, 0x02, 0x7f, 0x50, 0x3c, 0x9f, 0xa8, 0x51, 0xa3, 0x40, 0x8f, 0x92, 0x9d, 0x38, 0xf5, 0xbc, 0xb6, 0xda, 0x21, 0x10, 0xff, 0xf3, 0xd2, 0xcd, 0x0c, 0x13, 0xec, 0x5f, 0x97, 0x44, 0x17, 0xc4, 0xa7, 0x7e, 0x3d, 0x64, 0x5d, 0x19, 0x73, 0x60, 0x81, 0x4f, 0xdc, 0x22, 0x2a, 0x90, 0x88, 0x46, 0xee, 0xb8, 0x14, 0xde, 0x5e, 0x0b, 0xdb, 0xe0, 0x32, 0x3a, 0x0a, 0x49, 0x06, 0x24, 0x5c, 0xc2, 0xd3, 0xac, 0x62, 0x91, 0x95, 0xe4, 0x79, 0xe7, 0xc8, 0x37, 0x6d, 0x8d, 0xd5, 0x4e, 0xa9, 0x6c, 0x56, 0xf4, 0xea, 0x65, 0x7a, 0xae, 0x08, 0xba, 0x78, 0x25, 0x2e, 0x1c, 0xa6, 0xb4, 0xc6, 0xe8, 0xdd, 0x74, 0x1f, 0x4b, 0xbd, 0x8b, 0x8a, 0x70, 0x3e, 0xb5, 0x66, 0x48, 0x03, 0xf6, 0x0e, 0x61, 0x35, 0x57, 0xb9, 0x86, 0xc1, 0x1d, 0x9e, 0xe1, 0xf8, 0x98, 0x11, 0x69, 0xd9, 0x8e, 0x94, 0x9b, 0x1e, 0x87, 0xe9, 0xce, 0x55, 0x28, 0xdf, 0x8c, 0xa1, 0x89, 0x0d, 0xbf, 0xe6, 0x42, 0x68, 0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16 &#125;;/** * 逆S盒 */static const int INVERSE_S_BOX[16][16] = &#123; 0x52, 0x09, 0x6a, 0xd5, 0x30, 0x36, 0xa5, 0x38, 0xbf, 0x40, 0xa3, 0x9e, 0x81, 0xf3, 0xd7, 0xfb, 0x7c, 0xe3, 0x39, 0x82, 0x9b, 0x2f, 0xff, 0x87, 0x34, 0x8e, 0x43, 0x44, 0xc4, 0xde, 0xe9, 0xcb, 0x54, 0x7b, 0x94, 0x32, 0xa6, 0xc2, 0x23, 0x3d, 0xee, 0x4c, 0x95, 0x0b, 0x42, 0xfa, 0xc3, 0x4e, 0x08, 0x2e, 0xa1, 0x66, 0x28, 0xd9, 0x24, 0xb2, 0x76, 0x5b, 0xa2, 0x49, 0x6d, 0x8b, 0xd1, 0x25, 0x72, 0xf8, 0xf6, 0x64, 0x86, 0x68, 0x98, 0x16, 0xd4, 0xa4, 0x5c, 0xcc, 0x5d, 0x65, 0xb6, 0x92, 0x6c, 0x70, 0x48, 0x50, 0xfd, 0xed, 0xb9, 0xda, 0x5e, 0x15, 0x46, 0x57, 0xa7, 0x8d, 0x9d, 0x84, 0x90, 0xd8, 0xab, 0x00, 0x8c, 0xbc, 0xd3, 0x0a, 0xf7, 0xe4, 0x58, 0x05, 0xb8, 0xb3, 0x45, 0x06, 0xd0, 0x2c, 0x1e, 0x8f, 0xca, 0x3f, 0x0f, 0x02, 0xc1, 0xaf, 0xbd, 0x03, 0x01, 0x13, 0x8a, 0x6b, 0x3a, 0x91, 0x11, 0x41, 0x4f, 0x67, 0xdc, 0xea, 0x97, 0xf2, 0xcf, 0xce, 0xf0, 0xb4, 0xe6, 0x73, 0x96, 0xac, 0x74, 0x22, 0xe7, 0xad, 0x35, 0x85, 0xe2, 0xf9, 0x37, 0xe8, 0x1c, 0x75, 0xdf, 0x6e, 0x47, 0xf1, 0x1a, 0x71, 0x1d, 0x29, 0xc5, 0x89, 0x6f, 0xb7, 0x62, 0x0e, 0xaa, 0x18, 0xbe, 0x1b, 0xfc, 0x56, 0x3e, 0x4b, 0xc6, 0xd2, 0x79, 0x20, 0x9a, 0xdb, 0xc0, 0xfe, 0x78, 0xcd, 0x5a, 0xf4, 0x1f, 0xdd, 0xa8, 0x33, 0x88, 0x07, 0xc7, 0x31, 0xb1, 0x12, 0x10, 0x59, 0x27, 0x80, 0xec, 0x5f, 0x60, 0x51, 0x7f, 0xa9, 0x19, 0xb5, 0x4a, 0x0d, 0x2d, 0xe5, 0x7a, 0x9f, 0x93, 0xc9, 0x9c, 0xef, 0xa0, 0xe0, 0x3b, 0x4d, 0xae, 0x2a, 0xf5, 0xb0, 0xc8, 0xeb, 0xbb, 0x3c, 0x83, 0x53, 0x99, 0x61, 0x17, 0x2b, 0x04, 0x7e, 0xba, 0x77, 0xd6, 0x26, 0xe1, 0x69, 0x14, 0x63, 0x55, 0x21, 0x0c, 0x7d &#125;;int RC[10] = &#123;0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36&#125;;int main()&#123; int method = 1;//1表示加密， 0表示解密 //待加密/解密文件存放路径 char * source_path = &quot;0.py&quot;; // 加密/解密后文件存放路径 char *des_path = &quot;1.py&quot;; // 32位16进制密钥 char * password = &quot;dd67f79831571c947d9e85b76a7f6835&quot;; aes(source_path, des_path, password, method); printf(&quot;success!!!!!!!!!!&quot;); method = 0;//1表示加密， 0表示解密 //待加密/解密文件存放路径 source_path = &quot;1.py&quot;; // 加密/解密后文件存放路径 des_path = &quot;2.py&quot;; aes(source_path, des_path, password, method); printf(&quot;success!!!!!!!!!!&quot;);&#125;void aes(char* source_path, char* des_path, char* password, int method)&#123; //将密钥转换成4*4数组 int p[4][4]; for (int m = 0; m &lt; 4; ++m) &#123; for (int i = 0; i &lt; 4; ++i) &#123; int indx = 4 * i + m; p[i][m] = 16 * c2i(password[indx]) + c2i(password[indx + 1]); &#125; &#125; FILE *file = fopen(source_path, &quot;r&quot;); //获取文件的指针 fseek(file, 0, SEEK_END); //移动文件的指针到文件结尾 int len = ftell(file); //获取文件的长度 rewind(file); //将文件指针移动回文件开始 // 如果文件长度不是128位（16字节）的整数倍，则补齐 int size = len; if (len % 16 != 0) &#123; size = (len / 16 + 1) * 16; &#125; unsigned char content[size]; //读取文件内容赋值给content fread(content, 1, len, file); for (int j = len; j &lt; size; ++j) &#123; content[j] = 0; &#125; fclose(file); //存储结果 unsigned char encry[size]; //将文件转换成16字节的int型数组加密、解密 for (int i = 0; i &lt; size / 16; ++i) &#123; int content_to_int[4][4]; for (int j = 0; j &lt; 4; ++j) &#123; for (int k = 0; k &lt; 4; ++k) &#123; content_to_int[j][k] = content[j * 4 + k + 16 * i]; &#125; &#125; aes_detail(content_to_int, p, method); for (int j = 0; j &lt; 4; ++j) &#123; for (int k = 0; k &lt; 4; ++k) &#123; encry[j * 4 + k + 16 * i] = content_to_int[j][k]; &#125; &#125; &#125; FILE *file1 = fopen(des_path, &quot;w&quot;); fwrite(encry, size, 1, file1); fflush(file1); fclose(file1);&#125;void aes_detail(int content[4][4], int password[4][4], int encode)&#123; int p[11][4][4]; keyExpansion(password, p); if (encode) &#123; addRoundKey(content, p[0]); for (int i = 1; i &lt;= 10; ++i) &#123; subBytes(content, encode); shiftRows(content, encode); if (i != 10) &#123; mixColumns(content, encode); &#125; addRoundKey(content, p[i]); &#125; &#125;else &#123; addRoundKey(content, p[10]); for (int i = 9; i &gt;= 0; --i) &#123; shiftRows(content, encode); subBytes(content, encode); addRoundKey(content, p[i]); if (i != 0) &#123; mixColumns(content, encode); &#125; &#125; &#125;&#125;void subBytes(int a[4][4], int encode)&#123; // encode 为1 代表字节替代，为0代表逆向字节替代 for (int i = 0; i &lt; 4; ++i) &#123; for (int j = 0; j &lt; 4; ++j) &#123; int temp = a[i][j]; int row = temp / 16; int column = temp % 16; if (encode) a[i][j] = S_BOX[row][column]; else a[i][j] = INVERSE_S_BOX[row][column]; &#125; &#125;&#125;void shiftRows(int a[4][4], int encode)&#123; //encode 为1代表行移位，为0代表逆向行移位 for (int i = 0; i &lt; 4; ++i) &#123; for (int j = 0; j &lt; i; ++j) &#123; if (encode) &#123; int temp = a[i][0]; a[i][0] = a[i][1]; a[i][1] = a[i][2]; a[i][2] = a[i][3]; a[i][3] = temp; &#125; else&#123; int temp = a[i][3]; a[i][3] = a[i][2]; a[i][2] = a[i][1]; a[i][1] = a[i][0]; a[i][0] = temp; &#125; &#125; &#125;&#125;void mixColumns(int a[4][4], int encode)&#123; //encode 为1代表列混淆，为0代表逆向列混淆 for (int i = 0; i &lt; 4; ++i) &#123; int temp0 = a[0][i]; int temp1 = a[1][i]; int temp2 = a[2][i]; int temp3 = a[3][i]; if (encode) &#123; a[0][i] = aes_multiple(temp0, 2) ^ aes_multiple(temp1, 3) ^ temp2 ^ temp3; a[1][i] = temp0 ^ (aes_multiple(temp1, 2)) ^ (temp2 ^ aes_multiple(temp2, 2)) ^ temp3; a[2][i] = temp0 ^ temp1 ^ (aes_multiple(temp2, 2)) ^ (temp3 ^ aes_multiple(temp3, 2)); a[3][i] = temp0 ^ (aes_multiple(temp0, 2)) ^ temp1 ^ temp2 ^ aes_multiple(temp3, 2); &#125;else&#123; a[0][i] = aes_multiple(temp0, 14) ^ aes_multiple(temp1, 11) ^ aes_multiple(temp2, 13) ^ aes_multiple(temp3, 9); a[1][i] = aes_multiple(temp0, 9) ^ aes_multiple(temp1, 14) ^ aes_multiple(temp2, 11) ^ aes_multiple(temp3, 13); a[2][i] = aes_multiple(temp0, 13) ^ aes_multiple(temp1, 9) ^ aes_multiple(temp2, 14) ^ aes_multiple(temp3, 11); a[3][i] = aes_multiple(temp0, 11) ^ aes_multiple(temp1, 13) ^ aes_multiple(temp2, 9) ^ aes_multiple(temp3, 14); &#125; &#125;&#125;void addRoundKey(int a[4][4], int k[4][4])&#123; // 由于用w[11][4][4]表示W[44]导致行列转置，所以在进行异或操作的时候应该是a[i，j] 异或 k[j,i] for (int i = 0; i &lt; 4; ++i) &#123; for (int j = 0; j &lt; 4; ++j) &#123; a[i][j] = a[i][j] ^ k[j][i]; &#125; &#125;&#125;//AES乘法计算int aes_multiple(int a, int le)&#123; int thr = le &amp; 0x8; int sec = le &amp; 0x4; int fir = le &amp; 0x2; int fir_mod = le % 2; int result = 0; if (thr)&#123; int b = a; for (int i = 1; i &lt;=3 ; ++i) &#123; b = b&lt;&lt;1; if (b &gt;= 256) b = b ^ 0x11b; &#125; b = b % 256; result = result ^ b; &#125; if (sec)&#123; int b = a; for (int i = 1; i &lt;=2 ; ++i) &#123; b = b&lt;&lt;1; if (b &gt;= 256) b = b ^ 0x11b; &#125; b = b % 256; result = result ^ b; &#125; if (fir)&#123; int b = a &lt;&lt; 1; if (b &gt;= 256) b = b ^ 0x11b; b = b % 256; result = result ^ b; &#125; if (fir_mod) result = result ^ a; return result;&#125;void keyExpansion(int key[4][4], int w[11][4][4])&#123; for (int i = 0; i &lt; 4; ++i) &#123; for (int j = 0; j &lt; 4; ++j) &#123; w[0][i][j] = key[j][i]; &#125; &#125; for (int i = 1; i &lt; 11; ++i)&#123; for (int j = 0; j &lt; 4; ++j) &#123; int temp[4]; if (j == 0)&#123; temp[0] = w[i-1][3][1]; temp[1] = w[i-1][3][2]; temp[2] = w[i-1][3][3]; temp[3] = w[i-1][3][0]; for (int k = 0; k &lt; 4; ++k) &#123; int m = temp[k]; int row = m / 16; int column = m % 16; temp[k] = S_BOX[row][column]; if (k == 0)&#123; temp[k] = temp[k] ^ RC[i-1]; &#125; &#125; &#125; else&#123; temp[0] = w[i][j-1][0]; temp[1] = w[i][j-1][1]; temp[2] = w[i][j-1][2]; temp[3] = w[i][j-1][3]; &#125; for (int l = 0; l &lt; 4; ++l) &#123; w[i][j][l] = w[i-1][j][l] ^ temp[l]; &#125; &#125; &#125;&#125;/*int isdigit(char ch) &#123; if (ch&gt;=&#x27;0&#x27;&amp;&amp;ch&lt;=&#x27;9&#x27;) &#123; return 1; &#125; else &#123; return 0; &#125;&#125;int isalpha(char ch) &#123; if ((ch&gt;=&#x27;a&#x27;&amp;&amp;ch&lt;=&#x27;z&#x27;)||(ch&gt;=&#x27;A&#x27;&amp;&amp;ch&lt;=&#x27;Z&#x27;)) &#123; return 1; &#125; else &#123; return 0; &#125;&#125;int isupper(char ch) &#123; if (ch&gt;=&#x27;A&#x27;&amp;&amp;ch&lt;=&#x27;Z&#x27;) &#123; return 1; &#125; else &#123; return 0; &#125;&#125;*///将字符转换为数值int c2i(char ch) &#123; // 如果是数字，则用数字的ASCII码减去48, 如果ch = &#x27;2&#x27; ,则 &#x27;2&#x27; - 48 = 2 if(isdigit(ch)) return ch - 48; // 如果是字母，但不是A~F,a~f则返回 if( ch &lt; &#x27;A&#x27; || (ch &gt; &#x27;F&#x27; &amp;&amp; ch &lt; &#x27;a&#x27;) || ch &gt; &#x27;z&#x27; ) return -1; // 如果是大写字母，则用数字的ASCII码减去55, 如果ch = &#x27;A&#x27; ,则 &#x27;A&#x27; - 55 = 10 // 如果是小写字母，则用数字的ASCII码减去87, 如果ch = &#x27;a&#x27; ,则 &#x27;a&#x27; - 87 = 10 if(isalpha(ch)) return isupper(ch) ? ch - 55 : ch - 87; return -1;&#125;","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"密码学","slug":"python/密码学","permalink":"https://mhuig.github.io/categories/python/%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"tags":[{"name":"AES","slug":"aes","permalink":"https://mhuig.github.io/tags/aes/"},{"name":"密码学","slug":"密码学","permalink":"https://mhuig.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"加解密","slug":"加解密","permalink":"https://mhuig.github.io/tags/%E5%8A%A0%E8%A7%A3%E5%AF%86/"}]},{"title":"WebSocket Maven配置模板","slug":"code/WebSocketmaven配置模板","date":"2020-01-12T05:59:18.000Z","updated":"2020-01-12T05:59:18.000Z","comments":true,"path":"posts/4a71123b.html","link":"","permalink":"https://mhuig.github.io/posts/4a71123b.html","excerpt":"maven配置模板","text":"maven配置模板 WebSocketTemplate源码 GitHub 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn&lt;/groupId&gt; &lt;artifactId&gt;WebSocketTest&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;cloudera&lt;/id&gt; &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;dependencies&gt; &lt;!-- WebSocket --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-websocket&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-messaging&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.2.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.miemiedev&lt;/groupId&gt; &lt;artifactId&gt;mybatis-paginator&lt;/artifactId&gt; &lt;version&gt;1.2.15&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySql --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.32&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.9&lt;/version&gt; &lt;/dependency&gt; &lt;!-- JSP相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.10.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/fastjson --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.41&lt;/version&gt; &lt;/dependency&gt; &lt;!-- junit--&gt; &lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.testng&lt;/groupId&gt; &lt;artifactId&gt;testng&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.3&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;minimizeJar&gt;true&lt;/minimizeJar&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- 配置Tomcat插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;path&gt;/&lt;/path&gt; &lt;port&gt;8080&lt;/port&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt;","categories":[{"name":"模板","slug":"模板","permalink":"https://mhuig.github.io/categories/%E6%A8%A1%E6%9D%BF/"},{"name":"maven","slug":"模板/maven","permalink":"https://mhuig.github.io/categories/%E6%A8%A1%E6%9D%BF/maven/"}],"tags":[{"name":"maven","slug":"maven","permalink":"https://mhuig.github.io/tags/maven/"},{"name":"模板","slug":"模板","permalink":"https://mhuig.github.io/tags/%E6%A8%A1%E6%9D%BF/"},{"name":"WebSocket","slug":"websocket","permalink":"https://mhuig.github.io/tags/websocket/"}]},{"title":"SSM Maven配置模板","slug":"code/SSM maven配置模板","date":"2020-01-12T05:59:17.000Z","updated":"2020-01-12T05:59:17.000Z","comments":true,"path":"posts/4a71133b.html","link":"","permalink":"https://mhuig.github.io/posts/4a71133b.html","excerpt":"maven配置模板","text":"maven配置模板 SSMTemplate源码 GitHub 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn&lt;/groupId&gt; &lt;artifactId&gt;WebSocketTest&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;cloudera&lt;/id&gt; &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;dependencies&gt; &lt;!-- Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.2.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.miemiedev&lt;/groupId&gt; &lt;artifactId&gt;mybatis-paginator&lt;/artifactId&gt; &lt;version&gt;1.2.15&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySql --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.32&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.9&lt;/version&gt; &lt;/dependency&gt; &lt;!-- JSP相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.10.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/fastjson --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.41&lt;/version&gt; &lt;/dependency&gt; &lt;!-- junit--&gt; &lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.testng&lt;/groupId&gt; &lt;artifactId&gt;testng&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.3&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;minimizeJar&gt;true&lt;/minimizeJar&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- 配置Tomcat插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;path&gt;/&lt;/path&gt; &lt;port&gt;8080&lt;/port&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt;","categories":[{"name":"模板","slug":"模板","permalink":"https://mhuig.github.io/categories/%E6%A8%A1%E6%9D%BF/"},{"name":"maven","slug":"模板/maven","permalink":"https://mhuig.github.io/categories/%E6%A8%A1%E6%9D%BF/maven/"}],"tags":[{"name":"maven","slug":"maven","permalink":"https://mhuig.github.io/tags/maven/"},{"name":"模板","slug":"模板","permalink":"https://mhuig.github.io/tags/%E6%A8%A1%E6%9D%BF/"},{"name":"SSM","slug":"ssm","permalink":"https://mhuig.github.io/tags/ssm/"}]},{"title":"Flink常用的算子","slug":"Filnk/Flink常用的算子","date":"2020-01-11T06:12:29.000Z","updated":"2020-01-11T06:12:29.000Z","comments":true,"path":"posts/714668f9.html","link":"","permalink":"https://mhuig.github.io/posts/714668f9.html","excerpt":"Flink 数据处理模型 Flink 算子 Operator","text":"Flink 数据处理模型 Flink 算子 Operator Flink 数据处理模型在 Flink 应用程序中，无论你的应用程序是批程序，还是流程序，都是下图这种模型，有数据源（source），有数据下游（sink） Source: 数据源 基于本地集合、基于文件、基于网络套接字 自定义的 source Apache kafka、RabbitMQ Transformation: 数据转换 Map / FlatMap / Filter / KeyBy / Reduce / Fold / Aggregations / Window / WindowAll / Union / Window join / Split / Select / Project Sink: 接收器 写入文件、打印出来、写入 Socket 、自定义的 Sink 自定义的 Sink Apache kafka、RabbitMQ、MySQL、ElasticSearch、Apache Cassandra、HDFS Flink 算子 OperatorMap获取一个元素并生成一个元素 FlatMap获取一个元素并生成零个、一个或多个元素 filter KeyByKeyBy 在逻辑上是基于 key 对流进行分区，相同的 Key 会被分到一个分区 AggregationsDataStream API 支持各种聚合， 这些函数可以应用于 KeyedStream 以获得 Aggregations 聚合 常用的方法有 min、minBy、max、minBy、sum max 和 maxBy 之间的区别在于 max 返回流中的最大值，但 maxBy 返回具有最大值的键， min 和 minBy 同理 WindowWindow 函数允许按时间或其他条件对现有 KeyedStream 进行分组 10 秒的时间窗口的和（聚合） 1socketStream.keyBy(0).window(Time.seconds(10)).sum(1) UnionUnion 函数将两个或多个数据流结合在一起, 这样后面在使用的时候就只需使用一个数据流就行了 1inputStream.union(inputStream1, inputStream2, ...) 123val socketStream = env.socketTextStream(&quot;localhost&quot;, 9000, &#x27;\\n&#x27;)val textStream = env.readTextFile(&quot;/word.txt&quot;)socketStream.union(textStream) Window Join通过一些 key 将同一个 window 的两个数据流 join 起来 12345stream.join(otherStream) .where(&lt;KeySelector&gt;) .equalTo(&lt;KeySelector&gt;) .window(&lt;WindowAssigner&gt;) .apply(&lt;JoinFunction&gt;) 1234inputStream.join(inputStream1) .where(0).equalTo(1) .window(Time.seconds(5)) .apply (new JoinFunction () &#123;...&#125;); Split根据条件将流拆分为两个或多个流 Select从拆分流中选择特定流，那么就得搭配使用 Select 算子 通常搭配Split算子一起使用","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Flink","slug":"大数据/flink","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"}],"tags":[{"name":"Flink","slug":"flink","permalink":"https://mhuig.github.io/tags/flink/"}]},{"title":"Flink Window","slug":"Filnk/Flink Window","date":"2020-01-11T01:12:29.000Z","updated":"2020-01-11T01:12:29.000Z","comments":true,"path":"posts/38a07d35.html","link":"","permalink":"https://mhuig.github.io/posts/38a07d35.html","excerpt":"什么是 Window？ Window 有什么作用？ Flink 中的三种Window","text":"什么是 Window？ Window 有什么作用？ Flink 中的三种Window Flink Window Demo 源码GitHub 什么是 Window？统计经过某红绿灯的汽车数量之和？ 假设在一个红绿灯处，统计通过此红绿灯的汽车数量 可以把汽车的经过看成一个流，无穷的流，不断有汽车经过此红绿灯，因此无法统计总共的汽车数量。但是，我们可以换一种思路，每隔 15 秒，我们都将与上一次的结果进行 sum 操作（滑动聚合） 这个结果似乎还是无法回答我们的问题，根本原因在于流是无界的，我们不能限制流，但可以在有一个有界的范围内处理无界的流数据。因此，我们需要换一个问题的提法：每分钟经过某红绿灯的汽车数量之和？ 这个问题，就相当于一个定义了一个 Window（窗口），Window 的界限是 1 分钟，且每分钟内的数据互不干扰，因此也可以称为翻滚（不重合）窗口，如下图： 再考虑一种情况，每 30 秒统计一次过去 1 分钟的汽车数量之和 此时，Window 出现了重合。这样，1 个小时内会有 120 个 Window。 Window 指定时间范围内的所有数据 滚动窗口 各个窗口之间的数据不重叠（不重复） 滑动窗口 各个窗口之间的数据重叠（重复） Window 有什么作用？通常来讲，Window 就是用来对一个无限的流设置一个有限的集合，在有界的数据集上进行操作的一种机制。Window 又可以分为基于时间（Time-based）的 Window 以及基于数量（Count-based）的 window。 Flink 中的三种 WindowFlink 在 KeyedStream（DataStream 的继承类） 中提供了下面几种 Window： 以时间驱动的 Time Window 以事件数量驱动的 Count Window 以会话间隔驱动的 Session Window Time Window 正如命名那样，Time Window 根据时间来聚合流数据。 例如：一分钟的时间窗口就只会收集一分钟的数据，并在一分钟过后对窗口中的所有数据应用于下一个算子。 在 Flink 中使用 Time Window 非常简单，输入一个时间参数，这个时间参数可以利用 Time 这个类来控制，如果事前没指定 TimeCharacteristic 类型的话，则默认使用的是 ProcessingTime 123dataStream.keyBy(1).timeWindow(Time.minutes(1)) //time Window 每分钟统计一次数量和.sum(1); 123dataStream.keyBy(1).timeWindow(Time.minutes(1), Time.seconds(30)) //隔 30s 统计过去1m和.sum(1); Count WindowApache Flink 还提供计数窗口功能，如果计数窗口的值设置的为 3 ，那么将会在窗口中收集 3 个事件，并在添加第 3 个事件时才会计算窗口中所有事件的值。 123dataStream.keyBy(1).countWindow(3) //统计每 3 个元素的数量之和.sum(1); 123dataStream.keyBy(1) .countWindow(4, 3) //每隔 3 个元素统计过去 4 个元素的数量之和.sum(1); Session WindowApache Flink 还提供了会话窗口，是什么意思呢？使用该窗口的时候你可以传入一个时间参数（表示某种数据维持的会话持续时长），如果超过这个时间，就代表着超出会话时长。 123dataStream.keyBy(1).window(ProcessingTimeSessionWindows.withGap(Time.seconds(5)))//表示如果 5s 内没出现数据则认为超出会话时长，然后计算这个窗口的和.sum(1);","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Flink","slug":"大数据/flink","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"}],"tags":[{"name":"Flink","slug":"flink","permalink":"https://mhuig.github.io/tags/flink/"}]},{"title":"CentOS7重启之后无法联网重启network发现报错","slug":"CentOS/CentOS7重启之后无法联网重启network发现报错","date":"2020-01-10T12:12:29.000Z","updated":"2020-01-10T12:12:29.000Z","comments":true,"path":"posts/5cc46d49.html","link":"","permalink":"https://mhuig.github.io/posts/5cc46d49.html","excerpt":"虚拟机里边的CentOS7重启之后无法联网，重启network发现报错。","text":"虚拟机里边的CentOS7重启之后无法联网，重启network发现报错。 解决方式：禁用NetworkManager 123systemctl stop NetworkManagersystemctl disable NetworkManager 然后重启网络服务，能正常联网了！ 1service network restart","categories":[{"name":"错误集锦","slug":"错误集锦","permalink":"https://mhuig.github.io/categories/%E9%94%99%E8%AF%AF%E9%9B%86%E9%94%A6/"},{"name":"CentOS7","slug":"错误集锦/centos7","permalink":"https://mhuig.github.io/categories/%E9%94%99%E8%AF%AF%E9%9B%86%E9%94%A6/centos7/"}],"tags":[{"name":"CentOS7","slug":"centos7","permalink":"https://mhuig.github.io/tags/centos7/"},{"name":"network","slug":"network","permalink":"https://mhuig.github.io/tags/network/"}]},{"title":"Flink 时间语义","slug":"Filnk/Flink 时间语义","date":"2020-01-10T07:12:29.000Z","updated":"2020-01-10T07:12:29.000Z","comments":true,"path":"posts/594433a.html","link":"","permalink":"https://mhuig.github.io/posts/594433a.html","excerpt":"Flink 的三种时间语义Flink Time使用场景","text":"Flink 的三种时间语义Flink Time使用场景 Flink的三种时间语义 Processing Time：事件被处理时机器的系统时间 Event Time：事件自身的时间 Ingestion Time：事件进入 Flink 的时间 Process Time事件处理时间 即事件被处理时机器的系统时间 特点 最简单的 Time 概念 最好的性能和最低的延迟 分布式和异步环境下，不能提供确定性（不能保证结果数据的准确性） 容易受到事件到达系统的速度(如消息队列)、事件在系统内操作流动的速度和中断的影响 Event Time事件自身的时间，一般就是数据本身携带的时间 特点 数据本身携带，时间取决于数据 事件到达Flink之前就已经确定 必须指定如何生成WaterMarks，用来表示Event Time进度的机制 无论事件什么时候到达或者其怎么排序，最后处理 Event Time 将产生完全一致和确定的结果 Ingestion Time事件进入Flink的时间 在数据源操作处（进入 Flink source 时），每个事件将进入 Flink 时当时的时间作为时间戳 特点 事件在进入数据源（Flink Source）时的时间作为时间戳（） 介于Event Time 和 Processing Time 之间 Time生成的位置 Flink Time使用场景Time的使用场景一般来说在生产环境中使用 Processing Time 和 Event Time 比较多，Ingestion Time 一般用的较少 Processing Time使用场景Processing Time使用场景 用户不关心事件时间，只关心这个时间窗口要有数据进来 Processing Time 的几种应用场景举例 淘宝双十一晚会大屏幕的下单总金额 Event Time使用场景Event Time使用场景 业务需求需要时间这个字段 Event Time 的几种应用场景举例 购物时先有下单事件、再有支付事件 机器异常检测出发的警告也需要具体的事件展示出来 商品广告及时精准推荐给用户依赖的就是用户在浏览器的时间段/频率/时长等信息 可能出现的情况影响事件到达不一定及时、乱序、延迟 网络抖动 服务可用性 消息队列的分区数据堆积 但是使用事件时间的话，就可能有这样的情况：数据源采集的数据往消息队列中发送时可能因为网络抖动、服务可用性、消息队列的分区数据堆积的影响而导致数据到达的不一定及时，可能会出现数据出现一定的乱序、延迟几分钟等，庆幸的是 Flink 支持通过 WaterMark 机制来处理这种延迟的数据如何设置 Time 策略？1234val env = StreamExecutionEnvironment.getExecutionEnvironmentenv.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime)env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)env.setStreamTimeCharacteristic(TimeCharacteristic.IngestionTime)","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Flink","slug":"大数据/flink","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"}],"tags":[{"name":"Flink","slug":"flink","permalink":"https://mhuig.github.io/tags/flink/"}]},{"title":"Windows环境下netcat的安装及使用","slug":"win/windows环境下netcat的安装及使用","date":"2020-01-10T02:10:47.000Z","updated":"2020-01-10T02:10:47.000Z","comments":true,"path":"posts/d70eaced.html","link":"","permalink":"https://mhuig.github.io/posts/d70eaced.html","excerpt":"windows环境下netcat的安装及使用","text":"windows环境下netcat的安装及使用 下载netcat下载地址：https://eternallybored.org/misc/netcat/ 解压文件夹将文件夹中的所有内容复制到C:\\Windows\\System32的文件夹下打开命令界面：Windows+R cmd 输入nc 命令即可.","categories":[{"name":"windows","slug":"windows","permalink":"https://mhuig.github.io/categories/windows/"},{"name":"netcat","slug":"windows/netcat","permalink":"https://mhuig.github.io/categories/windows/netcat/"}],"tags":[{"name":"windows","slug":"windows","permalink":"https://mhuig.github.io/tags/windows/"},{"name":"netcat","slug":"netcat","permalink":"https://mhuig.github.io/tags/netcat/"}]},{"title":"Flink实时处理Socket数据","slug":"Filnk/Flink实时处理Socket数据","date":"2020-01-10T01:53:11.000Z","updated":"2020-01-10T01:53:11.000Z","comments":true,"path":"posts/fc610c2d.html","link":"","permalink":"https://mhuig.github.io/posts/fc610c2d.html","excerpt":"Apache Flink是一个面向分布式数据流处理和批量数据处理的开源计算平台，提供支持流处理和批处理两种类型应用的功能Flink实时处理Socket数据","text":"Apache Flink是一个面向分布式数据流处理和批量数据处理的开源计算平台，提供支持流处理和批处理两种类型应用的功能Flink实时处理Socket数据 Flink Socket 源码GitHub 通过 Maven Archetype 创建项目创建项目1234mvn archetype:generate \\-DarchetypeGroupId=org.apache.flink \\-DarchetypeArtifactId=flink-quickstart-scala \\-DarchetypeVersion=1.9.0 通过以上Maven 命令进行项目创建的过程中，命令会交互式地提示用户对项目的 groupId、artifactId、version、package 等信息进行定义，且部分选项有默认值，直接回车即可。如图如果创建项目成功之后，客户端会有相应提示。 这里我们分别指定 groupId、artifactId 的信息分别如下，其余参数使用默认值 groupId：com.qst artifactId：flink-socket 检查项目对于使用 Maven 创建的项目，我们可以看到的项目结构如下所示 以上项目结构可以看出，该项目是一个 Scala 代码的项目，分别是 BatchJob.java 和StreamingJob.java 两个文件，分别赌赢 Flink 批量接口 DataSet 的实例代码和流式接口的实例代码。 将项目导入IDE项目经过上述步骤创建后，Flink 官网推荐使用 Intellij IDEA 进行后续项目开发。 编译项目项目经过上述步骤创建后，可以使用 Maven Command 命令 mvn clean package 对项目进行编译，编译完成后会在项目同级目录下生成 target/-.jar 文件，此jar文件就可以通过 Web 客户端提交到集群上运行。 开发环境配置这里我们使用官网推荐的 IntelliJ IDEA 作为应用的开发的 IDE。 下载 IntelliJ IDEA用户可以通过 IntelliJ IDEA 官方地址下载安装程序，根据操作系统选择相应的程序包进行安装。 安装 Scala Plugins安装完 IntelliJ IDEA 默认是不支持 Scala 开发环境的，需要安装 Scala 插件进行支持。一下说明在 IDEA 中进行 Scala 插件的安装。 打开 IDEA IDE 后，在 IntelliJ IDEA 菜单栏中选择 Preferences选项，然后选择 Plugins 子选项，最后在页面中选择 Marketplace，在搜索框中输入 Scala 进行搜索 在检索出来的选项列表中选择和安装 Scala插件  点击安装后重启IDE，Scala 编程环境即可生效 导入 Flink 项目 启动 IntelliJ IDEA，选择 Import Project，在文件选项框中选择创建好的项目，点击确定。 导入项目中选择 Import project from external mode 中的 Maven 后续选项使用默认值即可。 Flink Socket 应用程序编写 Flink Socket 应用程序代码123456789101112131415161718192021import org.apache.flink.streaming.api.scala._object StreamingJob &#123; def main(args: Array[String]) &#123; //设置环境变量 val env = StreamExecutionEnvironment.getExecutionEnvironment //指定数据源，读取socket val socketStream = env.socketTextStream(&quot;localhost&quot;, 9000, &#x27;\\n&#x27;) //对数据集指定转换操作逻辑 val count = socketStream .flatMap(_.toLowerCase.split(&quot;\\\\W+&quot;)) .filter(_.nonEmpty) .map((_, 1)) .keyBy(0) .sum(1) //将计算结果打印到控制台 count.print() //指定任务名称并触发流式任务 env.execute(&quot;Socket Stream&quot;) &#125;&#125; 在 IDE 中测试代码在代码文件中右键运行程序 此时会报如下错误 这时我们需要在 IDEA 的 Run/Debug Configuration 中将 “Include dependencies with “Provided” scope ”选项勾选，这时我们就可以在本地 IDE 运行了 在本地测试代码首先在命令行我们现在终端开启监听端口9000，在命令行中执行如下命令 1nc -l 9000 然后在 IDE 中 右键运行 StreamingJob 类的 main 方法，运行结果如下 在 Web 客户端中运行 Job首先在项目所在目录执行 mvn clean package 进行打包，在项目的 target 目录下生成一个 flink-socket-1.0-SNAPSHOT.jar 文件在命令行我们现在终端开启监听端口9000，在命令行中执行如下命令 1nc -l 9000 在浏览器中打开 Flink Web 监控页面，在左侧选择 Submit New Job 选项，点击 右上角的 Add New 选择我们编译好的 flink-socket-1.0-SNAPSHOT.jar 文件，点击 Submit 按钮提交Job 选择 Task Managers 选择列表中的对应 Job 点击 Stdout选项查看执行结果","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Flink","slug":"大数据/flink","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"}],"tags":[{"name":"Flink","slug":"flink","permalink":"https://mhuig.github.io/tags/flink/"}]},{"title":"Flink 编程模型","slug":"Filnk/Flink 编程模型","date":"2020-01-10T01:19:47.000Z","updated":"2020-01-10T01:19:47.000Z","comments":true,"path":"posts/4920f048.html","link":"","permalink":"https://mhuig.github.io/posts/4920f048.html","excerpt":"Apache Flink是一个面向分布式数据流处理和批量数据处理的开源计算平台，提供支持流处理和批处理两种类型应用的功能","text":"Apache Flink是一个面向分布式数据流处理和批量数据处理的开源计算平台，提供支持流处理和批处理两种类型应用的功能 Flink 环境准备 Flink编写程序需要依赖Java——JDK 项目使用Maven管理依赖——Maven 开发工具使用IDEA——IntelliJ IDEA JDK 8https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html Mavenhttp://maven.apache.org/download.cgi IntelliJ IDEAhttps://www.jetbrains.com/idea/download/#section=windows 下载Flinkhttps://flink.apache.org/downloads.html 安装Scala Plugins点击 File -&gt; Settings 菜单 , 或Ctrl + Alt + S 快捷键 . 打开设置面板 . 并切换到Plugins插件视图搜索 Scala 点击 Install Flink 项目模版基于Java的项目模版Flink WordCount Java 源码GitHub 在命令行使用maven创建Flink项目1234mvn archetype:generate \\-DarchetypeGroupId&#x3D;org.apache.flink \\-DarchetypeArtifactId&#x3D;flink-quickstart-java \\-DarchetypeVersion&#x3D;1.8.3 根据提示输入groupId、artifactId groupId：com.qst（所在公司、学校、组织官网网址的反写） artifactId：wordcount-java（项目名称） 项目目录结构 使用mvn命令创建项目后我们会得到一个如下结构的项目目录 编译项目 在项目所在目录执行“mvn clean package”命令对项目进行编译 这时maven会下载Flink项目需要的依赖包并编译项目 编译完成后产生一个 target/-.jar 基于 Scala 的项目模版1234mvn archetype:generate \\-DarchetypeGroupId&#x3D;org.apache.flink \\-DarchetypeArtifactId&#x3D;flink-quickstart-scala \\-DarchetypeVersion&#x3D;1.8.3 Flink WordCountFlink WordCount scala 源码GitHub 创建WrodCount项目在命令行使用maven创建Flink项目1234mvn archetype:generate \\-DarchetypeGroupId&#x3D;org.apache.flink \\-DarchetypeArtifactId&#x3D;flink-quickstart-scala \\-DarchetypeVersion&#x3D;1.8.3 根据提示在输入groupId、artifactId groupId：com.qst（所在公司、学校、组织官网网址的反写） artifactId：wordcount-scala（项目名称） 其它选项使用默认值 将项目导入IDEA 在IDEA中将 flink-wordcount 项目导入 选择 Import Project 找到 wordcount-scala 所在目录将项目导入IDEA 开发WordCount程序第一步：设定执行环境 运行Flink程序的第一步就是获得相应的执行环境，执行环境决定了程序在什么环境执行（本地/集群） 不同的运行环境也决定了程序的类型 批处理 ExecutionEnvironment 流处理 StreamExecutionEnvironment第二步：指定数据源 读取数据 定义执行环境后需要获得需要处理的数据，将外部数据转换成 DateStream 或 DataSet如下方法读取所示使用 readTextFile() 方法读取文件中的数据并转换成 DataStream 数据集1val source = env.readTextFile(&quot;/word.txt&quot;) 第三步：对数据集执行转换操作 Flink 中的 Transformation 操作通过不同的 Operator 来实现对数据的操作 Operator 内部通过 Function 接口完成数据处理 在 DataStream API 和 DataSet API 中提供了大量的转换操作flatMap、map、filter、keyBy 123456source.flatMap(line =&gt; line.toLowerCase.split(&quot;\\\\W+&quot;)) //将文本转换成数组.filter(_.length &gt; 0) //过滤空字符串.map(word =&gt; (word, 1)) //转换成 key-value 接口.keyBy(0) //按照指定字段（key）对数据进行分区.sum(1) //执行求和运算 第四步：输出结果经过转换后形成了最终结果，通常需要将结果数据输出到外部系统中 12345678source.flatMap(line =&gt; line.toLowerCase.split(&quot;\\\\W+&quot;)) //将文本转换成数组.filter(_.length &gt; 0) //过滤空字符串.map(word =&gt; (word, 1)) //转换成 key-value 接口.keyBy(0) //按照指定字段（key）对数据进行分区.sum(1) //执行求和运算.print() //输出到控制台//.writeAsText(&quot;/word_out.txt&quot;) //写入外部文件 第五步：触发程序执行所有的计算逻辑完成之后，需要调用 StreamExecutionEnvironment 的 execute 方法来触发应用程序的执行 12env.execute(&quot;Streaming Scala WordCount&quot;) 运行&amp;编译 WordCount 程序编译 WordCount 应用程序 在程序根目录执行“mvn clean package”命令进行编译 这时maven会下载Flink项目需要的依赖包并编译项目 编译完成后产生一个 target/-.jar","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Flink","slug":"大数据/flink","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"}],"tags":[{"name":"Flink","slug":"flink","permalink":"https://mhuig.github.io/tags/flink/"}]},{"title":"Flink 概述","slug":"Filnk/Flink 概述","date":"2020-01-09T06:58:17.000Z","updated":"2020-01-09T06:58:17.000Z","comments":true,"path":"posts/72cd4c87.html","link":"","permalink":"https://mhuig.github.io/posts/72cd4c87.html","excerpt":"Apache Flink是一个面向分布式数据流处理和批量数据处理的开源计算平台，提供支持流处理和批处理两种类型应用的功能","text":"Apache Flink是一个面向分布式数据流处理和批量数据处理的开源计算平台，提供支持流处理和批处理两种类型应用的功能 Flink是什么 Apache Flink是一个面向分布式数据流处理和批量数据处理的开源计算平台，提供支持流处理和批处理两种类型应用的功能 Apache Flink 的前身是柏林理工大学一个研究性项目， 在 2014 被 Apache 孵化器所接受，然后迅速地成为了Apache Software Foundation的顶级项目之一 代码主要由Java实现，部分代码是Scala Flink主要处理的场景就是流数据，批处理只是流数据的一个极限特例 数据类型有界流（bounded stream） 批量数据 有界流有定义流的开始，也有定义流的结束。有界流可以在摄取所有数据后再进行计算。有界流所有数据可以被排序，所以并不需要有序摄取。有界流处理通常被称为批处理。 有界流通常被称为有界数据集，数据的特点为有限不会改变的数据集合 常见的有界流 T+1的销售数据 11月的汽车销售数量 2018年全国电影票房 无界流（unbounded stream） 实时数据 有定义流的开始，但没有定义流的结束。它们会无休止地产生数据。无界流的数据必须持续处理，即数据被摄取后需要立刻处理。我们不能等到所有数据都到达再处理，因为输入是无限的，在任何时候输入都不会完成。处理无界数据通常要求以特定顺序摄取数据，例如事件发生的顺序，以便能够推断结果的完整性。 无界流通常被称为无穷数据集，数据的特点为无穷集成的数据集合 常见的无界流 用户与客户断的实时交互数据 应用时产生的日志 金融市场的实时交易记录 有界流和无界流 数据运算模型流式计算 只要数据一直在产生，计算就持续的进行 处理无界数据集批处理 在预定义的时间内运行计算，当计算完成时释放计算机资源 处理有界数据集 Flink组件栈 Deploy本地 Local 一个Java虚拟机 Single JVM（IDE中直接运行）集群 Cluster Standalone（start-cluster.sh） YARN MESOS K8s云 Cloud GCE google AWS/EC2 amazon MapR Aliyun Program Code Flink应用程序代码Job Client 任务执行起点，负责接受用户的程序代码、创建数据流、提交数据流给Job Manager、返回结果Job Manager 作业管理器协调管理程序Task Manager 从Job Manager接受需要部署的Task RuntimeRuntime层提供了支持Flink计算的全部核心实现，比如：支持分布式Stream处理、JobGraph到ExecutionGraph的映射、调度等等，为上层API层提供基础服务 API&amp;Libaries 核心APIs DataSet API：批处理，处理有界的数据集 DataStream API：流式处理，处理有界或无界的数据集Table API 以表为中心声明的DSL select、project、join、group-by、aggregate操作 支持与DataStream/DataSet混合使用SQL Flink提供的最高级抽象 支持与DataStream/DataSet混合使用面向批处理的Lib FlinkML 机器学习 Gelly 图处理面向流处理的类库 CEP 复杂事件处理 SQL-Like Table的关系操作Flink的基本编程模型 Source 数据输入 基于文件 基于本地集合 基于网络套接字 自定义：Apache Kafka、RabbitMQTransformation 数据转换 Map、FlatMap、Filter、Reduce、WindowSink 数据输出 写文件 打印 socket 自定义：Apache Kafka、HDFS、MySQL 大数据框架对比（流式/实时数据处理） 大数据Lamdba框架","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Flink","slug":"大数据/flink","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"}],"tags":[{"name":"Flink","slug":"flink","permalink":"https://mhuig.github.io/tags/flink/"}]},{"title":"删除注释自动化","slug":"code/删除注释自动化","date":"2019-12-29T03:14:41.000Z","updated":"2019-12-29T03:14:41.000Z","comments":true,"path":"posts/53d0a404.html","link":"","permalink":"https://mhuig.github.io/posts/53d0a404.html","excerpt":"实现批量删除 python java C CPP JS CSS html xml php sql 注释","text":"实现批量删除 python java C CPP JS CSS html xml php sql 注释 源码见GitHub PythonPython中的注释有单行注释和多行注释： 井号（#） Python中单行注释以 # 开头，例如： 123# 这是一个注释print(&quot;Hello, World!&quot;)多行注释用三个单引号 &#x27;&#x27;&#x27; 或者三个双引号 &quot;&quot;&quot; 将注释括起来，例如: 单引号（’’’） 1234567#!/usr/bin/python3 &#x27;&#x27;&#x27;这是多行注释，用三个单引号这是多行注释，用三个单引号 这是多行注释，用三个单引号&#x27;&#x27;&#x27;print(&quot;Hello, World!&quot;) 双引号（”””）1234567#!/usr/bin/python3 &quot;&quot;&quot;这是多行注释，用三个双引号这是多行注释，用三个双引号 这是多行注释，用三个双引号&quot;&quot;&quot;print(&quot;Hello, World!&quot;) java 单行注释 1// 注释内容 多行注释 12345/*... 注释内容....... 注释内容....... 注释内容....*/ 文档注释 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import java.io.*; /*** 这个类演示了文档注释* @author Ayan Amhed* @version 1.2*/public class SquareNum &#123; /** * This method returns the square of num. * This is a multiline description. You can use * as many lines as you like. * @param num The value to be squared. * @return num squared. */ public double square(double num) &#123; return num * num; &#125; /** * This method inputs a number from the user. * @return The value input as a double. * @exception IOException On input error. * @see IOException */ public double getNumber() throws IOException &#123; InputStreamReader isr = new InputStreamReader(System.in); BufferedReader inData = new BufferedReader(isr); String str; str = inData.readLine(); return (new Double(str)).doubleValue(); &#125; /** * This method demonstrates square(). * @param args Unused. * @return Nothing. * @exception IOException On input error. * @see IOException */ public static void main(String args[]) throws IOException &#123; SquareNum ob = new SquareNum(); double val; System.out.println(&quot;Enter value to be squared: &quot;); val = ob.getNumber(); val = ob.square(val); System.out.println(&quot;Squared value is &quot; + val); &#125;&#125; C语言 以//开始、以换行符结束的单行注释1const double pi = 3.1415926536; // pi是—个常量 以/开始、以/结束的块注释1int open( const char *name, int mode, … /* int permissions */ ); html 标签 123&lt;!--这是一段注释。--&gt;&lt;p&gt;这是一段普通的段落。&lt;/p&gt; php // 单行注释1// 单行注释 井号（#） 单行注释1# 单行注释 /* */多行注释块12345/*这是多行注释块它横跨了多行*/","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"删除注释","slug":"删除注释","permalink":"https://mhuig.github.io/tags/%E5%88%A0%E9%99%A4%E6%B3%A8%E9%87%8A/"}]},{"title":"适用于Linux的windows子系统","slug":"win/windows10下安装kali子系统","date":"2019-11-23T01:23:29.000Z","updated":"2019-11-23T01:23:29.000Z","comments":true,"path":"posts/f70539ce.html","link":"","permalink":"https://mhuig.github.io/posts/f70539ce.html","excerpt":"适用于Linux的windows子系统方法案例","text":"适用于Linux的windows子系统方法案例 开启wsl首先：为了win10能运行适用于Linux的windows子系统，我们需要开启wsl第一种方法： 开启wsl，开启步骤：按win + x进入Windows Power Shell，输入下面的命令开启， 1Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 开启后重启系统。 第二种 方法步骤 安装kali进入应用商店，搜索kali，直接安装 安装VIM1sudo apt-get install vim 更新源1vi &#x2F;etc&#x2F;apt&#x2F;sources.list 1234567891011121314151617181920#阿里云deb http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kali kali-rolling main non-free contribdeb-src http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kali kali-rolling main non-free contrib#清华大学deb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;kali kali-rolling main contrib non-freedeb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;kali kali-rolling main contrib non-free#浙大deb http:&#x2F;&#x2F;mirrors.zju.edu.cn&#x2F;kali kali-rolling main contrib non-freedeb-src http:&#x2F;&#x2F;mirrors.zju.edu.cn&#x2F;kali kali-rolling main contrib non-free#中科大deb http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;kali kali-rolling main non-free contribdeb-src http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;kali kali-rolling main non-free contrib#官方源deb http:&#x2F;&#x2F;http.kali.org&#x2F;kali kali-rolling main non-free contribdeb-src http:&#x2F;&#x2F;http.kali.org&#x2F;kali kali-rolling main non-free contrib 1sudo apt-get update &amp;&amp; sudo apt-get dist-upgrade 1apt-get install apt-transport-https 配置SSH在Linux子系统默认命令端输入，查看ip地址 1ifconfig 配置SSH服务 12sudo apt-get remove --purge openssh-server ## 先删sshsudo apt-get install openssh-server ## 在安装ssh 12sudo rm &#x2F;etc&#x2F;ssh&#x2F;ssh_config ## 删配置文件sudo service ssh --full-restart 修改sshd_config文件 1vi &#x2F;etc&#x2F;ssh&#x2F;sshd_config 将#PasswordAuthentication no的注释去掉，并且将NO修改为YES，kali中默认是yes 1PasswordAuthentication yes 将PermitRootLogin without-password修改为 1PermitRootLogin yes 使用xshell登录 上面命令执行完之后，在xshell中输入用户名和ip就可以通过xshell登录自己电脑的Linux。 配置永久解决方案 通过上面的方法，我们可以通过xshell登录自己电脑的Linux。但是断开之后重新开机，我们又需要重新配置SSH。因此，我们需要配置以下命令下，一劳永逸。 1sudo service ssh --full-restart ## 将该命令保存为service.sh，存在home目录下 配置好之后，下次开机，只需要在Linux子系统的默认终端运行sh service.sh命令后，关掉终端改用xshell登录即可。 图形界面123456789sudo apt-get install vnc4server tightvncserversudo apt-get install xrdpsudo sed -i &#39;s&#x2F;port&#x3D;3389&#x2F;port&#x3D;3390&#x2F;g&#39; &#x2F;etc&#x2F;xrdp&#x2F;xrdp.ini&#x2F;&#x2F;apt-get install kali-defaults kali-root-login desktop-base kde-fullsudo apt-get install xorgsudo apt-get install xfce4&#x2F;&#x2F;apt-get install kali-defaults kali-root-login desktop-base xfce4 xfce4-places-plugin xfce4-goodiessudo echo xfce4-session &gt;~&#x2F;.xsessionsudo service xrdp restart 安装工具包1apt install kali-linux-full win下关闭kali1net stop LxssManager ubuntu下神奇的多线程apt-get安装axel1sudo apt-get install axel 下载脚本apt-fast.sh下载地址 http://www.mattparnell.com/linux/apt-fast/apt-fast.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# !/bin/sh# apt-fast v0.03 by Matt Parnell http://www.mattparnell.com, this thing is fully open-source# if you do anything cool with it, let me know so I can publish or host it for you# contact me at admin@mattparnell.com# Special thanks# Travis/travisn000 - support for complex apt-get commands# Allan Hoffmeister - aria2c support# Abhishek Sharma - aria2c with proxy support# Richard Klien - Autocompletion, Download Size Checking (made for on ubuntu, untested on other distros)# Patrick Kramer Ruiz - suggestions - see Suggestions.txt# Sergio Silva - test to see if axel is installed, root detection/sudo autorun# Use this just like apt-get for faster package downloading.# Check for proper priveliges[ &quot;`whoami`&quot; = root ] || exec sudo &quot;$0&quot; &quot;$@&quot;# Test if the axel is installedif [ ! -x /usr/bin/axel ]then echo &quot;axel is not installed, perform this?(y/n)&quot; read ops case $ops in y) if apt-get install axel -y --force-yes then echo &quot;axel installed&quot; else echo &quot;unable to install the axel. you are using sudo?&quot; ; exit fi ;; n) echo &quot;not possible usage apt-fast&quot; ; exit ;; esacfi# If the user entered arguments contain upgrade, install, or dist-upgradeif echo &quot;$@&quot; | grep -q &quot;upgrade\\|install\\|dist-upgrade&quot;; then echo &quot;Working...&quot;; # Go into the directory apt-get normally puts downloaded packages cd /var/cache/apt/archives/; # Have apt-get print the information, including the URI&#x27;s to the packages # Strip out the URI&#x27;s, and download the packages with Axel for speediness # I found this regex elsewhere, showing how to manually strip package URI&#x27;s you may need...thanks to whoever wrote it apt-get -y --print-uris $@ | egrep -o -e &quot;(ht|f)tp://[^\\&#x27;]+&quot; &gt; apt-fast.list &amp;&amp; cat apt-fast.list | xargs -l1 axel -a # Perform the user&#x27;s requested action via apt-get apt-get $@; echo -e &quot;\\nDone! Verify that all packages were installed successfully. If errors are found, run apt-get clean as root and try again using apt-get directly.\\n&quot;;else apt-get $@;fi 安装apt-fast12sudo mv &#x2F;root&#x2F;apt-fast.sh &#x2F;usr&#x2F;bin&#x2F;apt-fastsudo chmod +x &#x2F;usr&#x2F;bin&#x2F;apt-fast 现在你已经可以使用apt-fast替代apt-get了试一下 123apt-fast updateapt-fast upgradeapt-fast install XXXXX 魔改axel设置脚本1sudo vim &#x2F;etc&#x2F;axelrc 找到 1num_connections &#x3D; 4 默认的4线程直接修改这个值例如：十线程 1num_connections &#x3D; 10 Linux下的vim配置文件1vi ~&#x2F;.vimrc 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180&quot; Vim config file.&quot; Global Settings: &#123;&#123;&#123;syntax on &quot; highlight syntaxfiletype plugin indent on &quot; auto detect file typeset nocompatible &quot; out of Vi compatible mode&quot;set number &quot; show line numberset numberwidth&#x3D;3 &quot; minimal culumns for line numbersset textwidth&#x3D;0 &quot; do not wrap words (insert)set nowrap &quot; do not wrap words (view)set showcmd &quot; show (partial) command in status lineset ruler &quot; line and column number of the cursor positionset wildmenu &quot; enhanced command completionset wildmode&#x3D;list:longest,full &quot; command completion modeset laststatus&#x3D;2 &quot; always show the status lineset mouse&#x3D; &quot; use mouse in all modeset foldenable &quot; fold linesset foldmethod&#x3D;marker &quot; fold as markerset noerrorbells &quot; do not use error bellset novisualbell &quot; do not use visual bellset t_vb&#x3D; &quot; do not use terminal bellset wildignore&#x3D;.svn,.git,*.swp,*.bak,*~,*.o,*.aset autowrite &quot; auto save before commands like :next and :makeset cursorlineset hidden &quot; enable multiple modified buffersset history&#x3D;1000 &quot; record recent used command historyset autoread &quot; auto read file that has been changed on diskset backspace&#x3D;indent,eol,start &quot; backspace can delete everythingset completeopt&#x3D;menuone,longest &quot; complete options (insert)set pumheight&#x3D;10 &quot; complete popup heightset scrolloff&#x3D;5 &quot; minimal number of screen lines to keep beyond the cursorset autoindent &quot; automatically indent new lineset cinoptions&#x3D;:0,l1,g0,t0,(0,(s &quot; C kind language indent optionsset clipboard+&#x3D;unnamed &quot; shared clipboardset noexpandtab &quot; do not use spaces instead of tabsset tabstop&#x3D;4 &quot; number of spaces in a tabset softtabstop&#x3D;4 &quot; insert and delete space of &lt;tab&gt;set shiftwidth&#x3D;4 &quot; number of spaces for indentset expandtab &quot; expand tabs into spacesset incsearch &quot; incremental searchset hlsearch &quot; highlight search matchset ignorecase &quot; do case insensitive matchingset smartcase &quot; do not ignore if search pattern has CAPSset nobackup &quot; do not create backup file&quot;set noswapfile &quot; do not create swap fileset backupcopy&#x3D;yes &quot; overwrite the original fileset encoding&#x3D;utf-8set termencoding&#x3D;utf-8set fileencoding&#x3D;utf-8set fileencodings&#x3D;gb2312,utf-8,gbk,gb18030set fileformat&#x3D;unixset background&#x3D;dark&quot;colorscheme SolarizedDark_modified&quot;colorscheme wombat_modified&quot; gui settingsif has(&quot;gui_running&quot;) set guioptions-&#x3D;T &quot; no toolbar set guioptions-&#x3D;r &quot; no right-hand scrollbar set guioptions-&#x3D;R &quot; no right-hand vertically scrollbar set guioptions-&#x3D;l &quot; no left-hand scrollbar set guioptions-&#x3D;L &quot; no left-hand vertically scrollbar autocmd GUIEnter * simalt ~x &quot; window width and height language messages zh_CN.utf-8 &quot; use chinese messages if hasendif&quot; Restore the last quit position when open file.autocmd BufReadPost * \\ if line(&quot;&#39;\\&quot;&quot;) &gt; 0 &amp;&amp; line(&quot;&#39;\\&quot;&quot;) &lt;&#x3D; line(&quot;$&quot;) | \\ exe &quot;normal g&#39;\\&quot;&quot; | \\ endif&quot;&#125;&#125;&#125;&quot; Key Bindings: &#123;&#123;&#123;let mapleader &#x3D; &quot;,&quot;let maplocalleader &#x3D; &quot;\\\\&quot;&quot; map : -&gt; &lt;space&gt;map &lt;Space&gt; :&quot; move between windowsnmap &lt;C-h&gt; &lt;C-w&gt;hnmap &lt;C-j&gt; &lt;C-w&gt;jnmap &lt;C-k&gt; &lt;C-w&gt;knmap &lt;C-l&gt; &lt;C-w&gt;l&quot; Don&#39;t use Ex mode, use Q for formattingmap Q gq&quot;make Y consistent with C and Dnnoremap Y y$&quot; toggle highlight trailing whitespacenmap &lt;silent&gt; &lt;leader&gt;l :set nolist!&lt;CR&gt;&quot; Ctrl-E to switch between 2 last buffersnmap &lt;C-E&gt; :b#&lt;CR&gt;&quot; ,e to fast finding files. just type beginning of a name and hit TABnmap &lt;leader&gt;e :e **&#x2F;&quot; Make shift-insert work like in Xtermmap &lt;S-Insert&gt; &lt;MiddleMouse&gt;map! &lt;S-Insert&gt; &lt;MiddleMouse&gt;&quot; ,n to get the next location (compilation errors, grep etc)nmap &lt;leader&gt;n :cn&lt;CR&gt;nmap &lt;leader&gt;p :cp&lt;CR&gt;&quot; Ctrl-N to disable search match highlightnmap &lt;silent&gt; &lt;C-N&gt; :silent noh&lt;CR&gt;&quot; center display after searchingnnoremap n nzznnoremap N Nzznnoremap * *zznnoremap # #zznnoremap g* g*zznnoremap g# g#z&quot;&#125;&#125;&#125;&quot; mrulet MRU_Window_Height &#x3D; 10nmap &lt;Leader&gt;r :MRU&lt;cr&gt;&quot; taglistlet g:Tlist_WinWidth &#x3D; 25let g:Tlist_Use_Right_Window &#x3D; 0let g:Tlist_Auto_Update &#x3D; 1let g:Tlist_Process_File_Always &#x3D; 1let g:Tlist_Exit_OnlyWindow &#x3D; 1let g:Tlist_Show_One_File &#x3D; 1let g:Tlist_Enable_Fold_Column &#x3D; 0let g:Tlist_Auto_Highlight_Tag &#x3D; 1let g:Tlist_GainFocus_On_ToggleOpen &#x3D; 1nmap &lt;Leader&gt;t :TlistToggle&lt;cr&gt;&quot; nerdtreelet g:NERDTreeWinPos &#x3D; &quot;right&quot;let g:NERDTreeWinSize &#x3D; 30let g:NERDTreeShowLineNumbers &#x3D; 1let g:NERDTreeQuitOnOpen &#x3D; 1nmap &lt;Leader&gt;f :NERDTreeToggle&lt;CR&gt;nmap &lt;Leader&gt;F :NERDTreeFind&lt;CR&gt;&quot;pastevmap &lt;C-c&gt; &quot;+ynmap &lt;C-v&gt; &quot;+pset pastetoggle&#x3D;&lt;F12&gt;&quot;C，C++ Java Compile and run by F5map &lt;F5&gt; :call CompileRunGcc()&lt;CR&gt;func! CompileRunGcc() exec &quot;w&quot; if &amp;filetype &#x3D;&#x3D; &#39;c&#39; exec &quot;!g++ % -o %&lt;&quot; exec &quot;! .&#x2F;%&lt;&quot; elseif &amp;filetype &#x3D;&#x3D; &#39;cpp&#39; exec &quot;!g++ % -o %&lt;&quot; exec &quot;! .&#x2F;%&lt;&quot; elseif &amp;filetype &#x3D;&#x3D; &#39;java&#39; exec &quot;!javac %&quot; exec &quot;!java %&lt;&quot; elseif &amp;filetype &#x3D;&#x3D; &#39;sh&#39; :!.&#x2F;% endifendfunc&quot;C,C++ debugmap &lt;F8&gt; :call Rungdb()&lt;CR&gt;func! Rungdb() exec &quot;w&quot; exec &quot;!g++ % -g -o %&lt;&quot; exec &quot;!gdb .&#x2F;%&lt;&quot;endfunc PS11PS1&#x3D;&#39;$&#123;debian_chroot:+($debian_chroot)&#125;\\[\\033[01;31m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ &#39; bashrc123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113# ~&#x2F;.bashrc: executed by bash(1) for non-login shells.# see &#x2F;usr&#x2F;share&#x2F;doc&#x2F;bash&#x2F;examples&#x2F;startup-files (in the package bash-doc)# for examples# If not running interactively, don&#39;t do anythingcase $- in *i*) ;; *) return;;esac# don&#39;t put duplicate lines or lines starting with space in the history.# See bash(1) for more optionsHISTCONTROL&#x3D;ignoreboth# append to the history file, don&#39;t overwrite itshopt -s histappend# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)HISTSIZE&#x3D;1000HISTFILESIZE&#x3D;2000# check the window size after each command and, if necessary,# update the values of LINES and COLUMNS.shopt -s checkwinsize# If set, the pattern &quot;**&quot; used in a pathname expansion context will# match all files and zero or more directories and subdirectories.#shopt -s globstar# make less more friendly for non-text input files, see lesspipe(1)#[ -x &#x2F;usr&#x2F;bin&#x2F;lesspipe ] &amp;&amp; eval &quot;$(SHELL&#x3D;&#x2F;bin&#x2F;sh lesspipe)&quot;# set variable identifying the chroot you work in (used in the prompt below)if [ -z &quot;$&#123;debian_chroot:-&#125;&quot; ] &amp;&amp; [ -r &#x2F;etc&#x2F;debian_chroot ]; then debian_chroot&#x3D;$(cat &#x2F;etc&#x2F;debian_chroot)fi# set a fancy prompt (non-color, unless we know we &quot;want&quot; color)case &quot;$TERM&quot; in xterm-color) color_prompt&#x3D;yes;;esac# uncomment for a colored prompt, if the terminal has the capability; turned# off by default to not distract the user: the focus in a terminal window# should be on the output of commands, not on the promptforce_color_prompt&#x3D;yesif [ -n &quot;$force_color_prompt&quot; ]; then if [ -x &#x2F;usr&#x2F;bin&#x2F;tput ] &amp;&amp; tput setaf 1 &gt;&amp;&#x2F;dev&#x2F;null; then # We have color support; assume it&#39;s compliant with Ecma-48 # (ISO&#x2F;IEC-6429). (Lack of such support is extremely rare, and such # a case would tend to support setf rather than setaf.) color_prompt&#x3D;yes else color_prompt&#x3D; fifiif [ &quot;$color_prompt&quot; &#x3D; yes ]; then PS1&#x3D;&#39;$&#123;debian_chroot:+($debian_chroot)&#125;\\[\\033[01;31m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ &#39;else PS1&#x3D;&#39;$&#123;debian_chroot:+($debian_chroot)&#125;\\u@\\h:\\w\\$ &#39;fiunset color_prompt force_color_prompt# If this is an xterm set the title to user@host:dircase &quot;$TERM&quot; inxterm*|rxvt*) PS1&#x3D;&quot;\\[\\e]0;$&#123;debian_chroot:+($debian_chroot)&#125;\\u@\\h: \\w\\a\\]$PS1&quot; ;;*) ;;esac# colored GCC warnings and errorsexport GCC_COLORS&#x3D;&#39;error&#x3D;01;31:warning&#x3D;01;35:note&#x3D;01;36:caret&#x3D;01;32:locus&#x3D;01:quote&#x3D;01&#39;# enable color support of ls and also add handy aliasesif [ -x &#x2F;usr&#x2F;bin&#x2F;dircolors ]; then test -r ~&#x2F;.dircolors &amp;&amp; eval &quot;$(dircolors -b ~&#x2F;.dircolors)&quot; || eval &quot;$(dircolors -b)&quot; alias ls&#x3D;&#39;ls --color&#x3D;auto&#39; alias dir&#x3D;&#39;dir --color&#x3D;auto&#39; alias vdir&#x3D;&#39;vdir --color&#x3D;auto&#39; alias grep&#x3D;&#39;grep --color&#x3D;auto&#39; alias fgrep&#x3D;&#39;fgrep --color&#x3D;auto&#39; alias egrep&#x3D;&#39;egrep --color&#x3D;auto&#39;fi# some more ls aliasesalias ll&#x3D;&#39;ls -l&#39;alias la&#x3D;&#39;ls -A&#39;alias l&#x3D;&#39;ls -la&#39;# Alias definitions.# You may want to put all your additions into a separate file like# ~&#x2F;.bash_aliases, instead of adding them here directly.# See &#x2F;usr&#x2F;share&#x2F;doc&#x2F;bash-doc&#x2F;examples in the bash-doc package.if [ -f ~&#x2F;.bash_aliases ]; then . ~&#x2F;.bash_aliasesfi# enable programmable completion features (you don&#39;t need to enable# this, if it&#39;s already enabled in &#x2F;etc&#x2F;bash.bashrc and &#x2F;etc&#x2F;profile# sources &#x2F;etc&#x2F;bash.bashrc).if ! shopt -oq posix; then if [ -f &#x2F;usr&#x2F;share&#x2F;bash-completion&#x2F;bash_completion ]; then . &#x2F;usr&#x2F;share&#x2F;bash-completion&#x2F;bash_completion elif [ -f &#x2F;etc&#x2F;bash_completion ]; then . &#x2F;etc&#x2F;bash_completion fifi","categories":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"},{"name":"kali","slug":"linux/kali","permalink":"https://mhuig.github.io/categories/linux/kali/"}],"tags":[{"name":"kali","slug":"kali","permalink":"https://mhuig.github.io/tags/kali/"}]},{"title":"特征向量和特征值的几何本质","slug":"ml/特征向量和特征值的几何本质","date":"2019-11-17T01:52:45.000Z","updated":"2019-11-17T01:52:45.000Z","comments":true,"path":"posts/f0765214.html","link":"","permalink":"https://mhuig.github.io/posts/f0765214.html","excerpt":"子矩阵的特征值编码了原矩阵特征向量的隐藏信息。","text":"子矩阵的特征值编码了原矩阵特征向量的隐藏信息。 λλλλ 为阶矩阵，若数λ和维非列向量满足λ，那么数λ称为的特征值，称为的对应于特征值λ的特征向量。 它的物理意义是： 一个矩阵乘以一个向量， 就相当于做了一个线性变换λ。 方向仍然保持不变， 只是拉伸或者压缩一定倍数λ。 特征向量和特征值的几何本质，其实就是： 空间矢量的旋转和缩放。 线性变换 A 对于特征空间只起到“扩张(或者压缩)”的作用（扩张后还是同样的特征空间） 求解特征向量按照传统解法： 计算特征多项式→求解特征值→求解齐次线性方程组，得出特征向量。 λλλ 全新的方法： λλλλ 其中: 为特征值λ对应特征向量的第个元素; λ 为矩阵的第个特征向量; 为矩阵的第个余子式,λ是该主子式的第个特征值. 通过删除原始矩阵的行和列，创建子矩阵。 子矩阵和原始矩阵的特征值组合在一起，就可以计算原始矩阵的特征向量。 简而言之，已知特征值，一个方程式就可以求得特征向量。 参考文献Eigenvectors from Eigenvalues Eigenvalues: the Rosetta Stone for Neutrino Oscillations in Matter","categories":[{"name":"Math","slug":"math","permalink":"https://mhuig.github.io/categories/math/"},{"name":"线性代数","slug":"math/线性代数","permalink":"https://mhuig.github.io/categories/math/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"}],"tags":[{"name":"Math","slug":"math","permalink":"https://mhuig.github.io/tags/math/"},{"name":"线性代数","slug":"线性代数","permalink":"https://mhuig.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"},{"name":"特征向量","slug":"特征向量","permalink":"https://mhuig.github.io/tags/%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/"}]},{"title":"Xrdp连接远程桌面","slug":"win/xrdp连接远程桌面","date":"2019-11-07T03:46:25.000Z","updated":"2019-11-07T03:46:25.000Z","comments":true,"path":"posts/ca7a6c92.html","link":"","permalink":"https://mhuig.github.io/posts/ca7a6c92.html","excerpt":"在和远程服务器交互的过程中，除了最基础的ssh链接以外，更多人喜欢图形界面的操作，当然ssh+x11可以实现部分图形的使用，但是依然需要敲命令行，虽然看起来很酷（zhuang）炫 （bi）但是图形界面依然是很多人的习惯。所以介绍下xrdp访问远程CentOS的处理步骤","text":"在和远程服务器交互的过程中，除了最基础的ssh链接以外，更多人喜欢图形界面的操作，当然ssh+x11可以实现部分图形的使用，但是依然需要敲命令行，虽然看起来很酷（zhuang）炫 （bi）但是图形界面依然是很多人的习惯。所以介绍下xrdp访问远程CentOS的处理步骤 安装epel库，否则无法安装xrdp 1yum install epel-release 安装 xrdp 1yum install xrdp 安装tigervnc-server 1yum install tigervnc-server 设置xrdp服务，开机自动启动 12systemctl start xrdpsystemctl enable xrdp 查看xrdp是否启动 12systemctl status xrdp.servicess -antup|grep xrdp 启动window rdp连接 附录 centos系统xrdp登录失败 .bashrc里面修改过PATH环境变量，添加过anaconda/bin 1vi ~&#x2F;.bashrc 最后添加 1conda deactivate 1source .bashrc","categories":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/tags/linux/"},{"name":"xrdp","slug":"xrdp","permalink":"https://mhuig.github.io/tags/xrdp/"}]},{"title":"Linux设置虚拟内存","slug":"Linux/Linux设置虚拟内存","date":"2019-11-07T02:53:04.000Z","updated":"2019-11-07T02:53:04.000Z","comments":true,"path":"posts/d53724bc.html","link":"","permalink":"https://mhuig.github.io/posts/d53724bc.html","excerpt":"虚拟内存配置","text":"虚拟内存配置 查看内存1free -m -m是显示单位为MB，-g单位GB 创建一个文件1touch &#x2F;root&#x2F;swapfile 使用dd命令，来创建大小为2G的文件swapfile: 1dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;&#x2F;root&#x2F;swapfile bs&#x3D;1M count&#x3D;2048 命令执行完需要等待一段时间 if表示input_file输入文件 of表示output_file输出文件 bs表示block_size块大小 count表示计数。 这里，我采用了数据块大小为1M，数据块数目为2048，这样分配的空间就是2G大小。 格式化交换文件1mkswap &#x2F;root&#x2F;swapfile 启用交换文件1swapon &#x2F;root&#x2F;swapfile 开机自动加载虚拟内存1vi &#x2F;etc&#x2F;fstab 在/etc/fstab文件中加入如下命令： 1&#x2F;root&#x2F;swapfile swap swap defaults 0 0 重启后生效1reboot 删除交换分区和交换文件如果要删除交换分区和交换文件，逆着上面的顺序操作: 先删除/etc/fstab文件中添加的交换文件行停用交换文件 1swapoff &#x2F;root&#x2F;swapfile 删除交换文件 1rm -fr &#x2F;root&#x2F;swapfile","categories":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/tags/linux/"},{"name":"虚拟内存","slug":"虚拟内存","permalink":"https://mhuig.github.io/tags/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/"}]},{"title":"视知觉整合的认知和神经机制研究","slug":"ml/视知觉整合的认知和神经机制研究","date":"2019-10-02T01:00:46.000Z","updated":"2019-10-02T01:00:46.000Z","comments":true,"path":"posts/63637a24.html","link":"","permalink":"https://mhuig.github.io/posts/63637a24.html","excerpt":"本文主要探讨知觉整合研究的新视角、轮廓线整合与纹理整合的神经机制以及知觉整合机制待解决的研究问题。","text":"本文主要探讨知觉整合研究的新视角、轮廓线整合与纹理整合的神经机制以及知觉整合机制待解决的研究问题。 知觉整合研究新视角结构极简取向知觉整合理论研究中最有目共睹的研究成果是格式塔思想，其最核心的原则是结构最简化原则，该思想可根据结构极简原则推测出格式塔知觉组织的其他特定原则。 格式塔心理学家认为理解知觉组织原则的关键在于将视网膜图像中的所有结构识别为视觉系统所敏感的知觉结构。 所谓结构极简原则，是指视觉系统将所有可获得信息组合为最简化的表征方式。 Leeuwenberg提出了一套思想框架，视觉系统通过选择编码语言的最短表达式来描述刺激的可能组织，结构信息理论所负载的最短代码或者是最少信息即最短表达式。 生态学取向结构信息理论能够解释一些知觉组织现象，但是他不能回答的一个重要问题是，为什么视觉系统对某些特定的结构更为敏感。 为什么视觉系统对某些特定的结构敏感性有利于有机体发现外部世界的结构。 知觉整合生态学研究视角有一个普适性的基本原理：不论视觉系统通过哪种方式进行整合，确定哪些部分属于同一整体的判定，其结果更可能是对符合外部世界的真实状态的反应。 Kruer和Sigman等人发现自然场景图像共线、共圆以及平行排布的统计学规律。 相关研究发现自然场景中相邻边缘间最主要的排布方式是对齐分布。首尾相连的线段对出现的概率要远远高于边对边的线段对，而且他们在空间比例不变性维度上有质的差异。 计算模型取向一般来说，计算模型至少包括两个相关的计算理论水平：宏观水平的整体框架以及微观水平的特定机制。 在宏观水平，计算理论的目标是在各种结构类型中找出最适合用于计算观察者所看到结构的整体框架，从而服务于知觉整合分析。 在微观层面，计算理论主要聚焦于具体的计算元素以及元素间的相互关系。与知觉整合相关的一个计算模型来自于环路循环连接网络：一个类似神经元元素组成的前馈和反馈连接的构型。 有研究者进一步推测，大脑的物理格式塔是基于分布在皮层中的动态电磁场。 所谓对称环路循环网络，是指网络中任意单位对之间的双向连接方向都有相同的权重。该网络总会收敛到均衡状态，使得信息约束满足各向同性至物理最小能量。 神经机制研究取向知觉整合神经机制研究的目标是探究促使知觉整合发生的实际神经活动的本质。 以往关于初级视皮层简单神经元本质的研究说明功能和生理学研究相互依赖的最好例子。Hubel和Wiesel在对猫的研究中发现外侧膝状体和初级视皮层中的单个神经元对简单的刺激属性（如朝向、运动方向等）具有选择性反应，他们将此解释为“特征探测器”（如线条、边缘探测器）。 当研究者在经典感受野内呈现偏好朝向的随机运动点模式时，他们发现神经元反应与运动方向的倒U关系（最优朝向反应最强，随着与最优朝向顺时针或逆时针偏转越来越大时，神经元反应越来越小）。 结果表明神经元不仅仅对其感受野内的基本刺激属性有反应，单个神经元活动会受到周围神经元的影响，提示着神经元还表征格式塔的相关属性。 轮廓线整合的神经机制研究者发现初级视皮层中的神经元不仅受到经典感受野内刺激的影响，还受到感受野外刺激的影响，单个神经元的活动会受到神经元之间相互作用的调节。虽然感受野外的线段本身不会诱发神经元的反应，但是当感受野外的线段与感受野内线段成共线关系时，神经元的反应会增强，而且感受野外线段数量越多，其发放强度越大。 Field等人根据其系列结果提出了“联合野”概念，他们的理论认为具有相似朝向选择性的神经元之间会具有选择性的相互作用，当这些神经元的排布方式违反这种规则时，这种促进和抑制的链接使得大脑完成对轮廓线信息的编码。 视觉系统在长期的进化发展过程中受到环境的交互影响，外界环境优化了视觉系统对环境中具有最高统计概率的刺激或刺激模式的反应机制。 研究者提出轮廓整合的神经实现基础是通过初级视皮层神经元间长距离兴奋性连接网络组成的“联合野”所实现的，然而最新的研究认为实现“联合野”还可能需要来自高级皮层自上而下对初级皮层的反馈作用。 纹理整合的神经机制神经元感受野中的纹理朝向与外周非经典感受野内的纹理朝向成正交关系时，会使得具有朝向信息的纹理边界线被“朝向对抗”神经元探测到。 目前“朝向对抗”神经元还没有被证实。 研究提示，各层级视皮层的前馈和水平投射可以对感受野内进行中心-外周比较，从而使得早期视皮层实现对较小空间范围内的同向抑制，较高级视皮层实现对较大空间范围内的同向抑制；反馈连接则将较高级皮层的区域填充信号反馈传回到低级视皮层实现同向兴奋。 研究者在多分层的层级视觉框架中通过多个空间尺度的特征地图架构了纹理分隔计算模型，实现了对纹理分隔任务的加工。 关于图形背景分割两阶段理论：该理论提出的第一个阶段是边界探测，纹理定义的边界线首先由具有相似偏好神经元间的相互抑制机制所探测到，该理论得到了实验证据的支持，研究者发现初级和较高级视皮质表层的神经元在很短时间内对图形边界的反应更强。第二个阶段是区域填充，该模型的区域填充过程始于存在于视觉系统多个空间尺度中的特征探测器，然后这些神经元会将信号反馈回早期视皮层的神经元，区域填充的结果是初级视皮层以活动增强的方式表征图像区域。研究者提出通过NMDA受体以及存在反馈链接并投射到第1层和第5层深层和表层神经元的树突共同作用实现将调制信号限制在激活强度最大的神经元群体，即图像表征区域。通过两种机制的共同作用，视觉系统通过对图形增强背景抑制的编码模式实现对图形背景的分割，从而实现对图形的知觉以及准确完成行为任务。 知觉整合机制待解决的研究问题视知觉整合的加工时程视知觉整合与注意麻醉情况下的无意识状态不能进行轮廓整合 自下而上与自上而下初级视皮层是否表征轮廓信息受限于知觉学习状态，只有当轮廓任务被学习之后，初级视皮层才能表征轮廓信息。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://mhuig.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"机器视觉","slug":"机器学习/机器视觉","permalink":"https://mhuig.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"视知觉","slug":"视知觉","permalink":"https://mhuig.github.io/tags/%E8%A7%86%E7%9F%A5%E8%A7%89/"}]},{"title":"视知觉整合","slug":"ml/视知觉整合","date":"2019-10-01T11:51:37.000Z","updated":"2019-10-01T11:51:37.000Z","comments":true,"path":"posts/4c2deb5e.html","link":"","permalink":"https://mhuig.github.io/posts/4c2deb5e.html","excerpt":"为了满足生存和生活的需要，人类需随时对外界环境中的客体信息进行高效地识别并与之产生交互。然而，由于视觉系统的固有组织属性，视觉系统必须提供一个强有力的机制快速地从海量的碎片式信息中准确识别出目标客体，这是视觉系统面临的一大挑战。","text":"为了满足生存和生活的需要，人类需随时对外界环境中的客体信息进行高效地识别并与之产生交互。然而，由于视觉系统的固有组织属性，视觉系统必须提供一个强有力的机制快速地从海量的碎片式信息中准确识别出目标客体，这是视觉系统面临的一大挑战。 视知觉整合（visual perceptual grouping）是指视觉系统将场景中属于同一客体或模式的离散元素组合并与其他客体或模式及背景区分的过程。 视知觉整合通常被认为是低级感觉加工和高级知觉加工（如客体、场景或事件加工等）间的功能桥梁。 视知觉整合与知觉组织当视网膜上的信息经由外侧膝状体首次进入初级视觉皮层时，神经元群组会对落在其感受野内的局部信号进行表征，如客体的轮廓线、纹理，在大多数情况下，同一个客体的不同部分会由具有不同调谐属性的神经元来表征。这是由于初级视觉皮层单个神经元的感受野很小且仅编码特定特征，当客体的大小大于单个神经元的感受野范围时，同一个客体的不同部分会由不同神经元来表征。比如，同一个客体的轮廓线会以线段的方式在具有不同朝向调谐属性的神经元来表征。 理论上这会严重破坏视觉信息的完整性，但事实上人们始终能知觉到排列有序的不同客体和背景信息，而不是一堆没有组织结构的局部信息的集合。 在这个过程中，视觉系统所面临的第一个挑战是，人们如何将属于同一个客体的元素从嘈杂的背景中提取整合并与其他客体及背景信息区分开来，即大脑如何完成知觉整合过程。 知觉整合对客体识别及其与环境交互都很重要。视觉系统的内在结构属性使得外界信息始于碎片式表征，然而我们最终知觉到的是排布有序的外部世界。 研究表明灵长类动物在刺激出现后150ms内即可识别出自然场景中的客体，一种观点认为这是因为视觉系统具有一套强有力的机制能高效完成整合。 视觉系统面临的最首要的知觉组织问题是判断视网膜上的哪些色块或者亮度块集合属于同一个或同一群客体。 在视觉系统加工的过程中，视觉系统首先需要将输入的离散信号准确地组织为后续信息加工的整体单元，即知觉组织加工。知觉组织是后续客体识别、注意分配等高级加工的基础。 研究历史1923年，韦德海默提出了知觉组织和知觉整合问题，试图阐述清楚知觉组织最根本的定律。最具有普世性的核心定律是所谓的极简定律，即大脑具有看见最简单形状的倾向。 20世纪五六十年代，视觉科学有了革命性的发展，尤其是单细胞电生理记录技术和计算模型的发展。Hubel和Wiesel等人发现初级视皮层的神经元对基本视觉特征（如特定方向的边缘）具有选择性反应。 Campbell等人使用线性系统方法对视觉加工过程进行建模并取得了很大进展。 当代知觉组织研究还发展出了新的间接测量方法，并从实验心理学中借鉴了标准的测量范式，在测量指标上，借鉴了心理物理学的阈值和无偏差反应指标等。 当代视知觉整合研究进展共同区域律共同区域律是指观察者会倾向于将同一个边界范围内的元素知觉为整体。 具体来说，当离散元素处于同一个连续同质的颜色或纹理空间区域内，或处于同一个边界线内，这些离散元素会基于共同区域进行整合，从而被知觉为整体。 如果两个元素都处于同一个图像区域内，那么同偶然出现在一个空间区域内的元素相比，这两个元素属于同一个客体的概率更高。 元素连通律当两个元素间存在第三个元素将其联通时，观察者会倾向于将这两个元素知觉为整体，即所谓的元素连通律。 同步律亮度或运动方向的共同性会诱发整合。 研究还发现即便元素运动方向不相关，元素间也能根据他们在出现时间上的同步性进行整合。 同步律是新的整合原则，不能被已知的视觉机制所解释，并存在争议。 当代知觉整合范式的研究进展早期知觉整合研究通过简单图片分别研究整合的关键因素，然而日常生活中的视觉场景并不是如此简单。 外部世界的典型视觉场景投影在视网膜形成二维图像，该图像由不同的亮度、颜色、形状、纹理等大量图形元素组成。其中边界线为客体的二维和三维形状提供了至关重要的信息。对于连通的没有受遮挡的客体来说，客体的边缘线在视网膜上投射为简单的闭合曲线，该曲线本身即足以形成完整的二维至三维形状知觉。 然而，视觉场景中经常存在遮挡，或存在客体与背景的亮度或颜色对比度低等情况，导致投射在视网膜上的轮廓线线段就已经变得碎片化了，而且因为视觉系统自身的固有结构属性，这种零碎的信息在大脑中呈碎片化表征。为完成识别，视觉系统需将轮廓线线段进行整合。此外，作为替代方案，区域整合也为也为客体识别提供了重要的线索，即视觉系统将轮廓线内部的刺激信息根据相似性原则进行整合。 不论是轮廓边界线还是区块纹理，信息首先进入初级视觉皮层都是碎片化式的表征，那么视觉系统面临的一个根本的重要任务是如何将这些信息重组成我们所感知到的排列有序的客体知觉。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://mhuig.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"机器视觉","slug":"机器学习/机器视觉","permalink":"https://mhuig.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"视知觉","slug":"视知觉","permalink":"https://mhuig.github.io/tags/%E8%A7%86%E7%9F%A5%E8%A7%89/"}]},{"title":"银行家算法","slug":"OS/银行家算法","date":"2019-09-26T08:24:03.000Z","updated":"2019-09-26T08:24:03.000Z","comments":true,"path":"posts/3bfd1783.html","link":"","permalink":"https://mhuig.github.io/posts/3bfd1783.html","excerpt":"银行家算法（Banker’s Algorithm）是一个避免死锁（Deadlock）的著名算法，是由艾兹格·迪杰斯特拉在1965年为T.H.E系统设计的一种避免死锁产生的算法。它以银行借贷系统的分配策略为基础，判断并保证系统的安全运行。","text":"银行家算法（Banker’s Algorithm）是一个避免死锁（Deadlock）的著名算法，是由艾兹格·迪杰斯特拉在1965年为T.H.E系统设计的一种避免死锁产生的算法。它以银行借贷系统的分配策略为基础，判断并保证系统的安全运行。 背景在银行中，客户申请贷款的数量是有限的，每个客户在第一次申请贷款时要声明完成该项目所需的最大资金量，在满足所有贷款要求时，客户应及时归还。银行家在客户申请的贷款数量不超过自己拥有的最大值时，都应尽量满足客户的需要。在这样的描述中，银行家就好比操作系统，资金就是资源，客户就相当于要申请资源的进程。 进程123456 Allocation Max Available ＡＢＣＤ ＡＢＣＤ ＡＢＣＤP1 ００１４ ０６５６ １５２０ P2 １４３２ １９４２ P3 １３５４ １３５６P4 １０００ １７５０ 我们会看到一个资源分配表，要判断是否为安全状态，首先先找出它的Need，Need即Max(最多需要多少资源)减去Allocation(原本已经分配出去的资源)，计算结果如下： 123456 NEEDＡＢＣＤ０６４２ ０５１００００２０７５０ 然后加一个全都为false的字段 12345FINISHfalsefalsefalsefalse 接下来找出need比available小的(千万不能把它当成4位数 他是4个不同的数) 123456 NEED AvailableＡＢＣＤ ＡＢＣＤ０６４２ １５２００５１０&lt;-０００２０７５０ P2的需求小于能用的，所以配置给他再回收 123456 NEED AvailableＡＢＣＤ ＡＢＣＤ０６４２ １５２０００００ ＋１４３２０００２－－－－－－－０７５０ ２９５２ 此时P2 FINISH的false要改成true(己完成) 12345FINISHfalsetruefalsefalse 接下来继续往下找，发现P3的需求为0002，小于能用的2952，所以资源配置给他再回收 123456 NEED AvailableＡＢＣＤ Ａ Ｂ Ｃ Ｄ０６４２ ２ ９ ５ ２００００ ＋１ ３ ５ ４００００－－－－－－－－－－０７５０ ３ 12 10 6 依此类推，做完P4→P1，当全部的FINISH都变成true时，就是安全状态。 安全和不安全的状态如果所有过程有可能完成执行（终止），则一个状态（如上述范例）被认为是安全的。由于系统无法知道什么时候一个过程将终止，或者之后它需要多少资源，系统假定所有进程将最终试图获取其声明的最大资源并在不久之后终止。在大多数情况下，这是一个合理的假设，因为系统不是特别关注每个进程运行了多久（至少不是从避免死锁的角度）。此外，如果一个进程终止前没有获取其它能获取的最多的资源，它只是让系统更容易处理。 基于这一假设，该算法通过尝试寻找允许每个进程获得的最大资源并结束（把资源返还给系统）的进程请求的一个理想集合，来决定一个状态是否是安全的。不存在这个集合的状态都是不安全的。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"死锁","slug":"死锁","permalink":"https://mhuig.github.io/tags/%E6%AD%BB%E9%94%81/"}]},{"title":"定时备份服务器/网站数据到Github私人仓库","slug":"CentOS/定时备份服务器-网站数据到Github私人仓库","date":"2019-09-24T14:07:00.000Z","updated":"2019-09-24T14:07:00.000Z","comments":true,"path":"posts/32ffa341.html","link":"","permalink":"https://mhuig.github.io/posts/32ffa341.html","excerpt":"现在Github被微软收购后，私人仓库已经开始免费了，然后就可以拿来折腾下了，让其充分发挥下作用，这里我们可以用来备份下网站或者服务器一些数据。","text":"现在Github被微软收购后，私人仓库已经开始免费了，然后就可以拿来折腾下了，让其充分发挥下作用，这里我们可以用来备份下网站或者服务器一些数据。 配置Git SSH密钥由于本地Git仓库和GitHub仓库之间的传输是通过SSH加密的，所以必须要让github仓库认证你SSH key，在操作之前，需要先在服务器上生成SSH key。 我们先去根目录下使用命令： 12cd ~ssh-keygen -t rsa 这里会要你命名密匙名称(这里建议使用默认名称)，然后连续按几次Enter，这时候会在/root/.ssh文件夹生成2个ssh密钥，然后我们查看公钥id_rsa.pub。 1cat ~&#x2F;.ssh&#x2F;id_rsa.pub 查看后，再复制下公钥，然后打开Github官网，进入 https://github.com/settings/ssh/new ，Title随便填，然后Key填入刚刚复制的密匙，最后点击Add SSH Key添加即可。 建立私人仓库我们需要先访问 https://github.com/new ，新建一个仓库用来存放备份文件，名称自己随意，记得下面一定要勾选Private，也就是私人仓库。 配置本地仓库由于博主是用来备份网站，所以需要备份文件夹为网站根目录/alidata/，也就是把该文件夹定为本地仓库，使用命令： 12345678#进入需要备份的文件夹cd &#x2F;alidata&#x2F;#安装gityum install git#初始化你的github仓库git init#关联到远程github仓库git remote add origin git@github.com:MHuiG&#x2F;BackupWebSite.git 关联仓库的时候，后面可以用HTTPS链接也可以用SSH，这里强烈建议选择SSH，安全性很高。 初次备份1234567891011#进入备份的文件夹cd &#x2F;alidata&#x2F;#忽略大于50.00 MB文件find . -size +50M&gt;.gitignoresed -i &#39;s&#x2F;.&#x2F;&#x2F;&#39; .gitignore#把目录下所有文件更改状况提交到暂存区，包括增，删，改。git add -A#提交更改的说明，说明随意了，这里为BackupWebSitegit commit -m &quot;BackupWebSite&quot;#开始推送到Githubgit push -u origin master 推送的时候可能会提示The authenticity of host ‘github.com’ can’t be established.信息，直进yes即可。然后可以看到仓库的备份文件了。 设置定时备份在根目录先新建一个bash脚本： 1nano ~/gitback.sh 代码如下： 123456789101112#!/bin/bash#进入到网站根目录，记得修改为自己的站点cd /alidata/#将数据库导入到该目录，这里以mysql为例，passwd为数据库密码，all.sql为备份的数据库文件mysqldump -uroot -ppasswd --events --all-databases&gt;all.sql#忽略大于50.00 MB文件find . -size +50M&gt;.gitignoresed -i &#x27;s/.//&#x27; .gitignoregit add -Agit commit -m &quot;BackupWebSite&quot;git push -u origin master 然后编辑好了后，使用ctrl+x，y保存退出。再测试下脚本，使用命令 1bash ~&#x2F;gitback.sh 脚本没问题的话，再设置为每天05:15执行一次： 1234#并将运行日志输出到根目录的siteback.log文件echo &quot;15 05 * * * bash ~&#x2F;gitback.sh &gt; ~&#x2F;siteback.log 2&gt;&amp;1 &amp;&quot; &gt; bt.croncrontab bt.cronrm -rf bt.cron 最后使用命令查看添加成功。 1crontab -l 附录crontab定时任务中提示command not found解决方案写了个脚本定时从MySQL中提取数据，但是crontab发邮件提示mysql command not found 很奇怪，因为直接执行此脚本不会报错，正常运行，但加入到crontab中就会报错， 经查，MySQL不在crontab执行的环境变量中 解决方案： 找到MySQL的安装路径： which mysql 假设找到的是:/home/user1/mysql/bin/mysql 建立软连接 cd /usr/bin &amp;&amp; ln -fs /home/user1/mysql/bin/mysql mysql","categories":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/tags/linux/"},{"name":"Github","slug":"github","permalink":"https://mhuig.github.io/tags/github/"}]},{"title":"CPU调度","slug":"OS/CPU调度","date":"2019-09-24T13:11:01.000Z","updated":"2019-09-24T13:11:01.000Z","comments":true,"path":"posts/be57c430.html","link":"","permalink":"https://mhuig.github.io/posts/be57c430.html","excerpt":"CPU调度","text":"CPU调度 基本概念CPU－I/O区间周期进程执行由CPU和I／O等待周期组成。进程在这两个状态之间切换。 CPU调度程序所谓CPU调度程序，其实就是：当CPU空闲时，操作系统如何从就绪队列中选择一个进程来执行的策略。 抢占调度 非抢占调度，一旦CPU分配给一个进程，那么该进程会一直使用CPU直到进程终止或切换到等待状态。 抢占调度，可能一个进程正在运行时，另一个新的进程也到来。而依据调度策略与当前各进程状态，新进程应该先执行。那么，新进程会抢占CPU进行执行，原进程切换到就绪状态。 分派程序分派程序是一个模块，用来将CPU的控制交给由短期调度程序选择的进程。 功能包括： 切换上下文 切换到用户模式 跳转到用户程序的合适位置，以重新启动程序 调度准则 CPU使用率 吞吐量：一个时间单元内所完成进程的数量 周转时间：从进程提交到进程完成的时间段称为周转时间。 等待时间：为在就绪队列中等待所花费时间之和 响应时间：开始响应所需要的时间，响应时间指从进程提交到被运行第一段代码的时间 调度算法1.先到先服务调度（FCFS）非抢占。 补充概念：护航效果：所有其他进程等待一个大进程释放CPU的状态 2.最短作业优先调度（SJF）这一算法将每个进程与其下一个CPU区间段相关联。当CPU为空闲时，它会赋给具有最短CPU区间的进程。 如果两个进程具有同样长度，那可以使用FCFS调度来处理。 SJF调度算法的平均等待时间最小。 SJF的难点就是如何得知下一个CPU区间的长度。书上采用，预测下一个CPU区间为以前CPU区间的测量长度的指数平均。 T（n＋1）＝åt（n）＋（1-å）T（n） 抢占SJF调度：最短剩余时间优先调度 也存在非抢占SJF 3.优先级调度SJF可作为通用优先级调度算法的一个特例 （书上默认）优先级越高，数值越小 即 优先级1比优先级2的优先级要高 优先级调度可以是抢占的或者非抢占的。 主要问题：无穷阻塞或饥饿＝》它可能会导致某个低优先级进程无线等待CPU 解决：使用老化技术，以逐渐增加在系统中等待很长时间的进程的优先级 4.轮转法调度（RR）定义一个较小时间单元，称为时间片。 将就绪队列保存为进程的FIFO队列。新进程增加到就绪队列的尾部。CPU调度程序就从就绪队列中选择第一个进程，设置定时器在一个时间片之后中断，再分排该进程。（1进程在时间片中运行完，进程自动释放CPU，下一个进程开始执行 2.进程未在时间片内执行完，定时器产生中断并产生操作系统中断，然后进行上下文切换，将进程加入到就绪队列的尾部，就绪队列中下一个进程开始执行） 该策略的平均等待时间通常较长 具体效率和时间片大小有关 适合分时（交互系统） 5.多级队列调度将就绪队列分成多个独立队列，每个队列有自己的调度算法，每个队列有自己的优先级 6.多级反馈队列调度在上面的基础上，允许等待时间过长的进程转移到更高优先级的队列","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"进程调度","slug":"进程调度","permalink":"https://mhuig.github.io/tags/%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6/"}]},{"title":"进程同步之信号量机制","slug":"OS/信号量机制","date":"2019-09-24T12:28:47.000Z","updated":"2019-09-24T12:28:47.000Z","comments":true,"path":"posts/2ffcda9a.html","link":"","permalink":"https://mhuig.github.io/posts/2ffcda9a.html","excerpt":"信号量（semaphore）的数据结构为一个值和一个指针，指针指向等待该信号量的下一个进程。信号量的值与相应资源的使用情况有关。","text":"信号量（semaphore）的数据结构为一个值和一个指针，指针指向等待该信号量的下一个进程。信号量的值与相应资源的使用情况有关。 信号量机制信号量机制即利用pv操作来对信号量进行处理。 什么是信号量？信号量（semaphore）的数据结构为一个值和一个指针，指针指向等待该信号量的下一个进程。信号量的值与相应资源的使用情况有关。 当它的值大于0时，表示当前可用资源的数量； 当它的值小于0时，其绝对值表示等待使用该资源的进程个数。 注意，信号量的值仅能由PV操作来改变。 一般来说，信号量S$\\ge$0时，S表示可用资源的数量。执行一次P操作意味着请求分配一个单位资源，因此S的值减1；当S&lt;0时，表示已经没有可用资源，请求者必须等待别的进程释放该类资源，它才能运行下去。而执行一个V操作意味着释放一个单位资源，因此S的值加1；若S£0，表示有某些进程正在等待该资源，因此要唤醒一个等待状态的进程，使之运行下去。 经典伪代码p操作（wait）：申请一个单位资源，进程进入 1234wait(semaphore *S)&#123; S-&gt;value--; if(S-&gt;value&lt;0) block(S-&gt;list);&#125; v操作（signal）：释放一个单位资源，进程出来 1234signal(semaphore *S)&#123; S-&gt;value++; if(S-&gt;value&lt;=0) wakeup(S-&gt;list);&#125; 综合训练专题","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"进程同步","slug":"进程同步","permalink":"https://mhuig.github.io/tags/%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5/"}]},{"title":"自建Https证书","slug":"CentOS/自建https证书","date":"2019-09-23T11:53:44.000Z","updated":"2019-09-23T11:53:44.000Z","comments":true,"path":"posts/5bb73de.html","link":"","permalink":"https://mhuig.github.io/posts/5bb73de.html","excerpt":"生成nginx的证书与配置chrome安全告警的问题","text":"生成nginx的证书与配置chrome安全告警的问题 安装openssl生成根证书1openssl req -x509 -nodes -days 1461 -newkey rsa:2048 -subj &quot;&#x2F;C&#x3D;CN&#x2F;ST&#x3D;MyProvince&#x2F;L&#x3D;MyCity&#x2F;O&#x3D;MyOrganization&quot; -keyout CA-private.key -out CA-certificate.crt -reqexts v3_req -extensions v3_ca 生成私钥1openssl genrsa -out private.key 2048 1openssl req -new -key private.key -subj &quot;&#x2F;C&#x3D;CN&#x2F;ST&#x3D;MyProvince&#x2F;L&#x3D;MyCity&#x2F;O&#x3D;MyOrganization&#x2F;CN&#x3D;xxx.xxx.xxx.xxx&quot; -sha256 -out private.csr 解决 Chrome 安全警告按照上面的流程，需要注意的是，在默认情况下生成的证书一旦选择信任，在 Edge, Firefox 等浏览器都显示为安全，但是 Chrome 仍然会标记为不安全并警告拦截，这是因为 Chrome 需要证书支持扩展 Subject Alternative Name, 因此生成时需要特别指定 SAN 扩展并添加相关参数。SAN Extension 所需配置文件关键属性： req_distinguished_name: 一节的内容与上面 -subj 一样都是证书的附加信息subjectAltName: 是最关键的属性，取值有两种情况，除前缀外值应与上一步 -subj 中指定的 CN 参数值相同：如果是为某一域名签发证书，则其值可为 DNS:www.example.com 或者使用通配符 DNS:*.example.com；如果为 IP 地址颁发证书，则应该使用 IP:xxx.xxx.xxx.xxx 的形式。 123456789101112131415[ req ]default_bits &#x3D; 2048distinguished_name &#x3D; req_distinguished_namereq_extensions &#x3D; sanextensions &#x3D; san[ req_distinguished_name ]countryName &#x3D; CNstateOrProvinceName &#x3D; MyProvincelocalityName &#x3D; MyCityorganizationName &#x3D; MyOrganization[SAN]authorityKeyIdentifier&#x3D;keyid,issuerbasicConstraints&#x3D;CA:FALSEkeyUsage &#x3D; digitalSignature, nonRepudiation, keyEncipherment, dataEnciphermentsubjectAltName &#x3D; IP:xxx.xxx.xxx.xxx 将上述内容放到一个文件中,命名为private.ext执行命令,生成证书1openssl x509 -req -days 1461 -in private.csr -CA CA-certificate.crt -CAkey CA-private.key -CAcreateserial -sha256 -out private.crt -extfile private.ext -extensions SAN nginx中配置如下: 1234567server &#123; listen 443; server_name localhost; ssl on; ssl_certificate /alidata/ssl/private.crt; ssl_certificate_key /alidata/ssl/private.key;&#125; 使用证书生成的具体域名证书和私钥可在 nginx 中使用，然后再客户端所在电脑导入根证书： Windows 需要添加根证书至 受信任的根证书颁发机构macOS 将其导入 钥匙串访问 并选择信任另外 Windows 快捷安装根证书脚本如下(需要管理员权限)： 1certutil -addstore -f -enterprise -user root &quot;.\\CA-certificate.crt&quot; 在window或者mac上安装private.crt文件后，nginx上页面或者接口就可以正常访问了。","categories":[{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/categories/web/"},{"name":"Nginx","slug":"web/nginx","permalink":"https://mhuig.github.io/categories/web/nginx/"}],"tags":[{"name":"Nginx","slug":"nginx","permalink":"https://mhuig.github.io/tags/nginx/"},{"name":"https","slug":"https","permalink":"https://mhuig.github.io/tags/https/"}]},{"title":"Nginx配置","slug":"Nginx/Nginx配置","date":"2019-09-23T08:46:19.000Z","updated":"2019-09-23T08:46:19.000Z","comments":true,"path":"posts/ad720447.html","link":"","permalink":"https://mhuig.github.io/posts/ad720447.html","excerpt":"Nginx 基础配置 安全性配置","text":"Nginx 基础配置 安全性配置 Nginx配置error_page 404 500等自定义的错误页面 1.创建自己的404.html页面 2.更改nginx.conf在http定义区域加入： 12345server&#123; ... fastcgi_intercept_errors on; ...&#125; 3.更改nginx.conf(或单独网站配置文件)中在server 区域加入： 12345678server&#123; ... error_page 400 401 402 403 404 405 408 410 412 413 414 415 500 501 502 503 504 506 /404.html; location = /404.html &#123; root /alidata/www/phpwind/error; &#125; ...&#125; 4.更改后重启nginx,测试nginx.conf正确性：1nginx -t 5.502 等错误可以用同样的方法来配置。 12345678server&#123; ... error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /alidata/www/phpwind/error; &#125; ...&#125; Nginx隐藏版本号的安全性与方法隐藏原因：Nginx某些版本有漏洞，暴露出来容易被攻击者利用，隐藏起来更安全 隐藏版本号nginx.conf中去掉下面注释，或者添加这一行 12345http&#123; ... server_tokens off ...&#125; 如果是转发给php－fpm ，需要编辑fastcgi.conf，一般在nginx.conf 同层找到： 1fastcgi_param SERVER_SOFTWARE nginx/$nginx_version; 改为： 1fastcgi_param SERVER_SOFTWARE nginx; 编译源码返回自定义的server修改src/http/ngx_http_header_filter_module.c 中的48行 1static char ngx_http_server_string[] = &quot;Server: nginx&quot; CRLF; 把其中的nginx改为我们自己想要的文字即可，笔者就改为了GFW. 修改src/core/nginx.h 定位到13-14行 123#define nginx_version 2000000#define NGINX_VERSION &quot;2.0&quot;#define NGINX_VER &quot;GFW/&quot; NGINX_VERSION Server返回的就是常量NGINX_VER 重新编译 1make &amp;&amp; make install 控制缓冲区溢出攻击编辑nginx.conf，为所有客户端设置缓冲区的大小限制。 编辑和设置所有客户端缓冲区的大小限制如下： 12345678910http &#123; ...## Start: Size Limits &amp; Buffer Overflows ## client_body_buffer_size 1K; client_header_buffer_size 1k; client_max_body_size 1k; large_client_header_buffers 2 1k;## END: Size Limits &amp; Buffer Overflows ## ...&#125; 解释： 1、client_body_buffer_size 1k-（默认8k或16k）这个指令可以指定连接请求实体的缓冲区大小。如果连接请求超过缓存区指定的值，那么这些请求实体的整体或部分将尝试写入一个临时文件。 2、client_header_buffer_size 1k-指令指定客户端请求头部的缓冲区大小。绝大多数情况下一个请求头不会大于1k，不过如果有来自于wap客户端的较大的cookie它可能会大于1k，Nginx将分配给它一个更大的缓冲区，这个值可以在large_client_header_buffers里面设置。 3、client_max_body_size 1k-指令指定允许客户端连接的最大请求实体大小，它出现在请求头部的Content-Length字段。如果请求大于指定的值，客户端将收到一个”Request Entity Too Large” (413)错误。记住，浏览器并不知道怎样显示这个错误。 4、large_client_header_buffers-指定客户端一些比较大的请求头使用的缓冲区数量和大小。请求字段不能大于一个缓冲区大小，如果客户端发送一个比较大的头，nginx将返回”Request URI too large” (414) 同样，请求的头部最长字段不能大于一个缓冲区，否则服务器将返回”Bad request” (400)。缓冲区只在需求时分开。默认一个缓冲区大小为操作系统中分页文件大小，通常是4k或8k，如果一个连接请求最终将状态转换为keep-alive，它所占用的缓冲区将被释放。你还需要控制超时来提高服务器性能并与客户端断开连接。按照如下编辑： 12345678910http &#123; ...## Start: Timeouts ## client_body_timeout 10; client_header_timeout 10; keepalive_timeout 5 5; send_timeout 10;## End: Timeouts ## ...&#125; 1、client_body_timeout 10;-指令指定读取请求实体的超时时间。这里的超时是指一个请求实体没有进入读取步骤，如果连接超过这个时间而客户端没有任何响应，Nginx将返回一个”Request time out” (408)错误。 2、client_header_timeout 10;-指令指定读取客户端请求头标题的超时时间。这里的超时是指一个请求头没有进入读取步骤，如果连接超过这个时间而客户端没有任何响应，Nginx将返回一个”Request time out” (408)错误。 3、keepalive_timeout 5 5; – 参数的第一个值指定了客户端与服务器长连接的超时时间，超过这个时间，服务器将关闭连接。参数的第二个值（可选）指定了应答头中Keep-Alive: timeout=time的time值，这个值可以使一些浏览器知道什么时候关闭连接，以便服务器不用重复关闭，如果不指定这个参数，nginx不会在应答头中发送Keep-Alive信息。（但这并不是指怎样将一个连接“Keep-Alive”）参数的这两个值可以不相同。 4、send_timeout 10; 指令指定了发送给客户端应答后的超时时间，Timeout是指没有进入完整established状态，只完成了两次握手，如果超过这个时间客户端没有任何响应，nginx将关闭连接。 限制可用的请求方法GET和POST是互联网上最常用的方法。 Web服务器的方法被定义在RFC 2616。如果Web服务器不要求启用所有可用的方法，它们应该被禁用。下面的指令将过滤只允许GET，HEAD和POST方法： 123456789server &#123; ...## Only allow these request methods ## if ($request_method !~ ^(GET|HEAD|POST)$ ) &#123; return 444; &#125;## Do not accept DELETE, SEARCH and other methods ## ...&#125; 更多关于HTTP方法的介绍 GET方法是用来请求，如文件https://www.centos.bz/index.php。HEAD方法是一样的，除非该服务器的GET请求无法返回消息体。POST方法可能涉及到很多东西，如储存或更新数据，或订购产品，或通过提交表单发送电子邮件。这通常是使用服务器端处理，如PHP，Perl和Python等脚本。如果你要上传的文件和在服务器处理数据，你必须使用这个方法。 拒绝一些User-Agents你可以很容易地阻止User-Agents,如扫描器，机器人以及滥用你服务器的垃圾邮件发送者。Nginx的444状态比较特殊，如果返回444那么客户端将不会收到服务端返回的信息，就像是网站无法连接一样 123456789server &#123; ...## Block download agents ## if ($http_user_agent ~* LWP::Simple|BBBike|wget|curl) &#123; return 444; &#125;## ...&#125; 阻止Soso和有道的机器人： 123456789server &#123; ...## Block some robots ## if ($http_user_agent ~* Sosospider|YodaoBot) &#123; return 403; &#125;## ...&#125; Header头设置通过以下设置可有效防止XSS攻击 123add_header X-Frame-Options &quot;SAMEORIGIN&quot;;add_header X-XSS-Protection &quot;1; mode=block&quot;;add_header X-Content-Type-Options &quot;nosniff&quot;; X-Frame-Options： 响应头表示是否允许浏览器加载frame等属性，有三个配置DENY禁止任何网页被嵌入,SAMEORIGIN只允许本网站的嵌套,ALLOW-FROM允许指定地址的嵌套 X-XSS-Protection： 表示启用XSS过滤（禁用过滤为X-XSS-Protection: 0），mode=block表示若检查到XSS攻击则停止渲染页面 X-Content-Type-Options： 响应头用来指定浏览器对未指定或错误指定Content-Type资源真正类型的猜测行为，nosniff 表示不允许任何猜测 在通常的请求响应中，浏览器会根据Content-Type来分辨响应的类型，但当响应类型未指定或错误指定时，浏览会尝试启用MIME-sniffing来猜测资源的响应类型，这是非常危险的 例如一个.jpg的图片文件被恶意嵌入了可执行的js代码，在开启资源类型猜测的情况下，浏览器将执行嵌入的js代码，可能会有意想不到的后果 另外还有几个关于请求头的安全配置需要注意 Content-Security-Policy： 定义页面可以加载哪些资源， 1add_header Content-Security-Policy &quot;default-src &#x27;self&#x27;&quot;; 上边的配置会限制所有的外部资源，都只能从当前域名加载，其中default-src定义针对所有类型资源的默认加载策略，self允许来自相同来源的内容 Strict-Transport-Security： 会告诉浏览器用HTTPS协议代替HTTP来访问目标站点 1add_header Strict-Transport-Security &quot;max-age=31536000; includeSubDomains&quot;; 上边的配置表示当用户第一次访问后，会返回一个包含了Strict-Transport-Security响应头的字段，这个字段会告诉浏览器，在接下来的31536000秒内，当前网站的所有请求都使用https协议访问，参数includeSubDomains是可选的，表示所有子域名也将采用同样的规则 经过多层CDN之后取得原始用户的IP地址，nginx 配置根据用户的真实 IP 做连接限制123456789101112131415161718192021222324252627http &#123; ...##############map $http_x_forwarded_for $clientRealIp &#123; ## 没有通过代理，直接用 remote_addr &quot;&quot; $remote_addr; ## 用正则匹配，从 x_forwarded_for 中取得用户的原始IP ## 例如 X-Forwarded-For: 202.123.123.11, 208.22.22.234, 192.168.2.100,... ## 这里第一个 202.123.123.11 是用户的真实 IP，后面其它都是经过的 CDN 服务器 ~^(?P&lt;firstAddr&gt;[0-9\\.]+),?.*$ $firstAddr;&#125;## 通过 map 指令，我们为 nginx 创建了一个变量 $clientRealIp ，这个就是 原始用户的真实 IP 地址，## 不论用户是直接访问，还是通过一串 CDN 之后的访问，我们都能取得正确的原始IP地址################### 针对原始用户 IP 地址做限制limit_conn_zone $clientRealIp zone=TotalConnLimitZone:20m ;limit_conn TotalConnLimitZone 50;limit_conn_log_level notice;## 针对原始用户 IP 地址做限制limit_req_zone $clientRealIp zone=ConnLimitZone:20m rate=10r/s;limit_req zone=ConnLimitZone burst=10 nodelay;limit_req_log_level notice;###################### ...&#125; nginx日志按天保存1234log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; 1234log_format main &#x27;$remote_addr - $remote_user [$time_iso8601] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; 将原来的time_local修改为time_iso8601，该格式日期为“2017-01-19T09:10:52+08:00”，也可以其他格式，看个人习惯 注意层次关系，这段脚本一定要加到server配置内部，且if要在access_log前面，否则set的变量将无法引用 12345678server&#123;...if ($time_iso8601 ~ &#x27;(\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;)&#x27;) &#123; set $tttt $1; &#125; access_log logs/access-$tttt.log main;...&#125; 按yyyy-mm-dd格式截取字符串，写入指定日志文件中 执行 nginx -s reload 后则配置生效 123456789101112131415http &#123; .... log_format main &#x27;$remote_addr - $remote_user [$time_iso8601] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; server &#123; if ($time_iso8601 ~ &#x27;(\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;)&#x27;) &#123; set $tttt $1; &#125; access_log logs/$tttt.access.log main; .... &#125; ....&#125;","categories":[{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/categories/web/"},{"name":"Nginx","slug":"web/nginx","permalink":"https://mhuig.github.io/categories/web/nginx/"}],"tags":[{"name":"Nginx","slug":"nginx","permalink":"https://mhuig.github.io/tags/nginx/"},{"name":"Web安全","slug":"web安全","permalink":"https://mhuig.github.io/tags/web%E5%AE%89%E5%85%A8/"}]},{"title":"LaTeX数学符号语法速查表","slug":"math/LaTeX数学符号语法速查表","date":"2019-09-22T11:31:47.000Z","updated":"2019-09-22T11:31:47.000Z","comments":true,"path":"posts/96f894a7.html","link":"","permalink":"https://mhuig.github.io/posts/96f894a7.html","excerpt":"最近写一些报告的时候经常需要使用 LaTeX 语法输入数学公式，每次用的时候都去网上搜资料实在是太麻烦了，所以花了点时间整理了一些常用的 LaTeX 数学符号语法供自己查阅。","text":"最近写一些报告的时候经常需要使用 LaTeX 语法输入数学公式，每次用的时候都去网上搜资料实在是太麻烦了，所以花了点时间整理了一些常用的 LaTeX 数学符号语法供自己查阅。 PS： 本文中所有的符号都是我手动敲进去的，如发现错误请联系我做出修改。更多符号使用可以查看 LaTeX:Symbols 加减乘除 符号 语法 + - \\times \\div 幂运算 符号 语法 a^x a^{xyz} \\sqrt{x} \\sqrt[n]{x} 逻辑运算 符号 语法 \\oplus \\vee \\wedge 关系运算 符号 语法 = \\not= \\approx &gt; &lt; 符号 语法 \\equiv \\le \\ge \\ll \\gg 集合 符号 语法 \\in \\ni \\subset \\supset \\subseteq \\supseteq 存在 符号 语法 \\exists \\forall 希腊字母要输入希腊字母只要用反斜杠 \\ 加上相应字母的拼写即可。大写字母将对应拼写的首字母大写即可，这里仅列出一部分作为参考。 符号（小写） 语法 \\phi \\omega \\delta \\gamma 符号（大写） 语法 \\Phi \\Omega \\Delta \\Gamma 箭头 符号 语法 \\gets \\to \\Leftarrow \\Rightarrow \\Leftrightarrow 省略号 符号 语法 \\dots \\cdots \\vdots \\ddots 头顶符号 符号 语法 \\hat{x} \\bar{x} \\vec{x} \\dot{x} \\ddot{x} 标准括号 符号 语法 ( ) [ ] 取整括号（函数） 符号 语法 \\lfloor \\rfloor \\lceil \\rceil 空格LaTex 默认会忽略掉空格，要显示空格的话需要自己用命令输入（mu是一个数学单位）。 效果 说明 语法 空格宽度是当前字宽(18mu) \\quad 空格宽度是3mu \\, 空格宽度是4mu \\: 空格宽度是5mu \\; 空格宽度是-3mu(向左缩) \\! 空格宽度是标准空格键效果 在 \\ 后面敲一个空格 空格宽度是36mu \\qquad 上标与下标使用 ^ 和 _ 来表示上下标，使用 {} 来限定上下标的所属关系，下面是一些使用示例。 符号 语法 x^i a_i x^{a_i} x^a_i x^{a^i} x_{i+1} 上划线下划线 符号 语法 \\overline{a+bi} \\underline{xyz} 分式分式有两种尺寸表示，分别用 frac 和 dfrac 关键字表示 尺寸 较小 较小 适中 适中 符号 语法 \\frac{1}{2} \\frac{1+\\frac{1}{x}}{3x + 2} \\dfrac{1}{2} \\dfrac{1+\\frac{1}{x}}{3x + 2} 连续嵌套使用时用：\\cfrac 符号显示 语法 \\cfrac{1+\\cfrac{2}{1+\\cfrac{2}{1+\\cfrac{2}{1}}}}{2} 根式 符号 语法 \\sqrt{x+y} \\sqrt{x} \\sqrt[n]{x} 三角函数直接反斜杠 \\ 加正常书写的符号即可，这里只列举几个。 符号 语法 \\cos \\sin \\arccos 符号 语法 \\cos^2 x +\\sin^2 x = 1 \\cos 90^\\circ = 0 求和 求积 求极限 符号 语法 \\sum \\prod \\lim 符号 语法 \\sum_{i=1}^{\\infty}\\frac{1}{i} \\prod_{n=1}^5\\frac{n}{n-1} \\lim_{x\\to\\infty}\\frac{1}{x} 求积分 偏导 符号 语法 \\int \\oint \\partial^2y 符号 语法 \\frac{d}{dx}\\left(x^2\\right) = 2x \\int 2x\\ dx = x^2+C \\frac{\\partial^2U}{\\partial x^2} + \\frac{\\partial^2U}{\\partial y^2} 绝对值直接插入竖线 | 即可，可使用 \\left 、 \\right 标签来指定竖线的垂直长度与那对应字符块匹配 12直接插入竖线： |a^x|指定垂直长度相匹配： \\left|a\\right|^\\left|x\\right| 直接插入竖线：指定垂直长度相匹配： 注：所有成对出现的符号均可以像上面那样使用 \\left 、 \\right 标签来指定其大小匹配的字符块。 矩阵和行列式所有的矩阵都是使用 \\begin{matrix} 开始， \\end{matrix} 结束。其中的 matrix 还可以改为 pmatrix 、 bmatrix 、 Bmatrix 、 vmatrix 、 Vmatrix 。 在每一行中使用 &amp; 分隔元素，行末用双反斜杠 \\ 表示换行。 ##基础格式 对于下面的公式，修改大括号内的关键字分别为 matrix 、 pmatrix 、 bmatrix 、 Bmatrix 、 vmatrix 、 Vmatrix 时对应的情况如下所示。 12345\\begin{matrix}A &amp; B &amp; C\\\\D &amp; E &amp; F\\\\G &amp; H &amp; I\\\\\\end{matrix} matrix pmatrix bmatrix Bmatrix vmatrix Vmatrix 带省略号的矩阵这里使用 bmatrix 做示范，其他的类似。 如上面“省略号”所在小节所示，时使用 \\cdots 表示水平方向省略号， \\vdots 表示竖直方向省略号， \\ddots 表示对角线方向省略号（我这里为了美观把公式按 &amp; 对齐了，这并不是必需的）。 123456\\begin{bmatrix}A &amp; B &amp; \\cdots &amp; C \\\\D &amp; E &amp; \\cdots &amp; F \\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\G &amp; H &amp; \\cdots &amp; I \\\\\\end{bmatrix} 矩阵方程（函数）使用 \\begin{equation} 作为整个公式块的开始，以 \\end{equation} 结束。在里面再配合其他符号的语法使用即可。 一个简单的例子如下（这里使用 bmatrix 做示范，其他的类似）。 123456789\\begin{equation}H_x=\\frac{1}{3}\\times{\\begin{bmatrix}A &amp; B &amp; \\cdots &amp; C \\\\D &amp; E &amp; \\cdots &amp; F \\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\G &amp; H &amp; \\cdots &amp; I \\\\\\end{bmatrix}}\\end{equation} 其他符号 符号 语法 \\infty \\triangle \\angle \\checkmark \\nabla","categories":[{"name":"Math","slug":"math","permalink":"https://mhuig.github.io/categories/math/"},{"name":"LaTeX","slug":"math/latex","permalink":"https://mhuig.github.io/categories/math/latex/"}],"tags":[{"name":"Math","slug":"math","permalink":"https://mhuig.github.io/tags/math/"},{"name":"LaTeX","slug":"latex","permalink":"https://mhuig.github.io/tags/latex/"}]},{"title":"Nginx隐藏版本号信息","slug":"Nginx/Nginx隐藏版本号信息","date":"2019-09-22T09:35:17.000Z","updated":"2019-09-22T09:35:17.000Z","comments":true,"path":"posts/f3b50546.html","link":"","permalink":"https://mhuig.github.io/posts/f3b50546.html","excerpt":"当我们使用 apt 或者其他包管理工具安装完 Nginx 之后，访问网站时 Header 里面会默认携带 Nginx 的版本号信息。","text":"当我们使用 apt 或者其他包管理工具安装完 Nginx 之后，访问网站时 Header 里面会默认携带 Nginx 的版本号信息。 命令行下可以使用命令查看： 1curl -I http:&#x2F;&#x2F;your-domain 123456HTTP&#x2F;2 200server: nginx&#x2F;1.16.1 #这里带有版本号信息date: Thu, 12 Sep 2019 03:06:23 GMTcontent-type: text&#x2F;html; charset&#x3D;cache-control: publiccontent-language: auto 而软件漏洞往往都是跟版本绑定的，在管理员没有及时更新修复漏洞的情况下，一旦攻击者知道了你用的 Nginx 版本就能轻松利用已知漏洞实现入侵。 这无疑是一个安全隐患，所以对版本号进行隐藏就一定必要了（当然，更新修复漏洞才是解决问题的根本途径）。 解决方法要隐藏 Nginx 版本号其实很简单，稍微修改一下配置文件即可。这里使用 vim 编辑器： 1sudo vim &#x2F;etc&#x2F;nginx&#x2F;nginx.conf 在 http{} 段中添加一行 server_tokens off; 12345http &#123; ...... server_tokens off; ......&#125; 之后保存文件，测试 Nginx 配置文件是否正常后重载配置即可 12sudo nginx -t #测试配置文件是否正常sudo nginx -s reload #重载nginx配置 测试效果配置好之后可以再用 curl 测试一下，会发现不再显示 Nginx 版本号了。 123456HTTP&#x2F;2 200server: nginx #版本号信息没有了date: Thu, 12 Sep 2019 03:32:16 GMTcontent-type: text&#x2F;html; charset&#x3D;cache-control: publiccontent-language: auto","categories":[{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/categories/web/"},{"name":"Nginx","slug":"web/nginx","permalink":"https://mhuig.github.io/categories/web/nginx/"}],"tags":[{"name":"Nginx","slug":"nginx","permalink":"https://mhuig.github.io/tags/nginx/"}]},{"title":"Django带文件的表单上传","slug":"Django/Django带文件的表单上传","date":"2019-09-22T07:12:52.000Z","updated":"2019-09-22T07:12:52.000Z","comments":true,"path":"posts/4dd55455.html","link":"","permalink":"https://mhuig.github.io/posts/4dd55455.html","excerpt":"带文件的表单如何上传","text":"带文件的表单如何上传 带文件的表单上传首先在表单form中必须要添加这个属性1enctype=&quot;multipart/form-data&quot; 然后在js中添加下列代码 1234567891011121314151617181920212223242526272829303132333435//选中需要上传的表单，并且进行格式化处理var formData=new FormData($(&quot;#formdata&quot;)[0]);console.log(formData)//获取用户名var user=document.getElementById(&quot;username&quot;).innerHTML;var date=new Date();var month=date.getMonth()+1;//把数据追加到表单formData.append(&quot;username&quot;,user);formData.append(&quot;date&quot;,date.getFullYear()+&quot;-&quot;+month+&quot;-&quot;+date.getDate());formData.append(&quot;sign&quot;,date.getTime());$.ajax(&#123; type:&quot;post&quot;, url:&quot;http://127.0.0.1:8000/tour/sendDay&quot;, async:true, data:formData, timeout:5000, dataType:&quot;json&quot;, cache:false, //提交表单必须增加的属性 contentType:false, processData:false, success:function(data)&#123; alert(data); console.log(data) if(data.code == &quot;1&quot;) &#123; alert(&quot;发布成功&quot;) &#125; if(data.code == &quot;2&quot;)&#123; alert(&quot;发布失败&quot;) &#125; &#125;, error:function(xhr,textState)&#123; alert(&quot;请求失败！&quot;) &#125;&#125;); 在models中添加以下类12345678class Tours(models.Model): username = models.CharField(max_length=20) date = models.CharField(max_length=20) times = models.CharField(max_length=100) desc = models.CharField(max_length=255) photoname = models.FileField(upload_to=&quot;photo&quot;,null=True,blank=True) musicname = models.FileField(upload_to=&quot;music&quot;,null=True,blank=True) isDelete = models.BooleanField(default=False) 在settings.py文件中添加如下代码12MEDIA_URL = &#x27;/media/&#x27;MEDIA_ROOT = os.path.join(BASE_DIR,&#x27;media&#x27;) 在urls.py文件中创建路由12345678910111213from django.views.static import servefrom App import viewsfrom tourdemo import settingsfrom tourdemo.settings import MEDIA_ROOTurlpatterns = [ url(r&#x27;^admin/&#x27;, admin.site.urls), url(r&quot;^tour/sendDay&quot;,views.tourSendDay), #加载media文件需要的路由 url(r&#x27;^media/(?P&lt;path&gt;.*)/$&#x27;, serve, &#123;&quot;document_root&quot;: MEDIA_ROOT&#125;),] 在views.py文件中添加tourSendDay函数1234567891011121314151617181920212223242526272829303132def tourSendDay(request): try: tour = Tours() username = request.POST.get(&quot;username&quot;) tour.username = username date = request.POST.get(&quot;date&quot;) tour.date = date times = request.POST.get(&quot;sign&quot;) tour.times = times music = request.FILES.get(&quot;music&quot;) tour.musicname = music img = request.FILES.get(&quot;photo&quot;) tour.photoname = img desc = request.POST.get(&quot;desc&quot;) # print(desc) tour.desc = desc # print(&quot;desc&quot;,tour.desc) tour.save() tourdic = &#123;&quot;code&quot;:&quot;1&quot;,&quot;id&quot;: tour.id, &quot;photoname&quot;: tour.photoname.url, &quot;musicname&quot;: tour.musicname.url, &quot;times&quot;: tour.times, &quot;username&quot;: tour.username, &quot;date&quot;: tour.date, &quot;desc&quot;: tour.desc&#125; response = HttpResponse(json.dumps(tourdic)) except Exception as e: print(e) response = HttpResponse(json.dumps(&#123;&quot;code&quot;: &quot;2&quot;&#125;)) response[&quot;Access-Control-Allow-Origin&quot;] = &quot;*&quot; response[&quot;Access-Control-Allow-Methods&quot;] = &quot;POST, GET, OPTIONS&quot; response[&quot;Access-Control-Max-Age&quot;] = &quot;1000&quot; response[&quot;Access-Control-Allow-Headers&quot;] = &quot;*&quot; return response 注意若出现存储中文失败则需要在创建的的时候指定编码格式1create database tourdb charset&#x3D;&#39;utf8&#39;;","categories":[{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/categories/web/"},{"name":"Django","slug":"web/django","permalink":"https://mhuig.github.io/categories/web/django/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"Django","slug":"django","permalink":"https://mhuig.github.io/tags/django/"}]},{"title":"Django将发布内容动态显示到页面上","slug":"Django/Django将发布内容动态显示到页面上","date":"2019-09-22T07:11:42.000Z","updated":"2019-09-22T07:11:42.000Z","comments":true,"path":"posts/5bfe6261.html","link":"","permalink":"https://mhuig.github.io/posts/5bfe6261.html","excerpt":"Django如何将发布内容动态显示到页面上","text":"Django如何将发布内容动态显示到页面上 将发布内容动态显示到页面上在settings.py中配置12345678910111213141516171819202122TEMPLATES = [ &#123; &#x27;BACKEND&#x27;: &#x27;django.template.backends.django.DjangoTemplates&#x27;, &#x27;DIRS&#x27;: [os.path.join(BASE_DIR,&quot;Templates&quot;)], &#x27;APP_DIRS&#x27;: True, &#x27;OPTIONS&#x27;: &#123; &#x27;context_processors&#x27;: [ &#x27;django.template.context_processors.debug&#x27;, &#x27;django.template.context_processors.request&#x27;, &#x27;django.contrib.auth.context_processors.auth&#x27;, &#x27;django.contrib.messages.context_processors.messages&#x27;, &#x27;django.template.context_processors.media&#x27;, # 新添加的 ], &#125;, &#125;,]#已经配置过的MEDIA_URL = &#x27;/media/&#x27;MEDIA_ROOT = os.path.join(BASE_DIR,&#x27;media&#x27;) 在urls.py中配置路由123456789from tour.settings import MEDIA_ROOTfrom django.views.static import serve #注意包不能导错urlpatterns = [ url(r&#x27;^admin/&#x27;, admin.site.urls), url(r&#x27;^media/(?P&lt;path&gt;.*)/$&#x27;, serve, &#123;&quot;document_root&quot;: MEDIA_ROOT&#125;),#加载media文件的时候需要的路由 url(r&quot;^gettour&quot;,views.gettour),#获取tour.html页面的路由 url(r&quot;^sendtour&quot;,views.sendTour),#发布动态的路由] 在views.py文件中创建sendTour的函数12345678910111213141516171819202122232425def sendTour(request): try: #从请求中将表单中的数据取出，并且存储到数据库中 tour = Tour() tour.username= request.POST.get(&quot;username&quot;) tour.times = request.POST.get(&quot;times&quot;) tour.sendtime = request.POST.get(&quot;sendtime&quot;) tour.sendtxt = request.POST.get(&quot;sendtxt&quot;) tour.phonename = request.FILES.get(&quot;imgfile&quot;) tour.musicname = request.FILES.get(&quot;musicfile&quot;) tour.save() #若存储成功，则将对象转为字典 tourdict = &#123;&quot;code&quot;:&quot;1&quot;,&quot;username&quot;:tour.username,&quot;times&quot;:tour.times, &quot;sendtime&quot;:tour.sendtime,&quot;phonename&quot;:tour.phonename.url ,&quot;musicname&quot;:tour.musicname.url,&quot;sendtxt&quot;:tour.sendtxt&#125; # 再字典转为json字符串，返回到前端页面中 response = HttpResponse(json.dumps(tourdict)) except Exception as e: print(e) response = HttpResponse(json.dumps(&#123;&#x27;code&#x27;: &quot;0&quot;&#125;)) response[&quot;Access-Control-Allow-Origin&quot;] = &quot;*&quot; response[&quot;Access-Control-Allow-Methods&quot;] = &quot;POST, GET, OPTIONS&quot; response[&quot;Access-Control-Max-Age&quot;] = &quot;1000&quot; response[&quot;Access-Control-Allow-Headers&quot;] = &quot;*&quot; return response 在前端页面中添加函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869function sendData()&#123;//选中dataform表单对其进行格式化处理var dataform = new FormData($(&quot;#datafrom&quot;)[0])console.log(dataform)var user = document.getElementById(&quot;user&quot;).innerHTML; //将数据追加到表单中 dataform.append(&quot;username&quot;,user)var dates = new Date()var y = dates.getFullYear()var m = dates.getMonth() + 1var d = dates.getDate()dataform.append(&quot;sendtime&quot;,y+&quot;/&quot;+m+&quot;/&quot;+d)//追加一个时间戳dataform.append(&quot;times&quot;,dates.getTime())$.ajax(&#123; type:&quot;post&quot;, url:&quot;http://127.0.0.1:9000/sendtour&quot;, data:dataform, async:true, dataType:&quot;json&quot;, timeout:5000, cache:false, //提交表单的时候需要的参数 contentType:false, processData:false, success:function(data)&#123;//请求成功的时候返回的参数 alert(data) if(data.code==&quot;1&quot;)&#123;//判断数据是否成功存入数据库 alert(&quot;发布成功&quot;) // 将我们返回的数据显示到页面上来 addhistory(data) &#125; if(data.code==&quot;0&quot;)&#123;//数据没存储成功，则显示发布失败！ alert(&quot;发布失败&quot;) &#125; &#125;, error:function()&#123; alert(&quot;请求异常&quot;) &#125;&#125;)&#125;//将得到的数据动态的添加到html页面中function addhistory(data) &#123; //打印data数据console.log(data) //找到存放li的大盒子var $ul = document.getElementById(&quot;ulitem&quot;); //创建一个livar $li = document.createElement(&quot;li&quot;)//将li添加到ul中$ul.appendChild($li) //给li添加一个class属性$li.className = &quot;item&quot;; //给li添加标签$li.innerHTML = &#x27;&lt;img class=&quot;item-img&quot; src=&quot;&#x27;+data.phonename+&#x27;&quot;/&gt;&#x27; + &#x27;&lt;div class=&quot;item-right&quot;&gt;&#x27; + &#x27;&lt;a class=&quot;delete&quot; href=&quot;#&quot;&gt;删除&lt;/a&gt;&#x27; + &#x27;&lt;p class=&quot;itemtxt&quot;&gt;&#x27;+data.sendtxt+&#x27;&lt;/p&gt;&#x27;+ &#x27;&lt;div class=&quot;userbox&quot;&gt;&lt;img class=&quot;icon-img&quot; src=&quot;/static/img/a1.png&quot;/&gt; &#x27; + &#x27;&lt;span class=&quot;username&quot;&gt;&#x27;+data.username+&#x27;&lt;/span&gt;&lt;span class=&quot;sendtime&quot;&gt;&#x27;+data.sendtime +&#x27;&lt;/span&gt;&lt;/div&gt;&#x27; + &#x27;&lt;div&gt;&lt;a class=&quot;musicname&quot; href=&quot;#&quot;&gt;&#x27;+data.musicname+&#x27;&lt;/a&gt;&lt;/div&gt;&#x27; + &#x27;&lt;/div&gt;&#x27;&#125;","categories":[{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/categories/web/"},{"name":"Django","slug":"web/django","permalink":"https://mhuig.github.io/categories/web/django/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"Django","slug":"django","permalink":"https://mhuig.github.io/tags/django/"}]},{"title":"Django中引用静态文件","slug":"Django/Django中引用静态文件","date":"2019-09-22T07:09:59.000Z","updated":"2019-09-22T07:09:59.000Z","comments":true,"path":"posts/1f519fd3.html","link":"","permalink":"https://mhuig.github.io/posts/1f519fd3.html","excerpt":"Django中如何引用静态文件","text":"Django中如何引用静态文件 Django中引用静态文件 当我们将我们的html文件放到Templates文件中的时候，这时候此html我们可以直接引用， 若出现这个html文件，它还引用了其他的一些文件【js，css，img】，这是就需要引用django中静态的文件 需要在Templates的同级目录下创建一个static目录需要在setting文件中添加代码123456#默认自带的STATIC_URL = &#x27;/static/&#x27;#添加代码STATICFILES_DIRS = ( os.path.join(BASE_DIR, &#x27;static&#x27;),) 将html需要用到的资源，放在static目录下 在html中引用静态资源 1234567&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;&lt;/title&gt; &lt;script src=&quot;/static/js/jquery-2.1.0.js&quot; type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;/static/css/style.css&quot;/&gt;&lt;/head&gt; 配置路由，在urls.py文件中配置1234urlpatterns = [ url(r&#x27;^admin/&#x27;, admin.site.urls), url(r&quot;^getlogin&quot;,views.getlogin)] 需要在views.py文件中创建getlogin函数1234def getlogin(request): #返回登录的页面 return render(request,&quot;login.html&quot;) 启动服务1python manage.py runserver 127.0.0.1:9000 如何请求接口1http:&#x2F;&#x2F;127.0.0.1:9000&#x2F;getlogin","categories":[{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/categories/web/"},{"name":"Django","slug":"web/django","permalink":"https://mhuig.github.io/categories/web/django/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"Django","slug":"django","permalink":"https://mhuig.github.io/tags/django/"}]},{"title":"Django添加新的路由","slug":"Django/Django添加新的路由","date":"2019-09-22T07:09:06.000Z","updated":"2019-09-22T07:09:06.000Z","comments":true,"path":"posts/a79b4f5b.html","link":"","permalink":"https://mhuig.github.io/posts/a79b4f5b.html","excerpt":"Django如何添加新的路由","text":"Django如何添加新的路由 Django添加新的路由首先urls.py文件添加路由1234567urlpatterns = [ url(r&#x27;^admin/&#x27;, admin.site.urls), # alt+enter url(r&quot;^login/&quot;,views.login), url(r&quot;^app/addStu/&quot;,views.addStu), url(r&quot;^register&quot;,views.register)] 在views.py中创建函数register12345678910111213def register(request): print(&quot;register&quot;) user = request.POST.get(&quot;user&quot;) print(user) psd = request.POST.get(&quot;psd&quot;) print(psd) #解决跨域问题 response = HttpResponse(user) response[&quot;Access-Control-Allow-Origin&quot;] = &quot;*&quot; response[&quot;Access-Control-Allow-Methods&quot;] = &quot;POST, GET, OPTIONS&quot; response[&quot;Access-Control-Max-Age&quot;] = &quot;1000&quot; response[&quot;Access-Control-Allow-Headers&quot;] = &quot;*&quot; return response 由于ajax跨域的问题，也需要在settings.py文件中设置，将选中的模块注释12345678910MIDDLEWARE = [ &#x27;django.middleware.security.SecurityMiddleware&#x27;, &#x27;django.contrib.sessions.middleware.SessionMiddleware&#x27;, &#x27;django.middleware.common.CommonMiddleware&#x27;, # &#x27;django.middleware.csrf.CsrfViewMiddleware&#x27;, &#x27;django.contrib.auth.middleware.AuthenticationMiddleware&#x27;, &#x27;django.contrib.messages.middleware.MessageMiddleware&#x27;, &#x27;django.middleware.clickjacking.XFrameOptionsMiddleware&#x27;,] 我们的ajax请求在前端中使用的，在使用ajax之前，我们需要将jquery链接到我们的项目中12&lt;script src=&quot;js/jquery-2.1.0.js&quot; type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;src:jquery的链接地址 调用ajax请求12345678910111213$.ajax(&#123; type:&quot;post&quot;,//请求的类型 url:&quot;http://127.0.0.1:8000/register/&quot;,//请求的地址[路由] async:true, //声明异步请求 data:&#123;&quot;user&quot;:user,&quot;psd&quot;:psd&#125;,//将参数传递到后台 dataType:&quot;text&quot;, //声明返回的数据的类型，json success:function (data) &#123; //请求成功的时候调用的函数，data：后台返回给我们的数据 alert(data) &#125;, error:function () &#123; //请求的失败的时候，打印 alert(&quot;请求失败&quot;) &#125; &#125;)","categories":[{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/categories/web/"},{"name":"Django","slug":"web/django","permalink":"https://mhuig.github.io/categories/web/django/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"Django","slug":"django","permalink":"https://mhuig.github.io/tags/django/"}]},{"title":"Mysql与pycharm的设置","slug":"Django/mysql与pycharm的设置","date":"2019-09-22T07:07:16.000Z","updated":"2019-09-22T07:07:16.000Z","comments":true,"path":"posts/30b27542.html","link":"","permalink":"https://mhuig.github.io/posts/30b27542.html","excerpt":"mysql与pycharm的设置","text":"mysql与pycharm的设置 mysql与pycharm的设置 保证mysql已经安装成功 使用终端在mysql中创建一个数据库 mysql -u root -p *** #连接数据库 mysql&gt; show databases; #查看当前数据库 mysql&gt; create database tour; #创建数据库 tour：数据库名，可以自己命名 &lt;!--hexoPostRenderEscape:&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;- 找到setting.py文件，并在添加如下代码&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#96;&amp;#96;&amp;#96;python&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;DATABASES &amp;#x3D; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;#39;default&amp;#39;: &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; # &amp;#39;ENGINE&amp;#39;: &amp;#39;django.db.backends.sqlite3&amp;#39;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; # &amp;#39;NAME&amp;#39;: os.path.join(BASE_DIR, &amp;#39;db.sqlite3&amp;#39;),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;#39;ENGINE&amp;#39;: &amp;#39;django.db.backends.mysql&amp;#39;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;#39;NAME&amp;#39;: &amp;#39;tour&amp;#39;, #数据库名字&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;quot;USER&amp;quot;:&amp;quot;root&amp;quot;, #数据库用户名&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;quot;PASSWORD&amp;quot;:&amp;quot;root&amp;quot;, #数据库的密码&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;quot;HOST&amp;quot;:&amp;quot;127.0.0.1&amp;quot;, #ip地址&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;quot;PORT&amp;quot;:&amp;quot;3306&amp;quot;,# 端口号&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;:hexoPostRenderEscape--&gt; 注意：在使用数据库的时候，必须保证数据库的服务是开启的状态 net start mysql 找到mysql的安装地址，找到bin文件夹，到bin文件夹下面找到mysqld.exe，双击执行 到与setting.py同目录的init.py文件下，添加以下代码 import pymysql pymysql.install_as_MySQLdb() &lt;!--hexoPostRenderEscape:&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;**注意** 若没有安装pymysql模块，则会报错，需要将pymsql模块安装&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#96;&amp;#96;&amp;#96;python&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;1.使用pycharm安装&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2.使用pip安装&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;pip install pymsql&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;:hexoPostRenderEscape--&gt; 当项目创建之后，配置完成之后，我们执行一下迁移【因为只有执行迁移的时候，才会在数据库中生成表】 python manage.py migrate &lt;!--hexoPostRenderEscape:&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;- 需要在models.py文件中创建一个类，并且这个类必须要继承models.Model&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;- &amp;#96;&amp;#96;&amp;#96;python&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; class User(models.Model):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; username &amp;#x3D; models.CharField(max_length&amp;#x3D;20)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; password &amp;#x3D; models.CharField(max_length&amp;#x3D;20)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; #CharField 指定字段的类型&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; #max_length 指定字段的最大长度&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;:hexoPostRenderEscape--&gt; - 生成迁移文件 - ```pyhthon python manage.py makemigrations &lt;!--hexoPostRenderEscape:&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;- 执行迁移文件&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;- &amp;#96;&amp;#96;&amp;#96;python&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; python manage.py migrate&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;:hexoPostRenderEscape--&gt;","categories":[{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/categories/web/"},{"name":"Django","slug":"web/django","permalink":"https://mhuig.github.io/categories/web/django/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"Django","slug":"django","permalink":"https://mhuig.github.io/tags/django/"},{"name":"mysql","slug":"mysql","permalink":"https://mhuig.github.io/tags/mysql/"}]},{"title":"Django的环境配置","slug":"Django/Django的环境配置","date":"2019-09-22T07:06:15.000Z","updated":"2019-09-22T07:06:15.000Z","comments":true,"path":"posts/42ecd398.html","link":"","permalink":"https://mhuig.github.io/posts/42ecd398.html","excerpt":"Django环境配置","text":"Django环境配置 Django的环境配置python环境是ok的pip是可用的 pip用来安装第三方包的 创建虚拟环境【可以先不写】 linux/mac windows 安装Django 1pip install django==1.11.7 django安装成功之后，创建项目 创建项目之前首先新建一个目录【文件夹】 进入这个目录之后执行 12django-admin startproject projectname#django-admin startproject 项目名 使用pycharm打开项目的时候，要在manage.py的上一级打开 manage所在的文件夹 当进入pychram之后，我们可以使用自带终端来创建app1python manage.py startapp appname 当app创建完成之后，需要在setting.py文件中配置123456789INSTALLED_APPS = [ &#x27;django.contrib.admin&#x27;, &#x27;django.contrib.auth&#x27;, &#x27;django.contrib.contenttypes&#x27;, &#x27;django.contrib.sessions&#x27;, &#x27;django.contrib.messages&#x27;, &#x27;django.contrib.staticfiles&#x27;, &quot;App&quot;,#添加我们创建的app] 在setting.py文件中 ALLOWED_HOSTS = [&quot;*&quot;] #允许所有人访问 &lt;!--hexoPostRenderEscape:&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;### 在setting.py文件中&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &amp;#96;&amp;#96;&amp;#96;python&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; #设置语言&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; LANGUAGE_CODE &amp;#x3D; &amp;#39;zh-hans&amp;#39;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; #设置时区&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; TIME_ZONE &amp;#x3D; &amp;#39;Asia&amp;#x2F;Shanghai&amp;#39;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;:hexoPostRenderEscape--&gt; 运行当前项目1python manage.py runserver 运行成功，在浏览器访问12http:&#x2F;&#x2F;127.0.0.1:8000&#x2F;#会显示正常工作 添加一个路由，在urls.py文件中添加12345urlpatterns = [ url(r&#x27;^admin/&#x27;, admin.site.urls), # alt+enter 添加,需要导包，App下面的views url(r&quot;^login/&quot;,views.login),] 需要在app中的views.py去创建视图函数login 123def login(request): #必须返回的是httpResponse对象 return HttpResponse(&quot;你真是一个小机灵鬼！！！&quot;) 执行python manage.py runserver 将服务器重新部署 在浏览器访问的时候，这时候需要使用 1http:&#x2F;&#x2F;127.0.0.1:8000&#x2F;login","categories":[{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/categories/web/"},{"name":"Django","slug":"web/django","permalink":"https://mhuig.github.io/categories/web/django/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"Django","slug":"django","permalink":"https://mhuig.github.io/tags/django/"}]},{"title":"Mysql的使用","slug":"Django/mysql的使用","date":"2019-09-22T07:04:38.000Z","updated":"2019-09-22T07:04:38.000Z","comments":true,"path":"posts/606a512e.html","link":"","permalink":"https://mhuig.github.io/posts/606a512e.html","excerpt":"mysql的简单配置使用","text":"mysql的简单配置使用 mysql的使用 免安装版本 解压mysql压缩包【记得解压的文件路径】 进行环境变量的配置 我的电脑–》属性—》高级环境变量设置–》找到path –》新建–》将mysql的路径【bin的路径】直接复制粘贴 启动数据库 先进入mysql的解压文件–》找到bin文件夹–》双击执行mysqld.exe文件 连接数据库 mysql -u root -p root【默认密码】 数据库连接成功之后，可以查看数据库 show databases; //查看数据库 use 数据库名 ; //使用某个指定的数据库 show tables; //查看所有的表 create database 数据库名; //创建数据库 drop database 数据库名; //删除数据库","categories":[{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/categories/web/"},{"name":"Django","slug":"web/django","permalink":"https://mhuig.github.io/categories/web/django/"}],"tags":[{"name":"Django","slug":"django","permalink":"https://mhuig.github.io/tags/django/"},{"name":"mysql","slug":"mysql","permalink":"https://mhuig.github.io/tags/mysql/"}]},{"title":"Frp内网穿透","slug":"CentOS/Frp内网穿透","date":"2019-09-22T06:30:50.000Z","updated":"2019-09-22T06:30:50.000Z","comments":true,"path":"posts/48a2d97d.html","link":"","permalink":"https://mhuig.github.io/posts/48a2d97d.html","excerpt":"frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp 协议，为 http 和 https 应用协议提供了额外的能力，且尝试性支持了点对点穿透。","text":"frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp 协议，为 http 和 https 应用协议提供了额外的能力，且尝试性支持了点对点穿透。 github 启动 frps 123cd &#x2F;Main&#x2F;frp_024.1_server&#x2F;chmod -Rf 777 .&#x2F;*.&#x2F;frps -c frps.ini 相关配置 12345678# frps.ini[common]bind_port &#x3D; 7000token &#x3D; yourtokendashboard_port &#x3D; 7500dashboard_user &#x3D; usernamedashboard_pwd &#x3D; yourpasswordvhost_http_port &#x3D; 9000 #设置 http 访问端口 1234567891011121314# frpc.ini[common]server_addr &#x3D; x.x.x.x #假设 frps 所在服务器的公网 IP 为 x.x.x.xserver_port &#x3D; 7000 #与frps.ini bind_port一致token &#x3D; yourtoken #与frps.ini token一致#[ssh]#type &#x3D; tcp#local_ip &#x3D; 127.0.0.1#local_port &#x3D; 22#remote_port &#x3D; 8080[web]type &#x3D; httplocal_port &#x3D; 8000 #本地机器上 web 服务对应的端口custom_domains &#x3D; www.yourdomain.com #绑定自定义域名或serverip 关闭防火墙 12systemctl stop firewalld.servicesystemctl disable firewalld.service 设置开机自启动 1vim &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;frps.service 1234567891011121314151617181920212223#frps.service[Unit]Description&#x3D;fraps serviceAfter&#x3D;network.target syslog.targetWants&#x3D;network.target[Service]Type&#x3D;simple#启动服务的命令（此处写你的frps的实际安装目录）ExecStart&#x3D;&#x2F;Main&#x2F;frp_024.1_server&#x2F;frps -c &#x2F;Main&#x2F;frp_024.1_server&#x2F;frps.ini[Install]WantedBy&#x3D;multi-user.target 然后就启动frps 1sudo systemctl start frps 再打开自启动 1sudo systemctl enable frps 如果要重启应用，可以这样 1sudo systemctl restart frps 如果要停止应用，可以输入 1sudo systemctl stop frps 如果要查看应用的日志，可以输入 1sudo systemctl status frps","categories":[{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/categories/web/"},{"name":"内网穿透","slug":"web/内网穿透","permalink":"https://mhuig.github.io/categories/web/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"}],"tags":[{"name":"内网穿透","slug":"内网穿透","permalink":"https://mhuig.github.io/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"Frp","slug":"frp","permalink":"https://mhuig.github.io/tags/frp/"}]},{"title":"CentOS7设置Jupyter","slug":"CentOS/CentOS7设置Jupyter","date":"2019-09-22T06:05:46.000Z","updated":"2019-09-22T06:05:46.000Z","comments":true,"path":"posts/c2c98f74.html","link":"","permalink":"https://mhuig.github.io/posts/c2c98f74.html","excerpt":"Jupyter Notebook（前身是IPython Notebook）是一个基于Web的交互式计算环境，用于创建Jupyter Notebook文档。Notebook一词可以通俗地引用许多不同的实体，主要是Jupyter Web应用程序、Jupyter Python Web服务器或Jupyter文档格式（取决于上下文）。Jupyter Notebook文档是一个JSON文档，遵循版本化模式，包含一个有序的输入/输出单元格列表，这些单元格可以包含代码、文本（使用Markdown语言）、数学、图表和富媒体，通常以“.ipynb”结尾扩展。","text":"Jupyter Notebook（前身是IPython Notebook）是一个基于Web的交互式计算环境，用于创建Jupyter Notebook文档。Notebook一词可以通俗地引用许多不同的实体，主要是Jupyter Web应用程序、Jupyter Python Web服务器或Jupyter文档格式（取决于上下文）。Jupyter Notebook文档是一个JSON文档，遵循版本化模式，包含一个有序的输入/输出单元格列表，这些单元格可以包含代码、文本（使用Markdown语言）、数学、图表和富媒体，通常以“.ipynb”结尾扩展。 启动1jupyter notebook --allow-root --ip 0.0.0.0 --port 9999 默认不允许/不建议root启动jupyter,如果非要用，加上–allow-root–ip ip填写0.0.0.0 或者本机ip–port 端口号 启动后，浏览器访问对应ip和端口就行，需要输入token,token在启动界面有输出 生产配置文件每次记住token，复制再登录不现实 1jupyter notebook --generate-config 生成的配置文件位于 1~&#x2F;.jupyter&#x2F;jupyter_notebook_config.py 1jupyter-notebook password 输入两遍密码 启动，就可以 以固定密码登录了 1jupyter notebook --allow-root --ip 0.0.0.0 --port 999 设置浏览器打开jupyter默认路径1vim ~&#x2F;.jupyter&#x2F;jupyter_notebook_config.py 填写自己想要的服务器路径1c.NotebookApp.notebook_dir&#x3D;&#39;&#x2F;&#39; 设置jupyter开机启动systemctl脚本目录：/usr/lib/systemd/系统服务目录：/usr/lib/systemd/system/用户服务目录：/usr/lib/systemd/system/ 1cd &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F; 1vim myjupyter.service 12345678910111213141516171819202122232425262728293031[UNIT]#服务描述Description&#x3D;python jupyter Service#指定了在systemd在执行完那些target之后再启动该服务After&#x3D;network.target[Service]#定义Service的运行类型，一般是forking(后台运行) #Type&#x3D;forking 这个会卡住啊,不写Type 或者 如下Type&#x3D;simple#定义systemctl start|stop|reload *.service 的执行方法（具体命令需要写绝对路径）#注：ExecStartPre为启动前执行的命令# ExecStartPre&#x3D;&#x2F;usr&#x2F;bin&#x2F;test &quot;x$&#123;NETWORKMANAGER&#125;&quot; &#x3D; xyesExecStart&#x3D;&#x2F;root&#x2F;anaconda3&#x2F;bin&#x2F;jupyter notebook --allow-root --ip 0.0.0.0 --port 9999#ExecReload&#x3D;# ExecStop&#x3D;&#x2F;home&#x2F;mobileoa&#x2F;apps&#x2F;shMediaManager.sh -stop#创建私有的内存临时空间PrivateTmp&#x3D;True[Install]#多用户WantedBy&#x3D;multi-user.target 1vi &#x2F;root&#x2F;.jupyter&#x2F;jupyter_notebook_config.py 12345678# Set ip to &#39;*&#39; to bind on all interfaces (ips) for the public serverc.NotebookApp.ip &#x3D; &#39;*&#39;# It is a good idea to set a known, fixed port for server accessyc.NotebookApp.port &#x3D; 9999# 是否打开浏览器c.NotebookApp.open_browser &#x3D; False#设置工作路径c.NotebookApp.notebook_dir &#x3D; &#39;&#x2F;&#39; 重载系统服务1systemctl daemon-reload 设置开机启动1systemctl enable myjupyter.service 启动服务1systemctl start myjupyter.service 停止服务1systemctl stop myjupyter.service 重启服务1systemctl restart myjupyter.service Notebook支持虚拟运行环境为了让Jupyter Notebook支持虚拟运行环境，需要在Anaconda里安装一个插件。回到终端下面，用C-c退出目前正在运行的Jupyter Notebook Server，然后执行： 1conda install nb_conda 再重新开启 1Jupyter Notebook 或者(better) 安装 ipykernel 首先切换到想要在 jupyter notebook 里使用的虚拟环境： 1conda activate 环境名称 安装 ipykernel： 1conda install ipykernel 写入 jupyter 的 kernel 在当前虚拟环境里执行： 1python -m ipykernel install --user --name 环境名称 --display-name &quot;Python (环境名称)&quot; “环境名称”为当前虚拟环境的名称，最后面引号内的字符串是该虚拟环境显示在 jupyter notebook 界面的名字，可以随意修改。 删除 kernel 环境 上面写入 kernel 的配置并不会随虚拟环境的删除而删除。也就是说即使删除了该虚拟环境，jupyter notebook 的界面上仍会有它的选项，只是无法正常使用。 此时就需要去手动删除 kernel 环境了： 1jupyter kernelspec remove 环境名称 jupyter中用notedown插件来读取md文档1pip install https:&#x2F;&#x2F;github.com&#x2F;mli&#x2F;notedown&#x2F;tarball&#x2F;master 1vi &#x2F;root&#x2F;.jupyter&#x2F;jupyter_notebook_config.py 1c.NotebookApp.contents_manager_class &#x3D; &#39;notedown.NotedownContentsManager&#39; Jupyter Notebook 自定义主题安装好了Jupyter Notebook和Python之后，我们就已经搭建好啦运行和笔记环境，可以愉快的开始学习了。 于是本着爱折腾的精神和护眼的需求，我搜索了Jupyter Notebook的themes，也就是自定义主题。果然Github上有人一早解决了这个问题。 github 12345# install jupyterthemespip install jupyterthemes# upgrade to latest versionpip install --upgrade jupyterthemes 这时候，你就可以在terminal里面调用已经安装好的themes啦～ 例如，在terminal中输入 1jt -l 就会返回所有你安装好的主题的名词列表，这样你就知道了你安装了哪些主题。最终，我的选择是 1jt -t chesterish -T -N 表示我选择了chesterish这个主题，同时希望打开顶部的工具栏（Toolbar），显示笔记本的名字（Name） Jupyter 扩展配置器（ Jupyter NbExtensions Configurator）可以通过 coda 安装： 12conda install -c conda-forge jupyter_contrib_nbextensionsconda install -c conda-forge jupyter_nbextensions_configurator 也可以使用 pip 安装 1234pip install jupyter_nbextensions_configuratorjupyter_contrib_nbextensionsjupyter contrib nbextension install --userjupyter nbextensions_configurator enable --user 1.标题折叠 Collapsible headings 当你在处理一个大型的 notebooks 时，这项扩展非常有用，它可以让你隐藏部分内容。 通知 Notify当你长时间运行一个任务程序的时候，程序运行结束后，此扩展功能会自动提醒你。 如需使用此扩展，你需要勾选其对应得选择框，并点击 Notify 按钮来选择一个最短通知时间，即 notebook 最少持续运行多久后进行提醒。（需要注意的是，这个扩展只有在 notebook 被浏览器正常打开的情况下才能正常工作。） 代码折叠 Code folding 进度条 tqdm_notebook tqdm 本质上不是一个 notebook 的扩展，它是 Python 中的一个进度条库。 但是此库有时在 jupyter notebooks 会无法正常工作。 Randy Olson 给出一个小小的提醒： tqdm 是一个 Python 的进度条库，在 jupyter notebook 中则被称之为 “tqdm_notebook”。自从在 nootbook 中加入了 tqdm_notebook 扩展功能，你再也不用担心其引发的混乱问题了。 （Randy Olson 2018 年 3 月 2 日） %debug这个本质上也不是 notebook 的一个扩展，而是 IPython 中的一个魔法命令。为了加深你的理解，建议你读一读 Radek Osmulski 的发布 twitter 上的推文。 %debug 魔法命令 得到了一个异常 重新插入一个新的输入框，输入 %debug，然后运行它交互式的调试方法可以打开并显示代码出现异常的语句，方便你联系前后程序查看具体情况。(Radek 2017年12月26日) 其他小的拓展与技巧 %Ismagic ：在输入框中运行这个命令，列出所有可用的 IPython 魔法命令 zen mode 扩展： 隐藏菜单栏，让你更专注于代码 Execute time 扩展：显示程序块运行的时间 autoreload：在不重启 notebook 的情况下，自动载入外部文件，从而修改代码，具体操作如下： %load_ext autoreload %autoreload 2 JUPYTER 服务的 NGINX 配置jupyter 配置配置文件在 1&#x2F;home&#x2F;&#123;user&#125;&#x2F;.jupyter&#x2F;jupyter_notebook_config.py 配置 jupyter 的路径 1c.NotebookApp.base_url &#x3D; &#39;&#x2F;jupyter&#x2F;&#39; nginx 配置jupyter 使用了 websocket 协议，所以需要配置支持 websocket。 123456789101112131415location &#x2F;jupyter&#x2F; &#123; proxy_pass http:&#x2F;&#x2F;jupyter; proxy_set_header Host $host; proxy_set_header X-Real-Scheme $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # WebSocket support proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_read_timeout 120s; proxy_next_upstream error;&#125; jupyter notebook 用到了 websocket, 所以需要配置 12proxy_set_header Upgrade $http_upgrade;proxy_set_header Connection &quot;upgrade&quot;;","categories":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"},{"name":"CentOS7","slug":"linux/centos7","permalink":"https://mhuig.github.io/categories/linux/centos7/"},{"name":"Python","slug":"linux/centos7/python","permalink":"https://mhuig.github.io/categories/linux/centos7/python/"}],"tags":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/tags/linux/"},{"name":"CentOS7","slug":"centos7","permalink":"https://mhuig.github.io/tags/centos7/"},{"name":"Jupyter","slug":"jupyter","permalink":"https://mhuig.github.io/tags/jupyter/"}]},{"title":"Centos7安装Anaconda3","slug":"CentOS/Centos7安装Anaconda3","date":"2019-09-22T03:14:48.000Z","updated":"2019-09-22T03:14:48.000Z","comments":true,"path":"posts/6009a9d8.html","link":"","permalink":"https://mhuig.github.io/posts/6009a9d8.html","excerpt":"Anaconda是一个免费开源的Python和R语言的发行版本，用于计算科学（数据科学、机器学习、大数据处理和预测分析），Anaconda致力于简化包管理和部署。","text":"Anaconda是一个免费开源的Python和R语言的发行版本，用于计算科学（数据科学、机器学习、大数据处理和预测分析），Anaconda致力于简化包管理和部署。 安装下载Anaconda方式一：官方网站 方式二：清华大学开源软件镜像站 可以下载到本地，然后通过xftp上传到Contos上 1bash Anaconda3-4.4.0-Linux-x86_64.sh 该按enter按，该yes|no的yes。 1source ~&#x2F;.bashrc 然后重启终端，然后输入python Anaconda虚拟环境创建环境1conda create -n envname python&#x3D;3.6 删除环境1conda remove -n envname --all 激活环境1source activate envname 退出环境1source deactivate Anaconda 换源添加清华源12345conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;free&#x2F;conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;conda-forgeconda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;msys2&#x2F;conda config --set show_channel_urls yes 删源1conda config --remove-key channels 附录清华大学开源软件镜像站 12345channels: - https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;main&#x2F; - https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;free&#x2F; - https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;conda-forge&#x2F;ssl_verify: true 上海交通大学开源镜像站 12345channels: - https:&#x2F;&#x2F;mirrors.sjtug.sjtu.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;main&#x2F; - https:&#x2F;&#x2F;mirrors.sjtug.sjtu.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;free&#x2F; - https:&#x2F;&#x2F;mirrors.sjtug.sjtu.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;conda-forge&#x2F;ssl_verify: true 中国科学技术大学 USTC Mirror 12345channels: - https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;main&#x2F; - https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;free&#x2F; - https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;conda-forge&#x2F;ssl_verify: true .bashrc里面修改过PATH环境变量，添加过anaconda/bin 1vi ~&#x2F;.bashrc 最后添加 1conda deactivate 1source .bashrc","categories":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"},{"name":"CentOS7","slug":"linux/centos7","permalink":"https://mhuig.github.io/categories/linux/centos7/"},{"name":"Python","slug":"linux/centos7/python","permalink":"https://mhuig.github.io/categories/linux/centos7/python/"}],"tags":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/tags/linux/"},{"name":"CentOS7","slug":"centos7","permalink":"https://mhuig.github.io/tags/centos7/"},{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"Anaconda","slug":"anaconda","permalink":"https://mhuig.github.io/tags/anaconda/"}]},{"title":"CentOS7安装Python3","slug":"CentOS/CentOS7安装Python3","date":"2019-09-22T02:57:06.000Z","updated":"2019-09-22T02:57:06.000Z","comments":true,"path":"posts/eeb47c66.html","link":"","permalink":"https://mhuig.github.io/posts/eeb47c66.html","excerpt":"centos7 自带有 python，但是却是 python2 版本的 python，如果你想安装个python3怎么办呢？难道要从github上把源码clone下来进行编译安装么？没错！因为 yum 源中并没有现成的 python3 程序，所以必须要自己手动编译安装。","text":"centos7 自带有 python，但是却是 python2 版本的 python，如果你想安装个python3怎么办呢？难道要从github上把源码clone下来进行编译安装么？没错！因为 yum 源中并没有现成的 python3 程序，所以必须要自己手动编译安装。 首先，你要知道系统现在的python的位置在哪儿： 1whereis python 进入Python安装目录 1ll python* 添加epel扩展源 1yum -y install epel-release 安装pip 1yum install python-pip 用pip装wget 1pip install wget 用wget下载python3的源码包 1wget https:&#x2F;&#x2F;www.python.org&#x2F;ftp&#x2F;python&#x2F;3.6.4&#x2F;Python-3.6.4.tar.xz 编译python3源码包 解压 12xz -d Python-3.6.4.tar.xztar -xf Python-3.6.4.tar 进入解压后的目录，依次执行下面命令进行手动编译 12.&#x2F;configure prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;python3make &amp;&amp; make install 添加软链接将原来的链接备份 1mv &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;python.bak 添加python3的软链接 1ln -s &#x2F;usr&#x2F;local&#x2F;python3&#x2F;bin&#x2F;python3.6 &#x2F;usr&#x2F;bin&#x2F;python 测试是否安装成功了 1python -V 更改yum配置，因为其要用到python2才能执行，否则会导致yum不能正常使用 1vi &#x2F;usr&#x2F;bin&#x2F;yum 把#! /usr/bin/python修改为#! /usr/bin/python2 1vi &#x2F;usr&#x2F;libexec&#x2F;urlgrabber-ext-down 把#! /usr/bin/python 修改为#! /usr/bin/python2 加上pip的修改 12mv &#x2F;usr&#x2F;bin&#x2F;pip &#x2F;usr&#x2F;bin&#x2F;pip.bakln -s &#x2F;usr&#x2F;local&#x2F;python3&#x2F;bin&#x2F;pip3 &#x2F;usr&#x2F;bin&#x2F;pip 1pip -V 修改环境变量 1vi &#x2F;etc&#x2F;profile 12export PYTHON_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;python3export PATH&#x3D;:$PYTHON_HOME&#x2F;bin:$PATH 1source &#x2F;etc&#x2F;profile","categories":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"},{"name":"CentOS7","slug":"linux/centos7","permalink":"https://mhuig.github.io/categories/linux/centos7/"},{"name":"Python","slug":"linux/centos7/python","permalink":"https://mhuig.github.io/categories/linux/centos7/python/"}],"tags":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/tags/linux/"},{"name":"CentOS7","slug":"centos7","permalink":"https://mhuig.github.io/tags/centos7/"},{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"}]},{"title":"Linux安装PHP-EXIF扩展模块","slug":"Linux/Linux安装PHP-EXIF扩展模块","date":"2019-09-22T02:29:41.000Z","updated":"2019-09-22T02:29:41.000Z","comments":true,"path":"posts/d7edfddd.html","link":"","permalink":"https://mhuig.github.io/posts/d7edfddd.html","excerpt":"您可以使用exif相关的函数从文件头读取数码相机拍摄的JPEG和TIFF格式的图像文件元数据。","text":"您可以使用exif相关的函数从文件头读取数码相机拍摄的JPEG和TIFF格式的图像文件元数据。 安装编译PHP时安装使用–enable-exif选项配置PHP来启用exif支持。 Windows用户必须在php.ini中启用php_mbstring.dll和php_exif.dll扩展。请确保在php.ini中保持正确的顺序：php_mbstring.dll必须在php_exif.dll之前加载。 源码安装在PHP源码中可以找到EXIF扩展源码，然后编译安装到当前的PHP环境中 1234cd &#x2F;Main&#x2F;sh-1.5.5&#x2F;php-5.5.7&#x2F;ext&#x2F;exif&#x2F;alidata&#x2F;server&#x2F;php-5.5.7&#x2F;bin&#x2F;phpize.&#x2F;configure --with-php-config&#x3D;&#x2F;alidata&#x2F;server&#x2F;php-5.5.7&#x2F;bin&#x2F;php-configmake &amp;&amp; make install cd进入/alidata/server/php-5.5.7/etc文件夹，修改php.ini，添加exif.so扩展 1extension = exif.so 重启Apache服务器1service httpd restart Nginx的服务器Nginx服务器重启之前，需要先重启php-fpm 12service php-fpm restartnginx -s reload 查看使用phpinfo()查看PHP环境，安装配置成功。","categories":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/tags/linux/"},{"name":"php","slug":"php","permalink":"https://mhuig.github.io/tags/php/"}]},{"title":"云服务器部署可道云(KodExplorer)","slug":"Linux/云服务器部署可道云-KodExplorer","date":"2019-09-22T01:29:24.000Z","updated":"2019-09-22T01:29:24.000Z","comments":true,"path":"posts/9ef6ff16.html","link":"","permalink":"https://mhuig.github.io/posts/9ef6ff16.html","excerpt":"在做一些项目的时候，经常有一些文档交流，修改之后的文档在QQ或微信上发来发去，还要下载，我们在这里部署KodExplorer可道云。 kodexplorer可道云是目前国内有代表性、美观易用性好的私有云软件，本文介绍在阿里云的云服务器上如何部署kodexplorer可道云，搭建私有网盘。","text":"在做一些项目的时候，经常有一些文档交流，修改之后的文档在QQ或微信上发来发去，还要下载，我们在这里部署KodExplorer可道云。 kodexplorer可道云是目前国内有代表性、美观易用性好的私有云软件，本文介绍在阿里云的云服务器上如何部署kodexplorer可道云，搭建私有网盘。 注意：云服务器部署和普通的Ubuntu上部署有一些区别，因为云服务器上只能使用命令行，没有界面。 官方下载页面:https://kodcloud.com/download/。其中有Linux获取最新版可道云的相关命令。 下载命令： 1wget http:&#x2F;&#x2F;static.kodcloud.com&#x2F;update&#x2F;download&#x2F;kodexplorer4.40.zip 创建目录： 1sudo mkdir cloud 解压命令： 1unzip kodexplorer4.40.zip -d .&#x2F;cloud 进入对应文件夹，并设置权限： 1234chmod -Rf 777 .&#x2F;cloudcd .&#x2F;cloudchmod -Rf 777 .&#x2F;*","categories":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/tags/linux/"},{"name":"cloud","slug":"cloud","permalink":"https://mhuig.github.io/tags/cloud/"}]},{"title":"一键安装Ecs服务器的web环境(阿里云)","slug":"CentOS/一键安装ecs服务器的web环境-阿里云","date":"2019-09-22T00:27:11.000Z","updated":"2019-09-22T00:27:11.000Z","comments":true,"path":"posts/c91f449a.html","link":"","permalink":"https://mhuig.github.io/posts/c91f449a.html","excerpt":"阿里云Linux一键安装web环境使用教程","text":"阿里云Linux一键安装web环境使用教程 教程1.准备工具阿里云linux一键安装web环境 2.将安装包上传到服务器上ftp,putty等. 3.解压安装包进行安装1234unzip -o -d . sh-1.5.5.zipchmod -R 777 sh-1.5.5cd sh-1.5.5&#x2F;.&#x2F;install.sh 4.Mysql选择的5.5.40版本，其他版本会出现问题;php选择5.5.7版本;5.安装完成查看自己安装的信息1netstat -tunpl 正在运行状态的服务及端口 9000 端口：php进程服务(apache没有9000端口，因为nginx+php集成方式与apache+php集成方式不同） 3306端口：mysql服务 80端口：httpd或者nginx服务 21端口：ftp服务 6.查看ftp和mysql用户名和密码1cat account.log 7.修改ftp的密码使用root身份执行如下命令： 1passwd www 8.修改mysql的密码：1mysqladmin -uroot -p旧密码 password 新密码 注：-p 和旧密码之间没有空格，password 和新密码之间有空格 另外，我们也可以在在/alidata/website-info.log文件中查看到安装软件的版本信息 9.清空phpwind文件夹12cd &#x2F;alidata&#x2F;www&#x2F;phpwindrm -rf &#x2F;alidata&#x2F;www&#x2F;phpwind&#x2F;* 10.安装phpMyAdmin下载数据库管理软件:phpMyAdmin,不要下载带有“betal”字样的版本，那是测试版。排序规则选：utf8_general_ci 12wget https:&#x2F;&#x2F;files.phpmyadmin.net&#x2F;phpMyAdmin&#x2F;4.9.1&#x2F;phpMyAdmin-4.9.1-all-languages.tar.gztar -zxvf phpMyAdmin-4.9.1-all-languages.tar.gz 附录Linux下的解压命令小结 unzip filename. zip tar -zxvf filename. tar.gz tar -Jxvf filename. tar.xz tar -Zxvf filename. tar.Z tar –help tar -xvf filename. tar.gz tar -xvf filename phpMyAdmin配置文件现在需要一个短语密码解决方法phpMyAdmin登陆之后，在其下方会出现配置文件现在需要一个短语密码的提示。 解决方法： 1、将 phpMyAdmin/libraries/config.default.php中的$cfg[‘blowfish_secret’] = ‘’; 改成 $cfg[‘blowfish_secret’] = ‘thepie.top’; (注：其中的’thepie.top′为随意的长字符串) 2、在phpMyAdmin目录中，打开config.sample.inc.php，17行 $cfg[‘blowfish_secret’] = ‘’; 改成 $cfg[‘blowfish_secret’] = ‘thepie.top’; (注：其中的’thepie.top′为随意的长字符串) 这个密码用于Cookies的加密，以免多个PhpMyAdmin或者和其他程序共用Cookies时搞混。 变量 $cfg[‘TempDir’] （./tmp/）无法访问。phpMyAdmin无法缓存模板文件，所以会运行缓慢。出现这个的原因是 phpmyadmin的安装目录， tmp目录不存在，或者存在但是权限不对。解决的方法就是没有创建一下这个目录，给予正确的读写权限即可。进入phpmyadmin的安装目录然后执行 12mkdir tmpchmod 777 tmp phpmyadmin 提示的很清楚，这是个缓存目录，可以加快phpmyadmin的运行，即使不理睬这个警告信息，也不会影响程序的执行，就是执行的慢点。","categories":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/tags/linux/"},{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/tags/web/"}]},{"title":"CentOS7安装GUI图形界面","slug":"CentOS/CentOS7安装GUI图形界面","date":"2019-09-21T08:23:03.000Z","updated":"2019-09-21T08:23:03.000Z","comments":true,"path":"posts/bbe38b68.html","link":"","permalink":"https://mhuig.github.io/posts/bbe38b68.html","excerpt":"当你安装CentOS7服务器版本的时候，系统默认是不会安装GUI的图形界面程序，这个需要手动安装CentOS7 Gnome GUI包。","text":"当你安装CentOS7服务器版本的时候，系统默认是不会安装GUI的图形界面程序，这个需要手动安装CentOS7 Gnome GUI包。 在安装Gnome包之前，需要检查一下安装源(yum)是否正常，因为需要在yum命令来安装gnome包。 第一步：先检查yum 是否安装，以及网络是否有网络。如果这两者都没有，先解决网络，在解决yum的安装。 第二步：在命令行下 输入下面的命令来安装Gnome包。 1yum groupinstall &quot;GNOME Desktop&quot; &quot;Graphical Administration Tools&quot; 第三步：更新系统的运行级别。 1ln -sf /lib/systemd/system/runlevel5.target /etc/systemd/system/default.target 第四步：重启机器。启动默认进入图形界面。 1reboot Linux查看端口状态 1netstat -ntulp |grep 8000 杀进程 1kill -9 id","categories":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"},{"name":"CentOS7","slug":"linux/centos7","permalink":"https://mhuig.github.io/categories/linux/centos7/"}],"tags":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/tags/linux/"},{"name":"CentOS7","slug":"centos7","permalink":"https://mhuig.github.io/tags/centos7/"}]},{"title":"大数据处理技术-数据可视化Echarts介绍","slug":"bigdata/大数据处理技术 - 数据可视化Echarts介绍","date":"2019-09-19T03:25:51.000Z","updated":"2019-09-19T03:25:51.000Z","comments":true,"path":"posts/f4e10e30.html","link":"","permalink":"https://mhuig.github.io/posts/f4e10e30.html","excerpt":"大数据处理技术 PDF 数据可视化Echarts介绍","text":"大数据处理技术 PDF 数据可视化Echarts介绍 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Echarts","slug":"大数据/大数据处理技术/echarts","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/echarts/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Echarts","slug":"echarts","permalink":"https://mhuig.github.io/tags/echarts/"}]},{"title":"大数据处理技术-工作流调度器Azkaban","slug":"bigdata/大数据处理技术 -工作流调度器azkaban","date":"2019-09-19T03:25:50.000Z","updated":"2019-09-19T03:25:50.000Z","comments":true,"path":"posts/8485750c.html","link":"","permalink":"https://mhuig.github.io/posts/8485750c.html","excerpt":"大数据处理技术 PDF 工作流调度器azkaban","text":"大数据处理技术 PDF 工作流调度器azkaban GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Azkaban","slug":"大数据/大数据处理技术/azkaban","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/azkaban/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Azkaban","slug":"azkaban","permalink":"https://mhuig.github.io/tags/azkaban/"}]},{"title":"大数据处理技术-Sqoop数据迁移","slug":"bigdata/大数据处理技术 - sqoop数据迁移","date":"2019-09-19T03:25:49.000Z","updated":"2019-09-19T03:25:49.000Z","comments":true,"path":"posts/bfbc2e0b.html","link":"","permalink":"https://mhuig.github.io/posts/bfbc2e0b.html","excerpt":"大数据处理技术 PDF sqoop数据迁移","text":"大数据处理技术 PDF sqoop数据迁移 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Sqoop","slug":"大数据/大数据处理技术/sqoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/sqoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Sqoop","slug":"sqoop","permalink":"https://mhuig.github.io/tags/sqoop/"}]},{"title":"大数据处理技术-Kafka-Manager监控工具的使用","slug":"bigdata/大数据处理技术 - kafka-manager监控工具的使用","date":"2019-09-19T03:25:48.000Z","updated":"2019-09-19T03:25:48.000Z","comments":true,"path":"posts/10cabcd3.html","link":"","permalink":"https://mhuig.github.io/posts/10cabcd3.html","excerpt":"大数据处理技术 PDF kafka-manager监控工具的使用","text":"大数据处理技术 PDF kafka-manager监控工具的使用 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"大数据/大数据处理技术/kafka","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/kafka/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"kafka","permalink":"https://mhuig.github.io/tags/kafka/"}]},{"title":"大数据处理技术-Flume与kafka的整合","slug":"bigdata/大数据处理技术 - flume与kafka的整合","date":"2019-09-19T03:25:47.000Z","updated":"2019-09-19T03:25:47.000Z","comments":true,"path":"posts/a4a39746.html","link":"","permalink":"https://mhuig.github.io/posts/a4a39746.html","excerpt":"大数据处理技术 PDF flume与kafka的整合","text":"大数据处理技术 PDF flume与kafka的整合 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"大数据/大数据处理技术/kafka","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/kafka/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"flume","permalink":"https://mhuig.github.io/tags/flume/"},{"name":"Kafka","slug":"kafka","permalink":"https://mhuig.github.io/tags/kafka/"}]},{"title":"大数据处理技术-Kafka的配置文件的说明","slug":"bigdata/大数据处理技术 -kafka的配置文件的说明","date":"2019-09-19T03:25:46.000Z","updated":"2019-09-19T03:25:46.000Z","comments":true,"path":"posts/4e6873c5.html","link":"","permalink":"https://mhuig.github.io/posts/4e6873c5.html","excerpt":"大数据处理技术 PDF kafka的配置文件的说明","text":"大数据处理技术 PDF kafka的配置文件的说明 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"大数据/大数据处理技术/kafka","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/kafka/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"kafka","permalink":"https://mhuig.github.io/tags/kafka/"}]},{"title":"大数据处理技术-Kafka的数据的分区","slug":"bigdata/大数据处理技术 - kafka的数据的分区","date":"2019-09-19T03:25:45.000Z","updated":"2019-09-19T03:25:45.000Z","comments":true,"path":"posts/c8fc3430.html","link":"","permalink":"https://mhuig.github.io/posts/c8fc3430.html","excerpt":"大数据处理技术 PDF kafka的数据的分区","text":"大数据处理技术 PDF kafka的数据的分区 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"大数据/大数据处理技术/kafka","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/kafka/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"kafka","permalink":"https://mhuig.github.io/tags/kafka/"}]},{"title":"大数据处理技术-kafka的javaAPI的使用","slug":"bigdata/大数据处理技术 - kafka的javaAPI的使用","date":"2019-09-19T03:25:44.000Z","updated":"2019-09-19T03:25:44.000Z","comments":true,"path":"posts/32c5d0d9.html","link":"","permalink":"https://mhuig.github.io/posts/32c5d0d9.html","excerpt":"大数据处理技术 PDF kafka的javaAPI的使用","text":"大数据处理技术 PDF kafka的javaAPI的使用 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"大数据/大数据处理技术/kafka","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/kafka/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"kafka","permalink":"https://mhuig.github.io/tags/kafka/"}]},{"title":"大数据处理技术-Kafka的命令行的管理使用","slug":"bigdata/大数据处理技术 - kafka的命令行的管理使用","date":"2019-09-19T03:25:43.000Z","updated":"2019-09-19T03:25:43.000Z","comments":true,"path":"posts/aa02a436.html","link":"","permalink":"https://mhuig.github.io/posts/aa02a436.html","excerpt":"大数据处理技术 PDF kafka的命令行的管理使用","text":"大数据处理技术 PDF kafka的命令行的管理使用 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"大数据/大数据处理技术/kafka","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/kafka/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"kafka","permalink":"https://mhuig.github.io/tags/kafka/"}]},{"title":"大数据处理技术-Kafka的安装","slug":"bigdata/大数据处理技术 -kafka的安装","date":"2019-09-19T03:25:42.000Z","updated":"2019-09-19T03:25:42.000Z","comments":true,"path":"posts/f77eee2d.html","link":"","permalink":"https://mhuig.github.io/posts/f77eee2d.html","excerpt":"大数据处理技术 PDF kafka的安装","text":"大数据处理技术 PDF kafka的安装 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"大数据/大数据处理技术/kafka","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/kafka/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"kafka","permalink":"https://mhuig.github.io/tags/kafka/"}]},{"title":"大数据处理技术-Flume的负载均衡loadbalancer","slug":"bigdata/大数据处理技术 - flume的负载均衡loadbalancer","date":"2019-09-19T03:25:41.000Z","updated":"2019-09-19T03:25:41.000Z","comments":true,"path":"posts/c89a329f.html","link":"","permalink":"https://mhuig.github.io/posts/c89a329f.html","excerpt":"大数据处理技术 PDF flume的负载均衡loadbalancer","text":"大数据处理技术 PDF flume的负载均衡loadbalancer GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"大数据/大数据处理技术/flume","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/flume/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"flume","permalink":"https://mhuig.github.io/tags/flume/"}]},{"title":"大数据处理技术-Kafka的介绍","slug":"bigdata/大数据处理技术 - kafka的介绍","date":"2019-09-19T03:25:41.000Z","updated":"2019-09-19T03:25:41.000Z","comments":true,"path":"posts/b9b7baa7.html","link":"","permalink":"https://mhuig.github.io/posts/b9b7baa7.html","excerpt":"大数据处理技术 PDF kafka的介绍","text":"大数据处理技术 PDF kafka的介绍 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"大数据/大数据处理技术/kafka","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/kafka/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Kafka","slug":"kafka","permalink":"https://mhuig.github.io/tags/kafka/"}]},{"title":"大数据处理技术-高可用Flume","slug":"bigdata/大数据处理技术 - 高可用Flume","date":"2019-09-19T03:25:40.000Z","updated":"2019-09-19T03:25:40.000Z","comments":true,"path":"posts/a105df5c.html","link":"","permalink":"https://mhuig.github.io/posts/a105df5c.html","excerpt":"大数据处理技术 PDF 高可用Flume","text":"大数据处理技术 PDF 高可用Flume GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"大数据/大数据处理技术/flume","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/flume/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"flume","permalink":"https://mhuig.github.io/tags/flume/"}]},{"title":"大数据处理技术-Flume更多source和sink组件","slug":"bigdata/大数据处理技术 - Flume更多source和sink组件","date":"2019-09-19T03:25:39.000Z","updated":"2019-09-19T03:25:39.000Z","comments":true,"path":"posts/801b51ef.html","link":"","permalink":"https://mhuig.github.io/posts/801b51ef.html","excerpt":"大数据处理技术 PDF Flume更多source和sink组件","text":"大数据处理技术 PDF Flume更多source和sink组件 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"大数据/大数据处理技术/flume","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/flume/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"flume","permalink":"https://mhuig.github.io/tags/flume/"}]},{"title":"大数据处理技术-Flume两个agent级联","slug":"bigdata/大数据处理技术 -Flume两个agent级联","date":"2019-09-19T03:25:38.000Z","updated":"2019-09-19T03:25:38.000Z","comments":true,"path":"posts/d8795dab.html","link":"","permalink":"https://mhuig.github.io/posts/d8795dab.html","excerpt":"大数据处理技术 PDF Flume两个agent级联","text":"大数据处理技术 PDF Flume两个agent级联 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"大数据/大数据处理技术/flume","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/flume/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"flume","permalink":"https://mhuig.github.io/tags/flume/"}]},{"title":"大数据处理技术-Flume采集案例监控目录变化","slug":"bigdata/大数据处理技术 -Flume采集案例监控目录变化","date":"2019-09-19T03:25:37.000Z","updated":"2019-09-19T03:25:37.000Z","comments":true,"path":"posts/8ce758a7.html","link":"","permalink":"https://mhuig.github.io/posts/8ce758a7.html","excerpt":"大数据处理技术 PDF Flume采集案例监控目录变化","text":"大数据处理技术 PDF Flume采集案例监控目录变化 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"大数据/大数据处理技术/flume","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/flume/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"flume","permalink":"https://mhuig.github.io/tags/flume/"}]},{"title":"大数据处理技术-Flume的安装部署","slug":"bigdata/大数据处理技术 - Flume的安装部署","date":"2019-09-19T03:25:36.000Z","updated":"2019-09-19T03:25:36.000Z","comments":true,"path":"posts/75ee5fa.html","link":"","permalink":"https://mhuig.github.io/posts/75ee5fa.html","excerpt":"大数据处理技术 PDF Flume的安装部署","text":"大数据处理技术 PDF Flume的安装部署 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"大数据/大数据处理技术/flume","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/flume/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"flume","permalink":"https://mhuig.github.io/tags/flume/"}]},{"title":"大数据处理技术-Flume介绍","slug":"bigdata/大数据处理技术 - Flume介绍","date":"2019-09-19T03:25:35.000Z","updated":"2019-09-19T03:25:35.000Z","comments":true,"path":"posts/a5eec80c.html","link":"","permalink":"https://mhuig.github.io/posts/a5eec80c.html","excerpt":"大数据处理技术 PDF Flume介绍","text":"大数据处理技术 PDF Flume介绍 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"大数据/大数据处理技术/flume","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/flume/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Flume","slug":"flume","permalink":"https://mhuig.github.io/tags/flume/"}]},{"title":"大数据处理技术-关于Yarn常用参数设置","slug":"bigdata/大数据处理技术 - 关于yarn常用参数设置","date":"2019-09-19T03:25:34.000Z","updated":"2019-09-19T03:25:34.000Z","comments":true,"path":"posts/780b9de2.html","link":"","permalink":"https://mhuig.github.io/posts/780b9de2.html","excerpt":"大数据处理技术 PDF 关于yarn常用参数设置","text":"大数据处理技术 PDF 关于yarn常用参数设置 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Yarn","slug":"大数据/大数据处理技术/yarn","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/yarn/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Yarn","slug":"yarn","permalink":"https://mhuig.github.io/tags/yarn/"}]},{"title":"大数据处理技术-Yarn资源调度","slug":"bigdata/大数据处理技术 - Yarn资源调度","date":"2019-09-19T03:25:33.000Z","updated":"2019-09-19T03:25:33.000Z","comments":true,"path":"posts/c5520104.html","link":"","permalink":"https://mhuig.github.io/posts/c5520104.html","excerpt":"大数据处理技术 PDF Yarn资源调度","text":"大数据处理技术 PDF Yarn资源调度 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Yarn","slug":"大数据/大数据处理技术/yarn","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/yarn/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Yarn","slug":"yarn","permalink":"https://mhuig.github.io/tags/yarn/"}]},{"title":"大数据处理技术-Hive语句综合练习","slug":"bigdata/大数据处理技术 -hive语句综合练习","date":"2019-09-19T03:25:32.000Z","updated":"2019-09-19T03:25:32.000Z","comments":true,"path":"posts/b4fa1b4e.html","link":"","permalink":"https://mhuig.github.io/posts/b4fa1b4e.html","excerpt":"大数据处理技术 PDF hive语句综合练习","text":"大数据处理技术 PDF hive语句综合练习 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hive","slug":"大数据/大数据处理技术/hive","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hive/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hive","slug":"hive","permalink":"https://mhuig.github.io/tags/hive/"}]},{"title":"大数据处理技术-Hive创建数据库表","slug":"bigdata/大数据处理技术 - Hive创建数据库表","date":"2019-09-19T03:25:31.000Z","updated":"2019-09-19T03:25:31.000Z","comments":true,"path":"posts/48a224d1.html","link":"","permalink":"https://mhuig.github.io/posts/48a224d1.html","excerpt":"大数据处理技术 PDF Hive创建数据库表","text":"大数据处理技术 PDF Hive创建数据库表 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hive","slug":"大数据/大数据处理技术/hive","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hive/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hive","slug":"hive","permalink":"https://mhuig.github.io/tags/hive/"}]},{"title":"大数据处理技术-Hive基本操作之创建数据库","slug":"bigdata/大数据处理技术 - Hive基本操作之创建数据库","date":"2019-09-19T03:25:30.000Z","updated":"2019-09-19T03:25:30.000Z","comments":true,"path":"posts/7cb85200.html","link":"","permalink":"https://mhuig.github.io/posts/7cb85200.html","excerpt":"大数据处理技术 PDF Hive基本操作之创建数据库","text":"大数据处理技术 PDF Hive基本操作之创建数据库 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hive","slug":"大数据/大数据处理技术/hive","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hive/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hive","slug":"hive","permalink":"https://mhuig.github.io/tags/hive/"}]},{"title":"大数据处理技术-Hive基本概念","slug":"bigdata/大数据处理技术 - Hive基本概念","date":"2019-09-19T03:25:29.000Z","updated":"2019-09-19T03:25:29.000Z","comments":true,"path":"posts/f4524359.html","link":"","permalink":"https://mhuig.github.io/posts/f4524359.html","excerpt":"大数据处理技术 PDF Hive基本概念","text":"大数据处理技术 PDF Hive基本概念 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hive","slug":"大数据/大数据处理技术/hive","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hive/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hive","slug":"hive","permalink":"https://mhuig.github.io/tags/hive/"}]},{"title":"大数据处理技术-索引建立","slug":"bigdata/大数据处理技术 - 索引建立","date":"2019-09-19T03:25:28.000Z","updated":"2019-09-19T03:25:28.000Z","comments":true,"path":"posts/cc03340e.html","link":"","permalink":"https://mhuig.github.io/posts/cc03340e.html","excerpt":"大数据处理技术 PDF 索引建立","text":"大数据处理技术 PDF 索引建立 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"大数据/大数据处理技术/mapreduce","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/mapreduce/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"mapreduce","permalink":"https://mhuig.github.io/tags/mapreduce/"}]},{"title":"大数据处理技术-MapReduce Shuffle过程","slug":"bigdata/大数据处理技术 - MapReduceshuffle过程","date":"2019-09-19T03:25:27.000Z","updated":"2019-09-19T03:25:27.000Z","comments":true,"path":"posts/c81f7fcf.html","link":"","permalink":"https://mhuig.github.io/posts/c81f7fcf.html","excerpt":"大数据处理技术 PDF MapReduce shuffle过程","text":"大数据处理技术 PDF MapReduce shuffle过程 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"大数据/大数据处理技术/mapreduce","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/mapreduce/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"mapreduce","permalink":"https://mhuig.github.io/tags/mapreduce/"}]},{"title":"大数据处理技术-ReduceTask工作机制以及reduceTask的并行度","slug":"bigdata/大数据处理技术 - ReduceTask工作机制以及reduceTask的并行度","date":"2019-09-19T03:25:25.000Z","updated":"2019-09-19T03:25:25.000Z","comments":true,"path":"posts/ea7b2ec0.html","link":"","permalink":"https://mhuig.github.io/posts/ea7b2ec0.html","excerpt":"大数据处理技术 PDF ReduceTask工作机制以及reduceTask的并行度","text":"大数据处理技术 PDF ReduceTask工作机制以及reduceTask的并行度 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"大数据/大数据处理技术/mapreduce","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/mapreduce/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"mapreduce","permalink":"https://mhuig.github.io/tags/mapreduce/"}]},{"title":"大数据处理技术-MapTask运行机制详解以及Map任务的并行度","slug":"bigdata/大数据处理技术 - MapTask运行机制详解以及Map任务的并行度","date":"2019-09-19T03:25:25.000Z","updated":"2019-09-19T03:25:25.000Z","comments":true,"path":"posts/d178b062.html","link":"","permalink":"https://mhuig.github.io/posts/d178b062.html","excerpt":"大数据处理技术 PDF MapTask运行机制详解以及Map任务的并行度","text":"大数据处理技术 PDF MapTask运行机制详解以及Map任务的并行度 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"大数据/大数据处理技术/mapreduce","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/mapreduce/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"mapreduce","permalink":"https://mhuig.github.io/tags/mapreduce/"}]},{"title":"大数据处理技术-MapReduce的分区与reduceTask的数量","slug":"bigdata/大数据处理技术 - MapReduce的分区与reduceTask的数量","date":"2019-09-19T03:25:23.000Z","updated":"2019-09-19T03:25:23.000Z","comments":true,"path":"posts/a5d678be.html","link":"","permalink":"https://mhuig.github.io/posts/a5d678be.html","excerpt":"大数据处理技术 PDF MapReduce的分区与reduceTask的数量","text":"大数据处理技术 PDF MapReduce的分区与reduceTask的数量 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"大数据/大数据处理技术/mapreduce","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/mapreduce/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"mapreduce","permalink":"https://mhuig.github.io/tags/mapreduce/"}]},{"title":"大数据处理技术-MapReduce编程模型-WordCount实例分析","slug":"bigdata/大数据处理技术 - MapReduce编程模型-WordCount实例分析","date":"2019-09-19T03:25:22.000Z","updated":"2019-09-19T03:25:22.000Z","comments":true,"path":"posts/695a6c4b.html","link":"","permalink":"https://mhuig.github.io/posts/695a6c4b.html","excerpt":"大数据处理技术 PDF MapReduce编程模型-WordCount实例分析","text":"大数据处理技术 PDF MapReduce编程模型-WordCount实例分析 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"大数据/大数据处理技术/mapreduce","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/mapreduce/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"mapreduce","permalink":"https://mhuig.github.io/tags/mapreduce/"}]},{"title":"大数据处理技术-WordCount示例编写本地模式","slug":"bigdata/大数据处理技术 -WordCount示例编写本地模式","date":"2019-09-19T03:25:21.000Z","updated":"2019-09-19T03:25:21.000Z","comments":true,"path":"posts/46b39789.html","link":"","permalink":"https://mhuig.github.io/posts/46b39789.html","excerpt":"大数据处理技术 PDF WordCount示例编写本地模式","text":"大数据处理技术 PDF WordCount示例编写本地模式 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"大数据/大数据处理技术/mapreduce","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/mapreduce/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"mapreduce","permalink":"https://mhuig.github.io/tags/mapreduce/"}]},{"title":"大数据处理技术-MapReduce编程规范及示例编写","slug":"bigdata/大数据处理技术 - MapReduce编程规范及示例编写","date":"2019-09-19T03:25:20.000Z","updated":"2019-09-19T03:25:20.000Z","comments":true,"path":"posts/610da529.html","link":"","permalink":"https://mhuig.github.io/posts/610da529.html","excerpt":"大数据处理技术 PDF MapReduce编程规范及示例编写","text":"大数据处理技术 PDF MapReduce编程规范及示例编写 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"大数据/大数据处理技术/mapreduce","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/mapreduce/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"mapreduce","permalink":"https://mhuig.github.io/tags/mapreduce/"}]},{"title":"大数据处理技术-MapReduce框架结构","slug":"bigdata/大数据处理技术 - MapReduce框架结构","date":"2019-09-19T03:25:19.000Z","updated":"2019-09-19T03:25:19.000Z","comments":true,"path":"posts/7def3950.html","link":"","permalink":"https://mhuig.github.io/posts/7def3950.html","excerpt":"大数据处理技术 PDF MapReduce框架结构","text":"大数据处理技术 PDF MapReduce框架结构 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"大数据/大数据处理技术/mapreduce","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/mapreduce/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"mapreduce","permalink":"https://mhuig.github.io/tags/mapreduce/"}]},{"title":"大数据处理技术-HadoopMapReduce设计构思","slug":"bigdata/大数据处理技术 - HadoopMapReduce设计构思","date":"2019-09-19T03:25:18.000Z","updated":"2019-09-19T03:25:18.000Z","comments":true,"path":"posts/b0ef01f5.html","link":"","permalink":"https://mhuig.github.io/posts/b0ef01f5.html","excerpt":"大数据处理技术 PDF HadoopMapReduce设计构思","text":"大数据处理技术 PDF HadoopMapReduce设计构思 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"大数据/大数据处理技术/mapreduce","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/mapreduce/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"},{"name":"MapReduce","slug":"mapreduce","permalink":"https://mhuig.github.io/tags/mapreduce/"}]},{"title":"大数据处理技术-理解MapReduce思想","slug":"bigdata/大数据处理技术 - 理解MapReduce思想","date":"2019-09-19T03:25:17.000Z","updated":"2019-09-19T03:25:17.000Z","comments":true,"path":"posts/7d6b1f3c.html","link":"","permalink":"https://mhuig.github.io/posts/7d6b1f3c.html","excerpt":"大数据处理技术 PDF 理解MapReduce思想","text":"大数据处理技术 PDF 理解MapReduce思想 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"大数据/大数据处理技术/mapreduce","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/mapreduce/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"MapReduce","slug":"mapreduce","permalink":"https://mhuig.github.io/tags/mapreduce/"}]},{"title":"大数据处理技术-HDFS的JavaAPI操作","slug":"bigdata/大数据处理技术 - HDFS的JavaAPI操作","date":"2019-09-19T03:25:16.000Z","updated":"2019-09-19T03:25:16.000Z","comments":true,"path":"posts/a3ed1548.html","link":"","permalink":"https://mhuig.github.io/posts/a3ed1548.html","excerpt":"大数据处理技术 PDF HDFS的JavaAPI操作","text":"大数据处理技术 PDF HDFS的JavaAPI操作 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"大数据/大数据处理技术/hdfs","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hdfs/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"},{"name":"HDFS","slug":"hdfs","permalink":"https://mhuig.github.io/tags/hdfs/"},{"name":"JavaAPI","slug":"javaapi","permalink":"https://mhuig.github.io/tags/javaapi/"}]},{"title":"大数据处理技术-HDFS的文件读取过程","slug":"bigdata/大数据处理技术 - HDFS的文件读取过程","date":"2019-09-19T03:25:15.000Z","updated":"2019-09-19T03:25:15.000Z","comments":true,"path":"posts/6e430c9c.html","link":"","permalink":"https://mhuig.github.io/posts/6e430c9c.html","excerpt":"大数据处理技术 PDF HDFS的文件读取过程","text":"大数据处理技术 PDF HDFS的文件读取过程 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"大数据/大数据处理技术/hdfs","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hdfs/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"}]},{"title":"大数据处理技术-HDFS的文件写入过程","slug":"bigdata/大数据处理技术 - HDFS的文件写入过程","date":"2019-09-19T03:25:14.000Z","updated":"2019-09-19T03:25:14.000Z","comments":true,"path":"posts/4edeccca.html","link":"","permalink":"https://mhuig.github.io/posts/4edeccca.html","excerpt":"大数据处理技术 PDF HDFS的文件写入过程","text":"大数据处理技术 PDF HDFS的文件写入过程 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"大数据/大数据处理技术/hdfs","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hdfs/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"}]},{"title":"大数据处理技术-HDFS的元数据信息FSimage以及edits和secondaryNN的作用","slug":"bigdata/大数据处理技术 - HDFS的元数据信息FSimage以及edits和secondaryNN的作用","date":"2019-09-19T03:25:13.000Z","updated":"2019-09-19T03:25:13.000Z","comments":true,"path":"posts/fec1c989.html","link":"","permalink":"https://mhuig.github.io/posts/fec1c989.html","excerpt":"大数据处理技术 PDF HDFS的元数据信息FSimage以及edits和secondaryNN的作用","text":"大数据处理技术 PDF HDFS的元数据信息FSimage以及edits和secondaryNN的作用 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"大数据/大数据处理技术/hdfs","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hdfs/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"hdfs","permalink":"https://mhuig.github.io/tags/hdfs/"}]},{"title":"大数据处理技术-Hdfs的架构之文件的文件副本机制","slug":"bigdata/大数据处理技术 -hdfs的架构之文件的文件副本机制","date":"2019-09-19T03:25:12.000Z","updated":"2019-09-19T03:25:12.000Z","comments":true,"path":"posts/787a8307.html","link":"","permalink":"https://mhuig.github.io/posts/787a8307.html","excerpt":"大数据处理技术 PDF hdfs的架构之文件的文件副本机制","text":"大数据处理技术 PDF hdfs的架构之文件的文件副本机制 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"大数据/大数据处理技术/hdfs","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hdfs/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"hdfs","permalink":"https://mhuig.github.io/tags/hdfs/"}]},{"title":"大数据处理技术-HDFS的架构图之基础架构","slug":"bigdata/大数据处理技术 - HDFS的架构图之基础架构","date":"2019-09-19T03:25:11.000Z","updated":"2019-09-19T03:25:11.000Z","comments":true,"path":"posts/bb7c60d.html","link":"","permalink":"https://mhuig.github.io/posts/bb7c60d.html","excerpt":"大数据处理技术 PDF HDFS的架构图之基础架构","text":"大数据处理技术 PDF HDFS的架构图之基础架构 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"大数据/大数据处理技术/hdfs","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hdfs/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"hdfs","permalink":"https://mhuig.github.io/tags/hdfs/"}]},{"title":"大数据处理技术-HDFS的来源","slug":"bigdata/大数据处理技术 - HDFS的来源","date":"2019-09-19T03:25:10.000Z","updated":"2019-09-19T03:25:10.000Z","comments":true,"path":"posts/e981c79e.html","link":"","permalink":"https://mhuig.github.io/posts/e981c79e.html","excerpt":"大数据处理技术 PDF HDFS的来源","text":"大数据处理技术 PDF HDFS的来源 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"大数据/大数据处理技术/hdfs","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hdfs/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"hdfs","permalink":"https://mhuig.github.io/tags/hdfs/"}]},{"title":"大数据处理技术-HDFS分布式文件系统设计目标","slug":"bigdata/大数据处理技术 - HDFS分布式文件系统设计目标","date":"2019-09-19T03:25:09.000Z","updated":"2019-09-19T03:25:09.000Z","comments":true,"path":"posts/6acc7206.html","link":"","permalink":"https://mhuig.github.io/posts/6acc7206.html","excerpt":"大数据处理技术 PDF HDFS分布式文件系统设计目标","text":"大数据处理技术 PDF HDFS分布式文件系统设计目标 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"大数据/大数据处理技术/hdfs","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hdfs/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"hdfs","permalink":"https://mhuig.github.io/tags/hdfs/"}]},{"title":"大数据处理技术-分布式文件系统详细介绍","slug":"bigdata/大数据处理技术 -分布式文件系统详细介绍","date":"2019-09-19T03:25:08.000Z","updated":"2019-09-19T03:25:08.000Z","comments":true,"path":"posts/72b49ca2.html","link":"","permalink":"https://mhuig.github.io/posts/72b49ca2.html","excerpt":"大数据处理技术 PDF 分布式文件系统详细介绍","text":"大数据处理技术 PDF 分布式文件系统详细介绍 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"大数据/大数据处理技术/hdfs","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hdfs/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"HDFS","slug":"hdfs","permalink":"https://mhuig.github.io/tags/hdfs/"}]},{"title":"大数据处理技术-CDH伪分布式环境搭建","slug":"bigdata/大数据处理技术 - CDH伪分布式环境搭建","date":"2019-09-19T03:25:07.000Z","updated":"2019-09-19T03:25:07.000Z","comments":true,"path":"posts/b387b8d5.html","link":"","permalink":"https://mhuig.github.io/posts/b387b8d5.html","excerpt":"大数据处理技术 PDF CDH伪分布式环境搭建","text":"大数据处理技术 PDF CDH伪分布式环境搭建 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"大数据/大数据处理技术/hadoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"}]},{"title":"大数据处理技术-HDFS的命令行使用","slug":"bigdata/大数据处理技术 - HDFS的命令行使用","date":"2019-09-19T03:25:06.000Z","updated":"2019-09-19T03:25:06.000Z","comments":true,"path":"posts/fb97a8a5.html","link":"","permalink":"https://mhuig.github.io/posts/fb97a8a5.html","excerpt":"大数据处理技术 PDF HDFS的命令行使用","text":"大数据处理技术 PDF HDFS的命令行使用 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"大数据/大数据处理技术/hadoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"}]},{"title":"大数据处理技术-HDFS入门介绍","slug":"bigdata/大数据处理技术 -HDFS入门介绍","date":"2019-09-19T03:25:05.000Z","updated":"2019-09-19T03:25:05.000Z","comments":true,"path":"posts/87e9dc75.html","link":"","permalink":"https://mhuig.github.io/posts/87e9dc75.html","excerpt":"大数据处理技术 PDF HDFS入门介绍","text":"大数据处理技术 PDF HDFS入门介绍 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"大数据/大数据处理技术/hadoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"},{"name":"HDFS","slug":"hdfs","permalink":"https://mhuig.github.io/tags/hdfs/"}]},{"title":"大数据处理技术-Hadoop集群初体验","slug":"bigdata/大数据处理技术 - hadoop集群初体验","date":"2019-09-19T03:25:04.000Z","updated":"2019-09-19T03:25:04.000Z","comments":true,"path":"posts/980d646e.html","link":"","permalink":"https://mhuig.github.io/posts/980d646e.html","excerpt":"大数据处理技术 PDF hadoop集群初体验","text":"大数据处理技术 PDF hadoop集群初体验 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"大数据/大数据处理技术/hadoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"}]},{"title":"大数据处理技术-Hadoop三种架构介绍（高可用分布式环境介绍以及安装）","slug":"bigdata/大数据处理技术 - hadoop三种架构介绍（高可用分布式环境介绍以及安装）","date":"2019-09-19T03:25:03.000Z","updated":"2019-09-19T03:25:03.000Z","comments":true,"path":"posts/1e1e5118.html","link":"","permalink":"https://mhuig.github.io/posts/1e1e5118.html","excerpt":"大数据处理技术 PDF hadoop三种架构介绍（高可用分布式环境介绍以及安装）","text":"大数据处理技术 PDF hadoop三种架构介绍（高可用分布式环境介绍以及安装） GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"大数据/大数据处理技术/hadoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"}]},{"title":"大数据处理技术","slug":"bigdata/大数据处理技术 -hadoop三种架构介绍（伪分布介绍以及安装）","date":"2019-09-19T03:25:02.000Z","updated":"2019-09-19T03:25:02.000Z","comments":true,"path":"posts/1009d3f6.html","link":"","permalink":"https://mhuig.github.io/posts/1009d3f6.html","excerpt":"大数据处理技术 PDF hadoop三种架构介绍（伪分布介绍以及安装）","text":"大数据处理技术 PDF hadoop三种架构介绍（伪分布介绍以及安装） GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"大数据/大数据处理技术/hadoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"}]},{"title":"大数据处理技术-Apache hadoop三种架构介绍（standAlone)","slug":"bigdata/大数据处理技术 - apache hadoop三种架构介绍（standAlone)","date":"2019-09-19T03:25:01.000Z","updated":"2019-09-19T03:25:01.000Z","comments":true,"path":"posts/e00c1bc.html","link":"","permalink":"https://mhuig.github.io/posts/e00c1bc.html","excerpt":"大数据处理技术 PDF apache hadoop三种架构介绍（standAlone)","text":"大数据处理技术 PDF apache hadoop三种架构介绍（standAlone) GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"大数据/大数据处理技术/hadoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"}]},{"title":"大数据处理技术-hadoop的架构模型（1.x，2.x的各种架构模型介绍）","slug":"bigdata/大数据处理技术 - hadoop的架构模型（1.x，2.x的各种架构模型介绍）","date":"2019-09-19T03:25:00.000Z","updated":"2019-09-19T03:25:00.000Z","comments":true,"path":"posts/429246c5.html","link":"","permalink":"https://mhuig.github.io/posts/429246c5.html","excerpt":"大数据处理技术 PDF hadoop的架构模型（1.x，2.x的各种架构模型介绍）","text":"大数据处理技术 PDF hadoop的架构模型（1.x，2.x的各种架构模型介绍） GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"大数据/大数据处理技术/hadoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"}]},{"title":"大数据处理技术-三大公司发行版本介绍","slug":"bigdata/大数据处理技术 - 三大公司发行版本介绍","date":"2019-09-19T03:24:59.000Z","updated":"2019-09-19T03:24:59.000Z","comments":true,"path":"posts/bfb9db00.html","link":"","permalink":"https://mhuig.github.io/posts/bfb9db00.html","excerpt":"大数据处理技术 PDF 三大公司发行版本介绍","text":"大数据处理技术 PDF 三大公司发行版本介绍 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"大数据/大数据处理技术/hadoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"}]},{"title":"大数据处理技术-Hadoop的介绍以及发展历史","slug":"bigdata/大数据处理技术 - hadoop的介绍以及发展历史","date":"2019-09-19T03:24:58.000Z","updated":"2019-09-19T03:24:58.000Z","comments":true,"path":"posts/3098d714.html","link":"","permalink":"https://mhuig.github.io/posts/3098d714.html","excerpt":"大数据处理技术 PDF hadoop的介绍以及发展历史","text":"大数据处理技术 PDF hadoop的介绍以及发展历史 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"大数据/大数据处理技术/hadoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"},{"name":"历史","slug":"历史","permalink":"https://mhuig.github.io/tags/%E5%8E%86%E5%8F%B2/"}]},{"title":"大数据处理技术-Zookeeper的介绍以及集群环境搭建","slug":"bigdata/大数据处理技术 - zookeeper的介绍以及集群环境搭建","date":"2019-09-19T03:24:57.000Z","updated":"2019-09-19T03:24:57.000Z","comments":true,"path":"posts/f1ab62f1.html","link":"","permalink":"https://mhuig.github.io/posts/f1ab62f1.html","excerpt":"大数据处理技术 PDF zookeeper的介绍以及集群环境搭建","text":"大数据处理技术 PDF zookeeper的介绍以及集群环境搭建 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Zookeeper","slug":"大数据/大数据处理技术/zookeeper","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/zookeeper/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Zookeeper","slug":"zookeeper","permalink":"https://mhuig.github.io/tags/zookeeper/"}]},{"title":"大数据处理技术-分布式集群","slug":"bigdata/大数据处理技术 - 分布式集群","date":"2019-09-19T03:24:56.000Z","updated":"2019-09-19T03:24:56.000Z","comments":true,"path":"posts/897831fa.html","link":"","permalink":"https://mhuig.github.io/posts/897831fa.html","excerpt":"大数据处理技术 PDF 分布式集群","text":"大数据处理技术 PDF 分布式集群 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"大数据集群环境准备","slug":"大数据/大数据处理技术/大数据集群环境准备","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"大数据集群环境准备","slug":"大数据集群环境准备","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"}]},{"title":"大数据处理技术-大数据集群环境准备","slug":"bigdata/大数据处理技术 -大数据集群环境准备","date":"2019-09-19T03:24:55.000Z","updated":"2019-09-19T03:24:55.000Z","comments":true,"path":"posts/c16b9d82.html","link":"","permalink":"https://mhuig.github.io/posts/c16b9d82.html","excerpt":"大数据处理技术 PDF 大数据集群环境准备","text":"大数据处理技术 PDF 大数据集群环境准备 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"大数据集群环境准备","slug":"大数据/大数据处理技术/大数据集群环境准备","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"大数据集群环境准备","slug":"大数据集群环境准备","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"}]},{"title":"大数据处理技术-三台虚拟机创建并联网","slug":"bigdata/大数据处理技术 - 三台虚拟机创建并联网","date":"2019-09-19T03:24:54.000Z","updated":"2019-09-19T03:24:54.000Z","comments":true,"path":"posts/e821aeca.html","link":"","permalink":"https://mhuig.github.io/posts/e821aeca.html","excerpt":"大数据处理技术 PDF 三台虚拟机创建并联网","text":"大数据处理技术 PDF 三台虚拟机创建并联网 GitHub","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"大数据集群环境准备","slug":"大数据/大数据处理技术/大数据集群环境准备","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"大数据集群环境准备","slug":"大数据集群环境准备","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"}]},{"title":"大数据处理技术","slug":"bigdata/大数据处理技术","date":"2019-09-19T03:24:53.000Z","updated":"2019-09-19T03:24:53.000Z","comments":true,"path":"posts/1009d3f6.html","link":"","permalink":"https://mhuig.github.io/posts/1009d3f6.html","excerpt":"大数据处理技术 PDF 实训资料汇总","text":"大数据处理技术 PDF 实训资料汇总 GitHub day01大数据集群环境准备&amp;zookeeper的介绍以及集群环境搭建三台虚拟机创建并联网 大数据集群环境准备 分布式集群 zookeeper的介绍以及集群环境搭建 day02大数据发展简史及环境安装hadoop的介绍以及发展历史 hadoop的历史版本介绍 三大公司发行版本介绍 hadoop的架构模型（1.x，2.x的各种架构模型介绍） apache hadoop三种架构介绍（standAlone) apache hadoop三种架构介绍（伪分布介绍以及安装） apache hadoop三种架构介绍（高可用分布式环境介绍以及安装） day03Hadoop集群初体验&amp;HDFS的命令行使用hadoop集群初体验 HDFS入门介绍 HDFS的命令行使用 CDH伪分布式环境搭建 day04分布式文件系统HDF分布式文件系统详细介绍 HDFS分布式文件系统设计目标 HDFS的来源 HDFS的架构图之基础架构 hdfs的架构之文件的文件副本机制 HDFS的元数据信息FSimage以及edits和secondaryNN的作用 HDFS的文件写入过程 HDFS的文件读取过程 HDFS的JavaAPI操作 day05MapReduce编程模型-WordCount实例分析理解MapReduce思想 HadoopMapReduce设计构思 MapReduce框架结构 MapReduce编程规范及示例编写 WordCount示例编写本地模式 MapReduce编程模型-WordCount实例分析 day06MapReduce的运行机制MapReduce的分区与reduceTask的数量 MapTask运行机制详解以及Map任务的并行度 ReduceTask工作机制以及reduceTask的并行度 MapReduceshuffle过程 索引建立 day07Yarn资源调度及Hive初步Hive基本概念 Hive的安装部署 Hive基本操作之创建数据库 创建数据库表 hive语句综合练习 Yarn资源调度 关于yarn常用参数设置 day08Flume数据采集Flume介绍 Flume的安装部署 采集案例监控目录变化 采集案例监控文件的变化 两个agent级联 更多source和sink组件 高可用Flume flume的负载均衡loadbalancer day09消息队列Kafkakafka的介绍 kafka的安装 kafka的命令行的管理使用 kafka的javaAPI的使用 kafka的数据的分区 kafka的配置文件的说明 flume与kafka的整合 kafka-manager监控工具的使用 CDH版本的zookeeper环境搭建 day10sqoop数据迁移sqoop day11工作流调度器azkaban&amp;数据可视化Echarts介绍azkaban 数据可视化Echarts介绍","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hadoop","slug":"大数据/hadoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"}]},{"title":"数学建模资料","slug":"math/数学建模资料","date":"2019-09-19T01:16:41.000Z","updated":"2019-09-19T01:16:41.000Z","comments":true,"path":"posts/6cfc95e.html","link":"","permalink":"https://mhuig.github.io/posts/6cfc95e.html","excerpt":"汇总司守奎老师的讲义 程序 习题解答等","text":"汇总司守奎老师的讲义 程序 习题解答等 GitHub 封面 前言 目录 第一章 线性规划 第二章 整数规划 第三章 非线性规划 第四章 动态规划 第五章 图与网络 第六章 排队论 第七章 对策论 第八章 层次分析法 第九章 插值与拟合 第十章 数据的统计描述和分析 第十一章 方差分析 第十二章 回归分析 第十三章 微分方程建模 第十四章 稳定状态模型 第十五章 常微分方程的解法 第十六章 差分方程模型 第十七章 马氏链模型 第十八章 变分法模型 第十九章 神经网络模型 第二十章 偏微分方程的数值解 第二十一章 目标规划 第二十二章 模糊数学模型 第二十三章 现代优化算法 第二十四章 时间序列模型 第二十五章 灰色系统理论及其应用 第二十六章 多元分析 第二十七章 偏最小二乘回归分析 第二十八章 存贮论 第二十九章 经济与金融中的优化问题 第三十章 生产与服务运作管理中的优化问题 第三十一章 支持向量机 第三十二章 作业计划 附录一 Matlab入门 附录二 Matlab在线性代数中的应用 附录三 运筹学的LINGO软件 附录四 Excel在统计分析与数量方法中的应用 附录五 SPSS在统计分析中的应用 参考文献","categories":[{"name":"Math","slug":"math","permalink":"https://mhuig.github.io/categories/math/"},{"name":"数学建模","slug":"math/数学建模","permalink":"https://mhuig.github.io/categories/math/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"}],"tags":[{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"Math","slug":"math","permalink":"https://mhuig.github.io/tags/math/"},{"name":"数学建模","slug":"数学建模","permalink":"https://mhuig.github.io/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"}]},{"title":"数据挖掘PDF资料","slug":"ml/数据挖掘","date":"2019-09-17T01:02:02.000Z","updated":"2019-09-17T01:02:02.000Z","comments":true,"path":"posts/b59b6a41.html","link":"","permalink":"https://mhuig.github.io/posts/b59b6a41.html","excerpt":"汇总数据挖掘PDF资料","text":"汇总数据挖掘PDF资料 数据挖掘概念与特性 常用分类算法及原理 常用降维算法及原理 常用聚类算法及原理 关联分析及常用算法 常用推荐算法及原理","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"数据挖掘","slug":"大数据/数据挖掘","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://mhuig.github.io/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"}]},{"title":"数据可视化PDF资料","slug":"ml/数据可视化","date":"2019-09-17T01:02:02.000Z","updated":"2019-09-17T01:02:02.000Z","comments":true,"path":"posts/98579906.html","link":"","permalink":"https://mhuig.github.io/posts/98579906.html","excerpt":"汇总数据可视化PDF资料","text":"汇总数据可视化PDF资料 HTML的基本标签及语法 CSS语法规则 网页基本布局方式 自适应设计和响应式设计 js基本语法汇总 Ajax基本原理和概念 Ajax实现与后台服务通信 Echarts常用功能api","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"数据可视化","slug":"大数据/数据可视化","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"数据可视化","slug":"数据可视化","permalink":"https://mhuig.github.io/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"}]},{"title":"特征和分类器","slug":"ml/特征和分类器","date":"2019-09-12T03:19:19.000Z","updated":"2019-09-12T03:19:19.000Z","comments":true,"path":"posts/483290b5.html","link":"","permalink":"https://mhuig.github.io/posts/483290b5.html","excerpt":"特征提取和分类是典型计算机视觉系统的两个关键阶段。 视觉系统的准确性、稳健性和效率在很大程度上取决于图像特征，和分类器的质量。因此，目标是从输入图像中提取信息丰富的、可靠的特征，以便能够开发出很大程度上独立于领域理论的分类。","text":"特征提取和分类是典型计算机视觉系统的两个关键阶段。 视觉系统的准确性、稳健性和效率在很大程度上取决于图像特征，和分类器的质量。因此，目标是从输入图像中提取信息丰富的、可靠的特征，以便能够开发出很大程度上独立于领域理论的分类。 特征特征是任何独特的方面或特性，用于解决与特定应用相关的计算任务。 n个特征的组合可以表示成n维向量，称为特征向量。特征向量的质量取决于其区分不同类别的图像样本的能力。 来自同一类的图像样本应该有相似的特征值，来自不同类的图像应具有不同的特征值。 分类器分类器是现代计算机视觉和模式识别的核心。 分类器的任务是使用特征向量对图像或感兴趣区域（RoI）划分类别。 分类任务的困难程度取决于来自相同类别的图像的特征值的可变性，以及相对于来自不同类别图像的特征值的差异性。 但是，完美的分类性能通常是不可能的。这主要是因为： 噪声（以阴影、遮挡、透视扭曲等形式） 异常值 模糊性 缺少标签 仅有小训练样本可用 训练数据样本中正/负覆盖的不平衡 传统特征描述符传统（手工设计）特征提取方法可分为两大类： 全局 局部 全局特征提取方法定义了一组有效描述整个图像的全局特征。因此形状细节被忽略。全局特征也不适用于识别部分遮挡的对象。 局部特征提取方法提取关键点周围的局部区域，由此可以更好的处理遮挡。 检测关键点，并在他们周围构建描述符的方法： 局部描述符（如HOG、SIFT、SURF、FREAK、ORB、BRISK、BRIEF、LIOP） 方向梯度直方图HOG是一个特征描述符，用于自动检测图像中的对象。HOG描述符对图像中局部部分的梯度方向的分布进行编码。 HOG背后的想法是可以通过边缘方向的直方图来描述图像内的对象外观和形状。 1.梯度计算第一步是计算梯度值。在图像的水平和垂直方向上，执行一维中心点离散微分模板。具体的说，该方法需要用以下滤波器内核处理灰度图像： 因此给定一个图像，以下卷积操作（表示为 ）得出图像在和方向的导数： 因此，梯度的方向和梯度的大小计算如下： CNN也在层中使用卷积运算，然而主要区别在于不使用手工设计的滤波器，CNN使用可训练的滤波器，使其具有高度的自适应性。 CNN也在层中使用卷积运算，然而主要区别在于不使用手工设计的滤波器，CNN使用可训练的滤波器，使其具有高度的自适应性。 2.单元方向直方图第二步是计算单元直方图。首先将图像分成小的（通常是8X8像素）单元。每个单元都有固定数量的梯度方向区间，他们均匀分布在。或。之间，具体取决于梯度是有符号的还是无符号的。 单元内的每一个像素基于该像素处梯度的模对每一个梯度方向区间偷加权票。对于投票权重，可以是梯度大小，梯度大小的平方根或梯度大小的平方。 3.描述符块为了处理光照和对比度的变化，通过将单元组合在一起形成更大的空间上相连的块，局部的归一化梯度强度。然后，HOG描述符是来自所有块区域内的、归一化的单元直方图部件的向量。 4.块的归一化最后一步是块描述符的归一化。设v是包含给定块中所有直方图的非归一化向量，‖为它的(k)阶范数（(k=1,2) ），(\\epsilon)是一个小常量。归一化因子可以是如下之一： 范数或者 范数或者 范数平方根还有另一个归一化因子L2-Hys,它通过削减v的L2范数得到（将v的最大值限制为0.2），然后重新归一化。 最终的图像/RoI描述符是通过连接所有归一化的块描述符而形成的。 L2范数、L2-Hys和L1范数平方根（L1-sqrt）归一化方法提供了类似的性能，而L1范数提供了可靠性稍差的性能。 尺度不变特征变换SIFT[Lowe,2004]提供了一组对象的特征，这些特征对于对象缩放和旋转是健壮的。 SIFT算法由四个主要步骤组成。 1.尺度空间的极值侦测第一步旨在确定对缩放和方向不变的潜在关键点。 SIFT使用高斯差分（DoG）来检测尺度空间中关键点中的位置。 高斯差分是将两个不同尺度的图像（其中一个尺度为,另一个是其k倍，即）的高斯模糊进行差分得到的。 2.关键点精确定位3.方向定位4.关键点描述符","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://mhuig.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"机器视觉","slug":"机器学习/机器视觉","permalink":"https://mhuig.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://mhuig.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"机器视觉","slug":"机器视觉","permalink":"https://mhuig.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"},{"name":"分类器","slug":"分类器","permalink":"https://mhuig.github.io/tags/%E5%88%86%E7%B1%BB%E5%99%A8/"},{"name":"特征","slug":"特征","permalink":"https://mhuig.github.io/tags/%E7%89%B9%E5%BE%81/"}]},{"title":"图像导数","slug":"ml/图像导数","date":"2019-09-12T02:29:46.000Z","updated":"2019-09-12T02:29:46.000Z","comments":true,"path":"posts/9bc3b11e.html","link":"","permalink":"https://mhuig.github.io/posts/9bc3b11e.html","excerpt":"在图像中，边缘可以看做是位于一阶导数较大的像素处，因此，我们可以求图像的一阶导数来确定图像的边缘，像sobel算子等一系列算子都是基于这个思想的。","text":"在图像中，边缘可以看做是位于一阶导数较大的像素处，因此，我们可以求图像的一阶导数来确定图像的边缘，像sobel算子等一系列算子都是基于这个思想的。 如下图a表示函数在边沿的时候关系，求导得b图，可知边沿可就是函数的极值点，对应二阶导数为0处，如图c的二阶导图。 关于导数总结如下： （1）一阶导数通常图像中产生较粗的边缘 （2）二阶导数对精细细节，如细线、孤立点和噪声有较强的响应 （3）二阶导数在灰度斜坡和灰度台阶过度处会产生双边沿响应 （4）二阶导数的符号可以确定边缘的过渡是从亮到暗还是从暗到亮 （5）选导数提取边沿之前最好是做下图像的平滑，导数对噪声比较敏感","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://mhuig.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"机器视觉","slug":"机器学习/机器视觉","permalink":"https://mhuig.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://mhuig.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"机器视觉","slug":"机器视觉","permalink":"https://mhuig.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"},{"name":"图像","slug":"图像","permalink":"https://mhuig.github.io/tags/%E5%9B%BE%E5%83%8F/"},{"name":"数学模型","slug":"数学模型","permalink":"https://mhuig.github.io/tags/%E6%95%B0%E5%AD%A6%E6%A8%A1%E5%9E%8B/"}]},{"title":"进程的描述","slug":"OS/进程的描述","date":"2019-09-12T01:54:49.000Z","updated":"2019-09-12T01:54:49.000Z","comments":true,"path":"posts/253269c2.html","link":"","permalink":"https://mhuig.github.io/posts/253269c2.html","excerpt":"为了能使程序并发执行，并且可以对并发执行的程序加以描述和控制，人们引入了“进程”的概念。","text":"为了能使程序并发执行，并且可以对并发执行的程序加以描述和控制，人们引入了“进程”的概念。 进程的特征和定义结构特征进程实体是由程序段、数据段及进程、控制块（PCB）三部分组成. UNIX中将这三部分称为“进程映像”。 创建进程：创建进程实体中的进程控制块（PCB）。 撤销进程：撤销进程实体中的进程控制块（PCB）。 进程的特征 动态性 并发性 独立性 异步性","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"进程","slug":"进程","permalink":"https://mhuig.github.io/tags/%E8%BF%9B%E7%A8%8B/"}]},{"title":"前驱图和程序执行","slug":"OS/前驱图和程序执行","date":"2019-09-12T01:45:28.000Z","updated":"2019-09-12T01:45:28.000Z","comments":true,"path":"posts/a81e94e9.html","link":"","permalink":"https://mhuig.github.io/posts/a81e94e9.html","excerpt":"在多道程序环境中，允许多个程序并发执行；程序本身是具体代码，不能反映程序的执行过程从而引入进程。进程是抽象的。作为资源分配和独立运行的基本单位是进程。操作系统所有的特征都是基于进程而体现的。","text":"在多道程序环境中，允许多个程序并发执行；程序本身是具体代码，不能反映程序的执行过程从而引入进程。进程是抽象的。作为资源分配和独立运行的基本单位是进程。操作系统所有的特征都是基于进程而体现的。 程序顺序执行及其特征程序顺序执行时的特征 顺序性：每个操作在上一操作结束后开始 封闭性：程序开始执行，其执行结果不受外界因素影响 可再现性：只要环境和初始条件相同，其执行结果一定相同前驱图 定义前驱图是一个有向无循环图（DAG)，用于描述进程之间执行的前后关系。 注意：前驱图中不能存在循环。 程序并发执行及其特征 间断性： 共享资源 -&gt; 相互制约 -&gt; 执行-暂停-执行 失去封闭性： 一个程序的执行受到其他程序的影响 不可再现性 ##结论： 并发是提高资源利用率的好方法，从而提高系统吞吐量，所以程序尽量并发执行。 1）串行是顺序执行； 2）并发是交叉使用设备； 3）并行使用多个处理机—更快。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"前驱图","slug":"前驱图","permalink":"https://mhuig.github.io/tags/%E5%89%8D%E9%A9%B1%E5%9B%BE/"}]},{"title":"意识、脑与人工智能 十大科学问题","slug":"ml/意识、脑与人工智能十大科学问题","date":"2019-09-12T00:22:25.000Z","updated":"2019-09-12T00:22:25.000Z","comments":true,"path":"posts/c270974.html","link":"","permalink":"https://mhuig.github.io/posts/c270974.html","excerpt":"2018年9月，浙江大学发布“双脑计划”，布局脑科学与人工智能的会聚研究，聚集全校生命科学、信息科学、物质科学和哲学社会科学众多领域的专家学者，开启探索脑认知、意识及智能的本质和规律。2019年4月，浙江大学召开“意识、脑与人工智能”圆桌论坛，吴朝晖院士、段树民院士与倪梁康教授（文科资深教授）分别围绕“意识”问题，从计算机科学、脑科学、哲学角度作主旨报告，提出了一系列具有挑战性的跨学科问题。在此基础上，浙江大学“双脑计划”相关团队组织哲学、计算机科学、神经与脑科学、心理学、社会学等领域专家，聚焦意识与脑、意识与人工智能方面的重大问题，经过反复讨论、不断碰撞、深入凝练，最终提出了十大具有前沿性、挑战性的科学问题，旨在引领国内外学术界的思考，推动意识、脑与人工智能交叉领域的研究。","text":"2018年9月，浙江大学发布“双脑计划”，布局脑科学与人工智能的会聚研究，聚集全校生命科学、信息科学、物质科学和哲学社会科学众多领域的专家学者，开启探索脑认知、意识及智能的本质和规律。2019年4月，浙江大学召开“意识、脑与人工智能”圆桌论坛，吴朝晖院士、段树民院士与倪梁康教授（文科资深教授）分别围绕“意识”问题，从计算机科学、脑科学、哲学角度作主旨报告，提出了一系列具有挑战性的跨学科问题。在此基础上，浙江大学“双脑计划”相关团队组织哲学、计算机科学、神经与脑科学、心理学、社会学等领域专家，聚焦意识与脑、意识与人工智能方面的重大问题，经过反复讨论、不断碰撞、深入凝练，最终提出了十大具有前沿性、挑战性的科学问题，旨在引领国内外学术界的思考，推动意识、脑与人工智能交叉领域的研究。 “意识、脑与人工智能”十大科学问题一、意识的生物学基础是什么？意识曾仅是哲学家的研究领域，但随着神经科学发展，科学家逐渐参与到意识本质的研究中。目前大部分观点认为，意识产生的物质基础是神经元，其生物学基础是脑中多个神经网络间的相互作用；也有研究认为意识的产生由相对独立的脑结构（称为意识开关）来主导。意识的生物学基础是什么，及其衍生出来的一系列问题有待进一步探究。例如，意识产生的物质基础是否唯一，能否在神经元以外的物质载体上制造出意识等。 二、“人工意识”是否可能？从人工智能向人工意识的发展，必须考虑将人工情感和人工意欲的因素纳入人工意识和人工心灵系统的可能性。可尝试通过对神经回路的复杂性的把控来解决所有类型的意识涌现（表象、情感、意志）的复杂性，并在神经系统中找到作为意识之自身觉知（qualia）的对应项。 三、机器如何理解人类的情感表达？在人机共生社会，需要解决机器人与人类的自然交互问题，以使得机器人可以真正融入人们的生活，产生共情、共鸣和自然的社会行为。其中一个重要的挑战是机器如何理解人类的情感表达。 四、强人工智能的心理机制是什么？弱人工智能在解决特定领域问题中，展现出了强大到可以比肩甚至超越人类的能力，但也暴露出通用性弱、学习效率低等一系列问题。解决这些问题需要回归强人工智能的“初心”，即研究人类智能的心理机制是什么，探索人类为何能利用有限的算力实现通用智能、如何在小数据条件下完成高效学习等问题。 五、意识的信息机制是什么？意识是指一个人体验自身存在的能力，而不仅仅是记录或者像机器人那样对刺激做出反应。研究意识的信息处理机制，需要重点关注信息处理的主观性（subjective）、结构性（structured）、特有性（specific）、统一性（unified）和确定性（definitive）等问题。 六、脑机融合能否实现超级智能？脑机融合是基于脑机接口技术，实现脑与机的双向交互、相互适应及协同工作，最终达到生物智能和机器智能的融合，其目标是实现更强大的智能形态。鉴于机器智能与人类智能的互补性，如何实现生物智能和机器智能的互联互通，融合各自所长，创造出性能更强的智能形态是核心问题。 七、情绪情感的脑机制是什么？情绪是个体对一定程度的复杂情况做出反应的特定状态。情绪情感的产生涉及感觉、知觉、动机、奖赏、评估、感觉-行为转换等多种脑功能，并参与修饰和调控记忆及相关认知过程。人类智慧的形成和复杂社会体系的建立，均与情绪情感程序的进化和固化有关。情绪情感相关精神疾病也在持续和广泛地困扰人类社会。因此，研究情绪情感的脑机制是脑科学研究领域最令人兴奋的方向之一，其研究成果也将为相关精神疾病的诊断和治疗提供新的策略和手段。 八、学习的生物学基础是什么？动物需要适应环境变化，而学习就是神经系统把环境信息转变成经验的编码过程，与学习密切相关的记忆则是神经系统对这些经验的存储和提取的过程。研究学习记忆的神经生物学机制是神经科学领域至关重要的研究方向，也是阐明认知功能障碍的关键。 九、潜意识的脑科学机制是什么？潜意识指“已然发生但并未达到意识水平的心理活动过程或内容”，被认为是最复杂的心理现象，可能成为阐明人类意识大脑机制的突破口。随着认知神经科学和脑科学等交叉学科研究的发展，以及脑图谱技术、基因技术的进步，对潜意识的脑科学机制研究可能会有更大的突破。 十、人类决策的脑处理机制是什么？决策脑机制的研究日益受到重视，但决策偏好的神经机理还远未被揭开。系统探究决策脑机制，不仅有助于揭示决策者价值权衡过程的神经基础，还能为基于神经信号预测人的决策倾向，以及诊治决策异常相关脑疾病提供科学研究依据。 参考文献浙江大学面向2030的学科会聚研究计划（创新2030计划）“意识、脑与人工智能”十大科学问题","categories":[{"name":"会议报告","slug":"会议报告","permalink":"https://mhuig.github.io/categories/%E4%BC%9A%E8%AE%AE%E6%8A%A5%E5%91%8A/"}],"tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://mhuig.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"脑科学","slug":"脑科学","permalink":"https://mhuig.github.io/tags/%E8%84%91%E7%A7%91%E5%AD%A6/"}]},{"title":"Glob表达式","slug":"CentOS/glob表达式","date":"2019-09-11T13:05:18.000Z","updated":"2019-09-11T13:05:18.000Z","comments":true,"path":"posts/55b264de.html","link":"","permalink":"https://mhuig.github.io/posts/55b264de.html","excerpt":"glob是shell使用的路径匹配符，类似于正则表达式，但是与正则表达式不完全相同。在linux操作中如文件匹配等等其实已经使用了glob通配符。由于其在路径匹配方面的强大，其他语言也有相应的实现。我在使用基于node的gulp时遇到glob匹配文件路径，于是顺便整理一下glob的基础语法和使用。","text":"glob是shell使用的路径匹配符，类似于正则表达式，但是与正则表达式不完全相同。在linux操作中如文件匹配等等其实已经使用了glob通配符。由于其在路径匹配方面的强大，其他语言也有相应的实现。我在使用基于node的gulp时遇到glob匹配文件路径，于是顺便整理一下glob的基础语法和使用。 glob表达式(glob expressions)通配符：1234567891011121314151617* 匹配文件路径中的0个或多个字符，但**不会匹配路径分隔符，除非路径分隔符出现在末尾。** 匹配路径中的0个或多个目录及其子目录，如果出现在末尾，也能匹配文件。? 匹配文件路径中的一个字符(不会匹配路径分隔符)。[...] 匹配方括号中出现的字符中的任意一个，当方括号中第一个字符为 ·^ 或 ! 时，则表示不匹配方括号中出现的其他字符中的任意一个。!(pattern|pattern|pattern) 匹配任何与括号中给定的任一参数都不匹配的。?(pattern|pattern|pattern) 匹配括号中给定的任一参数0次或1次。+(pattern|pattern|pattern) 匹配括号中给定的任一参数1次或多次。*(pattern|pattern|pattern) 匹配括号中给定的任一参数0次或多次。@(pattern|pattern|pattern) 匹配括号中给定的任一参数1次。 用实例来加深理解： 123456789101112131415161718192021* 能匹配 a.js , x.y , abc , abc/ ，但不能匹配 a/b.js*.* 能匹配 a.js , style.css , a.b , x.y*/*/*.js 能匹配 a/b/c.js , x/y/z.js ，不能匹配 a/b.js , a/b/c/d.js** 能匹配 abc , a/b.js , a/b/c.js , x/y/z , x/y/z/a.b ，能用来匹配所有的目录和文件**/*.js 能匹配 foo.js , a/foo.js , a/b/foo.js , a/b/c/foo.jsa/**/z 能匹配 a/z , a/b/z , a/b/c/z , a/d/g/h/j/k/za/**b/z 能匹配 a/b/z , a/sb/z ，但不能匹配 a/x/sb/z ，因为只有单 ** 单独出现才能匹配多级目录?.js 能匹配 a.js , b.js , c.jsa?? 能匹配 a.b , abc ，但不能匹配 ab/ ，因为它不会匹配路径分隔符[xyz].js 只能匹配 x.js , y.js , z.js ，不会匹配 xy.js , xyz.js 等，整个中括号只代表一个字符[^xyz].js 能匹配 a.js , b.js , c.js 等，不能匹配 x.js , y.js , z.js 当有多种匹配模式时可以使用数组： 12// 使用数组的方式来匹配多种文件gulp.src([ &#x27;js/*.min.js&#x27;, &#x27;sass/*.min.css&#x27; ]) 使用数组的方式还有一个好处就是可以很方便的使用排除模式，在数组中的单个匹配模式前加上 ! 即是排除模式，它会在匹配的结果中排除这个匹配，要注意一点的是不能在数组中的第一个元素中使用排除模式： 123&#x2F;&#x2F; 使用数组的方式来匹配多种文件gulp.src([&#39;*.js&#39;,&#39;!b*.js&#39;]) &#x2F;&#x2F; 匹配所有js文件，但排除掉以b开头的js文件gulp.src([&#39;!b*.js&#39;,*.js]) &#x2F;&#x2F; 不会排除任何文件，因为排除模式不能出现在数组的第一个元素中 此外，还可以使用展开模式。展开模式以花括号作为定界符，根据它里面的内容，会展开为多个模式，最后匹配的结果为所有展开的模式相加起来得到的结果。展开的例子如下： a{b,c}d 会展开为 abd,acd a{b,}c 会展开为 abc,ac a{0..3}d 会展开为 a0d , a1d , a2d , a3d a{b,c{d,e}f}g 会展开为 abg , acdfg , acefg a{b,c}d{e,f}g 会展开为 abdeg , acdeg , abdeg , abdfg","categories":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"},{"name":"shell","slug":"linux/shell","permalink":"https://mhuig.github.io/categories/linux/shell/"}],"tags":[{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://mhuig.github.io/tags/shell/"},{"name":"通配符","slug":"通配符","permalink":"https://mhuig.github.io/tags/%E9%80%9A%E9%85%8D%E7%AC%A6/"},{"name":"glob表达式","slug":"glob表达式","permalink":"https://mhuig.github.io/tags/glob%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"操作系统引论","slug":"OS/操作系统引论","date":"2019-09-11T11:03:24.000Z","updated":"2019-09-11T11:03:24.000Z","comments":true,"path":"posts/f9a25cd7.html","link":"","permalink":"https://mhuig.github.io/posts/f9a25cd7.html","excerpt":"操作系统（OS）是配置在计算机硬件上的第一层软件，是对硬件系统的首次扩充。","text":"操作系统（OS）是配置在计算机硬件上的第一层软件，是对硬件系统的首次扩充。 操作系统的定义OS是一组控制和管理计算机硬件和软件资源，合理地对各类作业进行调度（合理地组织计算机工作），以及方便用户使用的程序的集合 操作系统的目标和作用操作系统的目标 方便性* 有效性* 提高系统资源利用率 提高系统吞吐量 可扩充性 开放性 遵循世界标准规范 方便性和有效性是设计操作系统时最重要的两个目标。 操作系统的作用 OS作为用户与计算机硬件系统之间的接口（用户的角度） 三种方式使用计算机： 命令行方式 系统调用方式 图标窗口方式 OS作为计算机系统资源的管理者（资源管理角度） 对四类资源进行管理： 处理机管理 存储器管理 I/O设备管理 文件管理 资源管理包含两种资源共享的使用方法： 分时 多个用户分时地使用该资源 空分 存储资源的空间可以被多个用户共同以分割的方式占用。 OS实现了对计算机资源的抽象（扩充机器） 裸机 虚拟机/扩展机 推动操作系统发展的主要动力 不断提高计算机资源利用率 方便用户 机器的不断更新换代 计算机体系结构的不断发展 不断提出新的应用需求 操作系统的发展过程无操作系统的计算机系统 人工操作方式 缺点： 用户独占全机 CPU等待人工操作 人机矛盾 CPU与I/O设备之间速度不匹配的矛盾 工作效率低 脱机输入/输出（Off-Line I/O）方式 程序和数据的输入和输出都是在外围机的控制之下完成的， 即：程序和数据的输入和输出是在脱离主机的情况下进行 脱机I/O的主要优点 减少了CPU的空闲时间 提高I/O速度，缓和了CPU和I/O设备间不匹配的矛盾 单道批处理操作系统 单道批处理系统的处理过程 批处理系统旨在提高系统资源的利用率和系统吞吐量. 特征: 自动性 顺序性 单道性 单道批处理系统的缺点最主要缺点：系统中的资源得不到充分利用 多道批处理操作系统 多道程序设计的基本概念： 内存同时驻留多道程序(作业)，处理机(单处理机)以交替的方式同时处理多道程序。 宏观：已有多道程序开始运行且尚未结束； 微观：某一时刻处理机只运行某道作业。 好处： 提高CPU的利用率； 可提高内存和I/O设备的利用率； 增加系统吞吐量。 能提高吞吐量的原因： 使CPU和资源保持“忙碌”状态； 仅当作业完成或运行不下去时才进行切换，系统开销小。 特征 多道性 无序性：作业完成的先后顺序和他们进入内存的顺序并无严格的对应关系 调度性: A、作业调度 B、进程调度 优点： 资源利用率高 系统吞吐量大 缺点： 平均周转时间长 作业的周转时间是指从作业进入系统开始，直至其完成并退出系统为止所经历的时间。 无交互能力 推动多道批处理系统形成和发展的主要动力是提高资源利用率和系统吞吐量； 分时操作系统 推动分时系统形成和发展的主要动力，则是用户的需求（人——机交互）。 工作方式 一台主机连接了若干个终端；每个终端有一个用户在使用； 交互式的向系统提出命令请求； 系统接受每个用户的命令采用时间片轮转方式处理服务请求并通过交互方式在终端上向用户显示结果，用户根据上步结果发出下道命令。 关键问题: 及时接收 及时处理 作业直接进入内存，在内存才能处理； 采用轮转运行方式。 不允许一个作业长期占用处理机； 规定每个作业只能运行很短的时间，使每个用户及时与自己的作业交互，从而用户请求得到及时响应。 特点 多路性：即同时性（宏观的同时） 交互性 独立性：用户好像独占主机 及时性 实时操作系统 定义 是指系统能及时响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地运行。 实时系统与分时系统特征的比较 多路性 独立性 及时性 交互性 可靠性 操作系统的基本特性 并发性 间断性 失去封闭性 不可再现性 共享性 互斥共享（临界资源） 同时访问（eg：同时读磁盘） 虚拟技术 时分复用技术 虚拟处理机技术 虚拟设备技术 空分复用技术 虚拟磁盘技术 虚拟存储器技术（内存） 异步性 OS结构设计 无结构OS 模块化OS 分层式OS 微内核OS 微内核技术：是指精心设计的、能实现现代操作系统核心功能的小型内核，运行在核心态，开机后常驻内存。 常驻内存的好处：因为CPU只访问内存，速度快、效率高。 微内核OS优点： 提高系统的可扩展性 增强系统的可靠性 可移植性强 提供对分布式系统的支持 融入面向对象技术","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"hexo命令及Markdown语法","slug":"web/hexo命令及Markdown语法","date":"2019-09-05T03:33:59.000Z","updated":"2019-09-05T03:33:59.000Z","comments":true,"path":"posts/f8d2d5ec.html","link":"","permalink":"https://mhuig.github.io/posts/f8d2d5ec.html","excerpt":"hexo是使用Markdown编辑文章的，我写的这些文章也都是用这种标记语言完成的。所以，我们先从Markdown说起。","text":"hexo是使用Markdown编辑文章的，我写的这些文章也都是用这种标记语言完成的。所以，我们先从Markdown说起。 前言你可以使用vim工具直接编辑md文件，也可以用记事本打开md文件编辑你的文章，也可以Markdown的编辑器编写，有很多在线的编辑器，何有不少客户端的编辑器. 什么是MarkdownMarkdown 是一种轻量级标记语言，创始人为约翰·格鲁伯和亚伦·斯沃茨。它允许人们“使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML文档”。 ——维基百科 先简单介绍一下，Markdown的语法，具体怎么用，我相信大家一看例文就马上明白了。 Markdown语法1、分段： 两个回车 2、换行 两个空格 + 回车 3、标题 # ~ ###### 井号的个数表示几级标题，即Markdown可以表示一级标题到六级标题 4、引用 &gt; 5、列表 * ， + ， - ， 1. ，选其中之一，注意后面有个空格 6、代码区块 四个空格 开头 7、链接 1[文字](链接地址) 文字 8、图片 1![](图片地址) &#x2F;&#x2F;图片地址可以是本地路径，也可以是网络地址 9、强调 1**文字** ， __文字__ ， _文字_ ， *文字* 文字 ， 文字 ， 文字 ， 文字 10、代码 1&#96;&#96;&#96;，&#96;&#96; hexo常用命令我们在前面的已经略微的接触了一些hexo的命令，如 hexo new “my blog” ， hexo server 等。下面来介绍一下我们经常会用到的hexo命令 1、新建 1hexo new &quot;my blog&quot; 新建的文件在 hexo/source/_posts/my-blog.md 2、生成静态页面 1hexo g 一般部署上去的时候都需要编译一下，编译后，会出现一个 public 文件夹，将所有的md文件编译成html文件 3、开启本地服务 1hexo s 这个命令，我之前已经用过了，开启本地hexo服务用的 4、部署 1hexo d 部署到git上的时候，需要用这个命令 5、清除 public 1hexo clean 当 source 文件夹中的部分资源更改过之后，特别是对文件进行了删除或者路径的改变之后，需要执行这个命令，然后重新编译。","categories":[{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/categories/web/"},{"name":"hexo","slug":"web/hexo","permalink":"https://mhuig.github.io/categories/web/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://mhuig.github.io/tags/hexo/"},{"name":"Markdown","slug":"markdown","permalink":"https://mhuig.github.io/tags/markdown/"}]},{"title":"AT89S52 或 STC89C52RC 串口发送温湿度数据","slug":"51/AT89S52 或 STC89C52RC 串口发送温湿度数据","date":"2018-12-02T09:54:31.000Z","updated":"2018-12-02T09:54:31.000Z","comments":true,"path":"posts/3d7d3997.html","link":"","permalink":"https://mhuig.github.io/posts/3d7d3997.html","excerpt":"AT89S52 或 STC89C52RC 串口发送温湿度数据","text":"AT89S52 或 STC89C52RC 串口发送温湿度数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224//****************************************************************////单片机 AT89S52 或 STC89C52RC//功能 串口发送温湿度数据 晶振 11.0592M 波特率 9600//硬件 sbit TXP口为通讯口连接DHT11,DHT11的电源和地连接单片机的电源和地，单片机串口加MAX232连接电脑//****************************************************************//#include &lt;STDIO.H&gt;#include &lt;reg51.h&gt;#include &lt;intrins.h&gt;//typedef unsigned char U8; /* defined for unsigned 8-bits integer variable 无符号8位整型变量 */typedef signed char S8; /* defined for signed 8-bits integer variable 有符号8位整型变量 */typedef unsigned int U16; /* defined for unsigned 16-bits integer variable 无符号16位整型变量 */typedef signed int S16; /* defined for signed 16-bits integer variable 有符号16位整型变量 */typedef unsigned long U32; /* defined for unsigned 32-bits integer variable 无符号32位整型变量 */typedef signed long S32; /* defined for signed 32-bits integer variable 有符号32位整型变量 */typedef float F32; /* single precision floating point variable (32bits) 单精度浮点数（32位长度） */typedef double F64; /* double precision floating point variable (64bits) 双精度浮点数（64位长度） *///#define uchar unsigned char#define uint unsigned int#define Data_0_time 4//----------------------------------------------////----------------IO口定义区--------------------////----------------------------------------------//sbit TXP = P2^0 ;//----------------------------------------------////----------------定义区--------------------////----------------------------------------------//U8 U8FLAG,k;U8 U8count,U8temp;U8 U8T_data_H,U8T_data_L,U8RH_data_H,U8RH_data_L,U8checkdata;U8 U8T_data_H_temp,U8T_data_L_temp,U8RH_data_H_temp,U8RH_data_L_temp,U8checkdata_temp;U8 U8comdata;U8 outdata[5]; //定义发送的字节数U8 indata[5];U8 count, count_r=0;U8 str[5]= &#123;&quot;RS232&quot;&#125;;U16 U16temp1,U16temp2;void SendData(U8 *a) &#123; outdata[0] = a[0]; outdata[1] = a[1]; outdata[2] = a[2]; outdata[3] = a[3]; outdata[4] = a[4]; count = 1; SBUF=outdata[0];&#125;void Delay(U16 j) &#123; U8 i; for(; j&gt;0; j--) &#123; for(i=0; i&lt;27; i++); &#125;&#125;void Delay_10us(void) &#123; U8 i; i--; i--; i--; i--; i--; i--;&#125;void COM(void) &#123; U8 i; for(i=0; i&lt;8; i++) &#123; U8FLAG=2; while((!TXP)&amp;&amp;U8FLAG++); Delay_10us(); Delay_10us(); Delay_10us(); U8temp=0; if(TXP) U8temp=1; U8FLAG=2; while((TXP)&amp;&amp;U8FLAG++); //超时则跳出for循环 if(U8FLAG==1) break; //判断数据位是0还是1 // 如果高电平高过预定0高电平值则数据位为 1 U8comdata&lt;&lt;=1; U8comdata|=U8temp; //0 &#125;//rof&#125;//--------------------------------//-----湿度读取子程序 ------------//--------------------------------//----以下变量均为全局变量--------//----温度高8位== U8T_data_H------//----温度低8位== U8T_data_L------//----湿度高8位== U8RH_data_H-----//----湿度低8位== U8RH_data_L-----//----校验 8位 == U8checkdata-----//----调用相关子程序如下----------//---- Delay();, Delay_10us();,COM();//--------------------------------void RH(void) &#123; //主机拉低18ms TXP=0; Delay(180); TXP=1; //总线由上拉电阻拉高 主机延时20us Delay_10us(); Delay_10us(); Delay_10us(); Delay_10us(); //主机设为输入 判断从机响应信号 TXP=1; //判断从机是否有低电平响应信号 如不响应则跳出，响应则向下运行 if(!TXP) &#123; //T ! U8FLAG=2; //判断从机是否发出 80us 的低电平响应信号是否结束 while((!TXP)&amp;&amp;U8FLAG++); U8FLAG=2; //判断从机是否发出 80us 的高电平，如发出则进入数据接收状态 while((TXP)&amp;&amp;U8FLAG++); //数据接收状态 COM(); U8RH_data_H_temp=U8comdata; COM(); U8RH_data_L_temp=U8comdata; COM(); U8T_data_H_temp=U8comdata; COM(); U8T_data_L_temp=U8comdata; COM(); U8checkdata_temp=U8comdata; TXP=1; //数据校验 U8temp=(U8T_data_H_temp+U8T_data_L_temp+U8RH_data_H_temp+U8RH_data_L_temp); if(U8temp==U8checkdata_temp) &#123; U8RH_data_H=U8RH_data_H_temp; U8RH_data_L=U8RH_data_L_temp; U8T_data_H=U8T_data_H_temp; U8T_data_L=U8T_data_L_temp; U8checkdata=U8checkdata_temp; &#125;//fi &#125;//fi&#125;//----------------------------------------------//main()功能描述: AT89C51 11.0592MHz 串口发//送温湿度数据,波特率 9600//----------------------------------------------void main() &#123; U8 i=0,j=0; //uchar str[6]=&#123;&quot;RS232&quot;&#125;; /* 系统初始化 */ TMOD = 0x20; //定时器T1使用工作方式2 TH1 = 253; // 设置初值 TL1 = 253; TR1 = 1; // 开始计时 SCON = 0x50; //工作方式1，波特率9600bps，允许接收 ES = 1; EA = 1; // 打开所以中断 TI = 0; RI = 0; SendData(str) ; //发送到串口 //Delay(1); //延时100US（12M晶振) while(1) &#123; //------------------------ //调用温湿度读取子程序 RH(); //串口显示程序 //-------------------------- str[0]=U8RH_data_H; str[1]=U8RH_data_L; str[2]=U8T_data_H; str[3]=U8T_data_L; str[4]=U8checkdata; SendData(str) ; //发送到串口 //读取模块数据周期不易小于 2S Delay(20000); &#125;//elihw&#125;// mainvoid RSINTR() interrupt 4 using 2 &#123; U8 InPut3; if(TI==1) &#123; //发送中断 TI=0; if(count!=5) &#123; //发送完5位数据 SBUF= outdata[count]; count++; &#125; &#125; if(RI==1) &#123; //接收中断 InPut3=SBUF; indata[count_r]=InPut3; count_r++; RI=0; if (count_r==5) &#123; //接收完4位数据 //数据接收完毕处理。 count_r=0; str[0]=indata[0]; str[1]=indata[1]; str[2]=indata[2]; str[3]=indata[3]; str[4]=indata[4]; P0=0; &#125; &#125;&#125;","categories":[{"name":"51","slug":"51","permalink":"https://mhuig.github.io/categories/51/"}],"tags":[{"name":"51","slug":"51","permalink":"https://mhuig.github.io/tags/51/"},{"name":"温湿度","slug":"温湿度","permalink":"https://mhuig.github.io/tags/%E6%B8%A9%E6%B9%BF%E5%BA%A6/"}]},{"title":"HC-SR04 超声波测距模块 串口 程序","slug":"51/HC-SR04 超声波测距模块 串口 程序","date":"2018-12-02T09:52:51.000Z","updated":"2018-12-02T09:52:51.000Z","comments":true,"path":"posts/eb168c8b.html","link":"","permalink":"https://mhuig.github.io/posts/eb168c8b.html","excerpt":"HC-SR04 超声波测距模块 串口 程序","text":"HC-SR04 超声波测距模块 串口 程序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104/***********************************************************************************************************///HC-SR04 超声波测距模块 串口 程序//晶振：11.0592//接线：模块TRIG接 P1.2 ECH0 接P1.1//串口波特率9600//Atmel AT89C52 C51/***********************************************************************************************************/#include &lt;AT89X51.H&gt;#include &lt;intrins.h&gt;#include &lt;STDIO.H&gt;#define uchar unsigned char#define uint unsigned int#define RX P1_1#define TX P1_2unsigned int time=0;unsigned int timer=0;float S=0;bit flag =0;/********************************************************/void Conut(void) &#123; time=TH0*256+TL0; TH0=0; TL0=0; S=(time*1.87)/100; //算出来是CM if(flag==1) &#123; //超出测量 flag=0; printf(&quot;-----\\n&quot;); &#125; printf(&quot;S=%fcm\\n&quot;,S);&#125;/********************************************************/void delayms(unsigned int ms) &#123; unsigned char i=100,j; for(; ms; ms--) &#123; while(--i) &#123; j=10; while(--j); &#125; &#125;&#125;/********************************************************/void zd0() interrupt 1 &#123; //T0中断用来计数器溢出,超过测距范围 flag=1; //中断溢出标志&#125;/********************************************************/void StartModule() &#123; //T1中断用来扫描数码管和计800MS启动模块 TX=1; //800MS 启动一次模块 _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); _nop_(); TX=0;&#125;/********************************************************/void main(void) &#123; TMOD=0x21; //设T0为方式1，GATE=1； SCON=0x50; TH1=0xFD; TL1=0xFD; TH0=0; TL0=0; TR0=1; ET0=1; //允许T0中断 TR1=1; //开启定时器 TI=1; EA=1; //开启总中断 while(1) &#123; StartModule(); while(!RX); //当RX为零时等待 TR0=1; //开启计数 while(RX); //当RX为1计数并等待 TR0=0; //关闭计数 Conut(); //计算 delayms(100); //100MS &#125;&#125;","categories":[{"name":"51","slug":"51","permalink":"https://mhuig.github.io/categories/51/"}],"tags":[{"name":"51","slug":"51","permalink":"https://mhuig.github.io/tags/51/"},{"name":"超声波","slug":"超声波","permalink":"https://mhuig.github.io/tags/%E8%B6%85%E5%A3%B0%E6%B3%A2/"}]},{"title":"51按键时钟","slug":"51/51按键时钟","date":"2018-12-02T09:51:32.000Z","updated":"2018-12-02T09:51:32.000Z","comments":true,"path":"posts/d07ffe1c.html","link":"","permalink":"https://mhuig.github.io/posts/d07ffe1c.html","excerpt":"51按键时钟","text":"51按键时钟 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/* * 按键时钟 秒表，可以通过按键开始或是停止 */#include&lt;reg52.h&gt;#define uchar unsigned charsbit key =P3 ^ 3; //按键uchar counter=0,tmp,second=0,minute=0, change = 1;int led[]= &#123;0xc0, 0xf9, 0xa4, 0xb0, 0x99, 0x92, 0x82, 0xf8, 0x80, 0x90&#125;; //数字0-9int _led[]= &#123;0x40, 0x79, 0x24, 0x30, 0x19, 0x12, 0x02, 0x78, 0x00, 0x10&#125;;void clockrun();void main() &#123; //设置TMOD寄存器 TMOD=0X01; //设置TMOD寄存器 TH0=(65536-5000)/256; //装初值 TL0=(65536-5000)%256; EA=1; //开 中断 ET0=1; TR0=1; if(key==0) &#123;//按键按下 while(1) &#123; clockrun(); &#125; &#125;&#125;void zhongduan()interrupt 1 &#123; TH0=(65536-5000)/256; //装初值 TL0=(65536-5000)%256; TF0=0; TR0=1; counter++; if(counter==200) &#123; counter=0; second++; if(second==60) &#123; second=0; minute++; &#125; &#125; change = 1;&#125;void clockrun() &#123; tmp=counter%4; switch(tmp) &#123; case 0: P2 = 0x7f; P0 = led[second%10]; break; case 1: P2 = 0xbf; P0 = led[second/10]; break; case 2: P2 = 0xdf; P0 = _led[minute%10]; break; case 3: P2 = 0xef; P0 = led[minute/10]; break; &#125;&#125;","categories":[{"name":"51","slug":"51","permalink":"https://mhuig.github.io/categories/51/"}],"tags":[{"name":"51","slug":"51","permalink":"https://mhuig.github.io/tags/51/"},{"name":"按键时钟","slug":"按键时钟","permalink":"https://mhuig.github.io/tags/%E6%8C%89%E9%94%AE%E6%97%B6%E9%92%9F/"}]},{"title":"51 秒表","slug":"51/51 秒表","date":"2018-12-02T09:50:24.000Z","updated":"2018-12-02T09:50:24.000Z","comments":true,"path":"posts/129a9db5.html","link":"","permalink":"https://mhuig.github.io/posts/129a9db5.html","excerpt":"51 单片机 秒表","text":"51 单片机 秒表 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** 秒表*/#include&lt;reg52.h&gt;#define uchar unsigned charuchar counter=0,tmp,second=0,minute=0, change = 1;int led[]= &#123;0xc0, 0xf9, 0xa4, 0xb0, 0x99, 0x92, 0x82, 0xf8, 0x80, 0x90&#125;; //数字0-9int _led[]= &#123;0x40, 0x79, 0x24, 0x30, 0x19, 0x12, 0x02, 0x78, 0x00, 0x10&#125;;void main() &#123; //设置TMOD寄存器 TMOD=0X01; //设置TMOD寄存器 TH0=(65536-5000)/256; //装初值 TL0=(65536-5000)%256; EA=1; //开 中断 ET0=1; TR0=1; while(1) &#123; tmp=counter%4; switch(tmp) &#123; case 0: P2 = 0x7f; P0 = led[second%10]; break; case 1: P2 = 0xbf; P0 = led[second/10]; break; case 2: P2 = 0xdf; P0 = _led[minute%10]; break; case 3: P2 = 0xef; P0 = led[minute/10]; break; &#125; &#125;&#125;void zhongduan()interrupt 1 &#123; TH0=(65536-5000)/256; //装初值 TL0=(65536-5000)%256; TF0=0; TR0=1; counter++; if(counter==200) &#123; counter=0; second++; if(second==60) &#123; second=0; minute++; &#125; &#125; change = 1;&#125;","categories":[{"name":"51","slug":"51","permalink":"https://mhuig.github.io/categories/51/"}],"tags":[{"name":"51","slug":"51","permalink":"https://mhuig.github.io/tags/51/"},{"name":"秒表","slug":"秒表","permalink":"https://mhuig.github.io/tags/%E7%A7%92%E8%A1%A8/"}]},{"title":"pyc文件反编译到Python源码","slug":"Python/pyc文件反编译到Python源码","date":"2018-12-01T08:20:24.000Z","updated":"2018-12-01T08:20:24.000Z","comments":true,"path":"posts/14fa5bba.html","link":"","permalink":"https://mhuig.github.io/posts/14fa5bba.html","excerpt":"pyc文件反编译到Python源码","text":"pyc文件反编译到Python源码 使用uncompyle 项目地址：https://github.com/wibiti/uncompyle2 注： 按照官方文档的说法应该是只支持python 2.7，其他版本我也没有测试 安装最方便的就是使用pip安装 1pip install uncompyle 使用方法查看帮助1uncompyle6 --help 将models.pyc反编译成py文件1uncompyle6 models.pyc &gt; models.py 将当前文件夹中所有的pyc文件反编译成后缀名为.pyc_dis的源文件1uncompile -o . *.pyc","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"反编译","slug":"python/反编译","permalink":"https://mhuig.github.io/categories/python/%E5%8F%8D%E7%BC%96%E8%AF%91/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"反编译","slug":"反编译","permalink":"https://mhuig.github.io/tags/%E5%8F%8D%E7%BC%96%E8%AF%91/"}]},{"title":"Python RailFenceCipher","slug":"Python/Python RailFenceCipher","date":"2018-12-01T07:59:17.000Z","updated":"2018-12-01T07:59:17.000Z","comments":true,"path":"posts/91223731.html","link":"","permalink":"https://mhuig.github.io/posts/91223731.html","excerpt":"Python RailFenceCipher","text":"Python RailFenceCipher RailFenceCipher.py 12345678910111213141516171819202122232425#coding=utf-8def railFenceCipher(): e = input() elen = len(e) field=[] for i in range(2,elen): if(elen%i==0): field.append(i) for f in field: b = int(elen / f) result = &#123;x:&#x27;&#x27; for x in range(b)&#125; for i in range(elen): a = i % b; result.update(&#123;a:result[a] + e[i]&#125;) d = &#x27;&#x27; for i in range(b): d = d + result[i] print (d.lower())if __name__ == &#x27;__main__&#x27;: try: while True: railFenceCipher() except EOFError: exit()","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"密码学","slug":"python/密码学","permalink":"https://mhuig.github.io/categories/python/%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"密码学","slug":"密码学","permalink":"https://mhuig.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"加解密","slug":"加解密","permalink":"https://mhuig.github.io/tags/%E5%8A%A0%E8%A7%A3%E5%AF%86/"}]},{"title":"Python QRcode","slug":"Python/Python QRcode","date":"2018-12-01T06:39:17.000Z","updated":"2018-12-01T06:39:17.000Z","comments":true,"path":"posts/6980c27e.html","link":"","permalink":"https://mhuig.github.io/posts/6980c27e.html","excerpt":"Python QRcode","text":"Python QRcode enQRcode.py 1234567891011121314151617181920212223242526272829303132import qrcodeimport osimport sysimport time#pip install zxing解析库，还需要安装PIL，pillow和qrCode库QRImagePath = os.getcwd() + &#x27;/qrcode.png&#x27; #临时存储位置qr = qrcode.QRCode( version=1, error_correction=qrcode.constants.ERROR_CORRECT_L, box_size=10, border=2,) #设置图片格式print(&quot;input:QRcode image:&quot;)data = input() #运行时输入数据qr.add_data(data)qr.make(fit=True)img = qr.make_image()img.save(&#x27;qrcode.png&#x27;) #生成图片 if sys.platform.find(&#x27;darwin&#x27;) &gt;= 0: os.system(&#x27;open %s&#x27; % QRImagePath) elif sys.platform.find(&#x27;linux&#x27;) &gt;= 0: os.system(&#x27;xdg-open %s&#x27; % QRImagePath)else: os.system(&#x27;call %s&#x27; % QRImagePath) time.sleep(5) #间隔5个单位#os.remove(QRImagePath) #删除图片 deQRcode.py 1234567891011121314151617181920212223242526272829303132333435363738import osimport loggingfrom PIL import Imageimport zxing #导入解析包import randomlogger = logging.getLogger(__name__) #记录数据if not logger.handlers: logging.basicConfig(level = logging.INFO)DEBUG = (logging.getLevelName(logger.getEffectiveLevel()) == &#x27;DEBUG&#x27;) #记录调式过程# 在当前目录生成临时文件，规避java的路径问题def ocr_qrcode_zxing(filename): img = Image.open(filename) ran = int(random.random() * 100000) #设置随机数据的大小 img.save(&#x27;%s%s.jpg&#x27; % (os.path.basename(filename).split(&#x27;.&#x27;)[0], ran)) zx = zxing.BarCodeReader() #调用zxing二维码读取包 data = &#x27;&#x27; zxdata = zx.decode(&#x27;%s%s.jpg&#x27; % (os.path.basename(filename).split(&#x27;.&#x27;)[0], ran)) #图片解码# 删除临时文件 os.remove(&#x27;%s%s.jpg&#x27; % (os.path.basename(filename).split(&#x27;.&#x27;)[0], ran)) if zxdata: logger.debug(u&#x27;zxing识别二维码:%s,内容: %s&#x27; % (filename, zxdata)) data = zxdata else: logger.error(u&#x27;识别zxing二维码出错:%s&#x27; % (filename)) img.save(&#x27;%s-zxing.jpg&#x27; % filename) return data #返回记录的内容if __name__ == &#x27;__main__&#x27;: print(&quot;input:QRcode path:&quot;) filename = input() # zxing二维码识别 ltext = ocr_qrcode_zxing(filename) #将图片文件里的信息转码放到ltext里面 logger.info(u&#x27;[%s]Zxing二维码识别:[%s]!!!&#x27; % (filename, ltext)) #记录文本信息 print(ltext) #打印出二维码名字","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"密码学","slug":"python/密码学","permalink":"https://mhuig.github.io/categories/python/%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"密码学","slug":"密码学","permalink":"https://mhuig.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"加解密","slug":"加解密","permalink":"https://mhuig.github.io/tags/%E5%8A%A0%E8%A7%A3%E5%AF%86/"}]},{"title":"Python Playfair","slug":"Python/Python Playfair","date":"2018-12-01T05:29:17.000Z","updated":"2018-12-01T05:29:17.000Z","comments":true,"path":"posts/b4a5318a.html","link":"","permalink":"https://mhuig.github.io/posts/b4a5318a.html","excerpt":"Python Playfair","text":"Python Playfair Playfair.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143#########################Playfair密码##########################约定1：若明文字母数量为奇数，在明文末尾添加一个&#x27;Z&#x27;#约定2：&#x27;I&#x27;作为&#x27;J&#x27;来处理#字母表letter_list=&#x27;ABCDEFGHJKLMNOPQRSTUVWXYZ&#x27;#密码表T_letter=[&#x27;&#x27;,&#x27;&#x27;,&#x27;&#x27;,&#x27;&#x27;,&#x27;&#x27;]#根据密钥建立密码表def Create_Matrix(key): key=Remove_Duplicates(key) #移除密钥中的重复字母 key=key.replace(&#x27; &#x27;,&#x27;&#x27;) #去除密钥中的空格 for ch in letter_list: #根据密钥获取新组合的字母表 if ch not in key: key+=ch j=0 for i in range(len(key)): #将新的字母表里的字母逐个填入密码表中，组成5*5的矩阵 T_letter[j]+=key[i] #j用来定位字母表的行 if 0==(i+1)%5: j+=1#移除字符串中重复的字母def Remove_Duplicates(key): key=key.upper() #转成大写字母组成的字符串 _key=&#x27;&#x27; for ch in key: if ch==&#x27;I&#x27;: ch=&#x27;J&#x27; if ch in _key: continue else: _key+=ch return _key #获取字符在密码表中的位置def Get_MatrixIndex(ch): for i in range(len(T_letter)): for j in range(len(T_letter)): if ch==T_letter[i][j]: return i,j #i为行，j为列 #加密def Encrypt(plaintext,T_letter): ciphertext=&#x27;&#x27; if len(plaintext) % 2 !=0: #如果新的明文长度为奇数，在其末尾添上&#x27;Z&#x27; plaintext+=&#x27;Z&#x27; i=0 while i&lt;len(plaintext): #对明文进行遍历 if True==plaintext[i].isalpha(): #如果是明文是字母的话， j=i+1 #则开始对该字母之后的明文进行遍历， while j&lt;len(plaintext): #直到遍历到字母，进行加密 if True==plaintext[j].isalpha(): if &#x27;I&#x27;==plaintext[i].upper(): # x=Get_MatrixIndex(&#x27;J&#x27;) # else: # x=Get_MatrixIndex(plaintext[i].upper()) #对字符在密码表中的坐标 if &#x27;I&#x27;==plaintext[j].upper(): #进行定位,同时将&#x27;I&#x27;作为 y=Get_MatrixIndex(&#x27;J&#x27;) #&#x27;J&#x27;来处理 else: # y=Get_MatrixIndex(plaintext[j].upper()) # if x[0]==y[0]: #如果在同一行 ciphertext+=T_letter[x[0]][(x[1]+1)%5]+T_letter[y[0]][(y[1]+1)%5] elif x[1]==y[1]: #如果在同一列 ciphertext+=T_letter[(x[1]+1)%5][x[0]]+T_letter[(y[1]+1)%5][y[0]] else: #如果不同行不同列 ciphertext+=T_letter[x[0]][y[1]]+T_letter[y[0]][x[1]] break; #每组明文对加密完成后，结束本次对明文的遍历 j+=1 i=j+1 #每次对明文的遍历是从加密过后的明文的后一个明文开始的,结束本次循环 continue else: ciphertext+=plaintext[i] #如果明文不是字母，直接加到密文上 i+=1 return ciphertext #解密def Decrypt(ciphertext,T_letter): plaintext=&#x27;&#x27; if len(ciphertext) % 2 !=0: #如果新的密文长度为奇数，在其末尾添上&#x27;Z&#x27; ciphertext+=&#x27;Z&#x27; i=0 while i&lt;len(ciphertext): #对密文进行遍历 if True==ciphertext[i].isalpha(): #如果是密文是字母的话， j=i+1 #则开始对该字母之后的密文进行遍历， while j&lt;len(ciphertext): #直到遍历到字母，进行解密 if True==ciphertext[j].isalpha(): if &#x27;I&#x27;==ciphertext[i].upper(): # x=Get_MatrixIndex(&#x27;J&#x27;) # else: # x=Get_MatrixIndex(ciphertext[i].upper()) #对字符在密码表中的坐标 if &#x27;I&#x27;==ciphertext[j].upper(): #进行定位,同时将&#x27;I&#x27;作为 y=Get_MatrixIndex(&#x27;J&#x27;) #&#x27;J&#x27;来处理 else: # y=Get_MatrixIndex(ciphertext[j].upper()) # if x[0]==y[0]: #如果在同一行 plaintext+=T_letter[x[0]][(x[1]-1)%5]+T_letter[y[0]][(y[1]-1)%5] elif x[1]==y[1]: #如果在同一列 plaintext+=T_letter[(x[1]-1)%5][x[0]]+T_letter[(y[1]-1)%5][y[0]] else: #如果不同行不同列 plaintext+=T_letter[x[0]][y[1]]+T_letter[y[0]][x[1]] break; #每组密文对解密完成后，结束本次对密文的遍历 j+=1 i=j+1 #每次对密文的遍历是从解密过后的密文的后一个密文开始的,结束本次循环 continue else: plaintext+=ciphertext[i] #如果密文不是字母，直接加到明文上 i+=1 return plaintext #主函数if __name__==&#x27;__main__&#x27;: print(&quot;加密请按D,解密请按E:&quot;) user_input=input(); while(user_input!=&#x27;D&#x27; and user_input!=&#x27;E&#x27;):#输入合法性检测 print(&quot;输入有误!请重新输入:&quot;) user_input=input() print(&#x27;请输入密钥，密钥由英文字母组成:&#x27;) key=input() Create_Matrix(key) #建立密码表 if user_input==&#x27;D&#x27;: #加密 print(&#x27;请输入明文:&#x27;) plaintext=input() print(&quot;密文为:\\n%s&quot; % Encrypt(plaintext,T_letter)) else: #解密 print(&#x27;请输入密文:&#x27;) ciphertext=input() print(&#x27;明文为:\\n%s&#x27; % Decrypt(ciphertext,T_letter))","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"密码学","slug":"python/密码学","permalink":"https://mhuig.github.io/categories/python/%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"密码学","slug":"密码学","permalink":"https://mhuig.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"加解密","slug":"加解密","permalink":"https://mhuig.github.io/tags/%E5%8A%A0%E8%A7%A3%E5%AF%86/"}]},{"title":"Python Caesar","slug":"Python/Python Caesar","date":"2018-12-01T03:49:43.000Z","updated":"2018-12-01T03:49:43.000Z","comments":true,"path":"posts/fecd7f2.html","link":"","permalink":"https://mhuig.github.io/posts/fecd7f2.html","excerpt":"Python Caesar","text":"Python Caesar Caesar.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#-*-coding:utf-8-*-import osdef encryption(): str_raw = input(&quot;请输入明文：&quot;) k = int(input(&quot;请输入位移值：&quot;)) str_change = str_raw.lower() str_list = list(str_change) str_list_encry = str_list i = 0 while i &lt; len(str_list): if ord(str_list[i]) &lt; 123-k: str_list_encry[i] = chr(ord(str_list[i]) + k) else: str_list_encry[i] = chr(ord(str_list[i]) + k - 26) i = i+1 print (&quot;加密结果为：&quot;+&quot;&quot;.join(str_list_encry))def decryption(): str_raw = input(&quot;请输入密文：&quot;) k = int(input(&quot;请输入位移值：(-1代表穷举)&quot;)) if k==-1: print(&quot;解密结果为：&quot;) for k in range(1,27): str_change = str_raw.lower() str_list = list(str_change) str_list_decry = str_list i = 0 while i &lt; len(str_list): if ord(str_list[i]) &gt;= 97+k: str_list_decry[i] = chr(ord(str_list[i]) - k) else: str_list_decry[i] = chr(ord(str_list[i]) + 26 - k) i = i+1 print (&quot;&quot;.join(str_list_decry)) else: print(&quot;解密结果为：&quot;) str_change = str_raw.lower() str_list = list(str_change) str_list_decry = str_list i = 0 while i &lt; len(str_list): if ord(str_list[i]) &gt;= 97+k: str_list_decry[i] = chr(ord(str_list[i]) - k) else: str_list_decry[i] = chr(ord(str_list[i]) + 26 - k) i = i+1 print (&quot;&quot;.join(str_list_decry))def caesar(): print (u&quot;1. 加密&quot;) print (u&quot;2. 解密&quot;) choice = input(&quot;请选择：&quot;) if choice == &quot;1&quot;: encryption() elif choice == &quot;2&quot;: decryption() else: print (u&quot;您的输入有误！&quot;)if __name__ == &#x27;__main__&#x27;: try: while True: caesar() except EOFError: exit()","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"密码学","slug":"python/密码学","permalink":"https://mhuig.github.io/categories/python/%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"密码学","slug":"密码学","permalink":"https://mhuig.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"加解密","slug":"加解密","permalink":"https://mhuig.github.io/tags/%E5%8A%A0%E8%A7%A3%E5%AF%86/"}]},{"title":"Python BinaryConversion","slug":"Python/Python BinaryConversion","date":"2018-12-01T03:23:17.000Z","updated":"2018-12-01T03:23:17.000Z","comments":true,"path":"posts/1601d925.html","link":"","permalink":"https://mhuig.github.io/posts/1601d925.html","excerpt":"Python BinaryConversion","text":"Python BinaryConversion Binary.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#coding:utf-8import reimport argparse def bintostr(text): text &#x3D; text.replace(&#39; &#39;,&#39;&#39;) text &#x3D; re.findall(r&#39;.&#123;8&#125;&#39;,text) s &#x3D; map(lambda x:chr(int(x,2)),text) #批量二进制转十进制 flag &#x3D; &#39;&#39;.join(s) return (flag) def asciitostr(text): if &#39; &#39; in text: text &#x3D; text.split(&#39; &#39;) elif &#39;,&#39; in text: text &#x3D; text.split(&#39;,&#39;) s &#x3D; map(lambda x:chr(int(x)),text) flag &#x3D; &#39;&#39;.join(s) return flag def hextostr(text): text &#x3D; re.findall(r&#39;.&#123;2&#125;&#39;,text) #print text s &#x3D; map(lambda x:chr(int(x,16)),text) #print s flag &#x3D; &#39;&#39;.join(s) return flag if __name__ &#x3D;&#x3D; &#39;__main__&#39;: parser &#x3D; argparse.ArgumentParser() parser.add_argument(&quot;-b&quot;) parser.add_argument(&quot;-a&quot;) parser.add_argument(&quot;-x&quot;) argv &#x3D; parser.parse_args() #print argv if argv.b: res &#x3D; bintostr(argv.b) print (res) elif argv.a: res &#x3D; asciitostr(argv.a) print (res) elif argv.x: res &#x3D; hextostr(argv.x) print (res)","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"密码学","slug":"python/密码学","permalink":"https://mhuig.github.io/categories/python/%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"密码学","slug":"密码学","permalink":"https://mhuig.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"加解密","slug":"加解密","permalink":"https://mhuig.github.io/tags/%E5%8A%A0%E8%A7%A3%E5%AF%86/"}]},{"title":"Python Morse","slug":"Python/Python Morse","date":"2018-12-01T02:52:17.000Z","updated":"2018-12-01T02:52:17.000Z","comments":true,"path":"posts/a2af0ea3.html","link":"","permalink":"https://mhuig.github.io/posts/a2af0ea3.html","excerpt":"Python Morse","text":"Python Morse Morse.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# -*- coding:utf-8 -*-def Morse(): try: s = input() codebook = &#123; &#x27;A&#x27;:&quot;.-&quot;, &#x27;B&#x27;:&quot;-...&quot;, &#x27;C&#x27;:&quot;-.-.&quot;, &#x27;D&#x27;:&quot;-..&quot;, &#x27;E&#x27;:&quot;.&quot;, &#x27;F&#x27;:&quot;..-.&quot;, &#x27;G&#x27;:&quot;--.&quot;, &#x27;H&#x27;:&quot;....&quot;, &#x27;I&#x27;:&quot;..&quot;, &#x27;J&#x27;:&quot;.---&quot;, &#x27;K&#x27;:&quot;-.-&quot;, &#x27;L&#x27;:&quot;.-..&quot;, &#x27;M&#x27;:&quot;--&quot;, &#x27;N&#x27;:&quot;-.&quot;, &#x27;O&#x27;:&quot;---&quot;, &#x27;P&#x27;:&quot;.--.&quot;, &#x27;Q&#x27;:&quot;--.-&quot;, &#x27;R&#x27;:&quot;.-.&quot;, &#x27;S&#x27;:&quot;...&quot;, &#x27;T&#x27;:&quot;-&quot;, &#x27;U&#x27;:&quot;..-&quot;, &#x27;V&#x27;:&quot;.--&quot;, &#x27;W&#x27;:&quot;.--&quot;, &#x27;X&#x27;:&quot;-..-&quot;, &#x27;Y&#x27;:&quot;-.--&quot;, &#x27;Z&#x27;:&quot;--..&quot;, &#x27;1&#x27;:&quot;.----&quot;, &#x27;2&#x27;:&quot;..---&quot;, &#x27;3&#x27;:&quot;...---&quot;, &#x27;4&#x27;:&quot;....-&quot;, &#x27;5&#x27;:&quot;.....&quot;, &#x27;6&#x27;:&quot;-....&quot;, &#x27;7&#x27;:&quot;--...&quot;, &#x27;8&#x27;:&quot;---..&quot;, &#x27;9&#x27;:&quot;----.&quot;, &#x27;0&#x27;:&quot;-----&quot;, &#x27;.&#x27;:&quot;.━.━.━&quot;, &#x27;?&#x27;:&quot;..--..&quot;, &#x27;!&#x27;:&quot;-.-.--&quot;, &#x27;(&#x27;:&quot;-.--.&quot;, &#x27;@&#x27;:&quot;.--.-.&quot;, &#x27;:&#x27;:&quot;---...&quot;, &#x27;=&#x27;:&quot;-...-&quot;, &#x27;-&#x27;:&quot;-....-&quot;, &#x27;)&#x27;:&quot;-.--.-&quot;, &#x27;+&#x27;:&quot;.-.-.&quot;, &#x27;,&#x27;:&quot;--..--&quot;, &#x27;\\&#x27;&#x27;:&quot;.----.&quot;, &#x27;_&#x27;:&quot;..--.-&quot;, &#x27;$&#x27;:&quot;...-..-&quot;, &#x27;;&#x27;:&quot;-.-.-.&quot;, &#x27;/&#x27;:&quot;-..-.&quot;, &#x27;\\&quot;&#x27;:&quot;.-..-.&quot;, &#125; clear = &quot;&quot; cipher = &quot;&quot; while 1: ss = s.split(&quot; &quot;); for c in ss: for k in codebook.keys(): if codebook[k] == c: cipher+=k print(cipher) break; except Exception as e: print(&quot;&quot;,end=&quot;&quot;)if __name__ == &#x27;__main__&#x27;: try: while True: Morse() except EOFError: exit()","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"密码学","slug":"python/密码学","permalink":"https://mhuig.github.io/categories/python/%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"密码学","slug":"密码学","permalink":"https://mhuig.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"加解密","slug":"加解密","permalink":"https://mhuig.github.io/tags/%E5%8A%A0%E8%A7%A3%E5%AF%86/"}]},{"title":"Python MD5","slug":"Python/Python MD5","date":"2018-12-01T02:29:16.000Z","updated":"2018-12-01T02:29:16.000Z","comments":true,"path":"posts/53ab8d74.html","link":"","permalink":"https://mhuig.github.io/posts/53ab8d74.html","excerpt":"Python MD5","text":"Python MD5 MD5.py 12345678910111213141516171819202122232425262728import hashlibclass MD5: def str(): str=input() m = hashlib.md5() m.update(str.encode(&#x27;utf-8&#x27;)) print (m.hexdigest()) def filebin(): src=input() f = open(src, &#x27;rb&#x27;) f_md5 = hashlib.md5() f_md5.update(f.read()) print (f_md5.hexdigest()) def file(): src=input() f = open(src, &#x27;r&#x27;) f_md5 = hashlib.md5() f_md5.update(f.read().encode(&#x27;utf-8&#x27;)) print (f_md5.hexdigest()) if __name__==&#x27;__main__&#x27;: try: while True: MD5.filebin() except EOFError: exit()","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"密码学","slug":"python/密码学","permalink":"https://mhuig.github.io/categories/python/%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"密码学","slug":"密码学","permalink":"https://mhuig.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"加解密","slug":"加解密","permalink":"https://mhuig.github.io/tags/%E5%8A%A0%E8%A7%A3%E5%AF%86/"}]},{"title":"Python Base","slug":"Python/Python Base","date":"2018-12-01T02:12:17.000Z","updated":"2018-12-01T02:12:17.000Z","comments":true,"path":"posts/7827182c.html","link":"","permalink":"https://mhuig.github.io/posts/7827182c.html","excerpt":"Python Base","text":"Python Base Base.py 12345678910111213141516171819202122232425262728293031import base64def base64codes(): s = input() b64encode = base64.b64encode(s.encode(encoding=&#x27;utf-8&#x27;)) b32encode = base64.b32encode(s.encode(encoding=&#x27;utf-8&#x27;)) b16encode = base64.b16encode(s.encode(encoding=&#x27;utf-8&#x27;)) print(b64encode.decode(encoding=&#x27;utf-8&#x27;)) print(b32encode.decode(encoding=&#x27;utf-8&#x27;)) print(b16encode.decode(encoding=&#x27;utf-8&#x27;)) print(&#x27;---------------------------------&#x27;) try: b64decode = base64.b64decode(s.encode(encoding=&#x27;utf-8&#x27;)) print(b64decode.decode(encoding=&#x27;utf-8&#x27;)) except Exception as e: print(&quot;&quot;,end=&quot;&quot;) try: b32decode = base64.b32decode(s.encode(encoding=&#x27;utf-8&#x27;)) print(b32decode.decode(encoding=&#x27;utf-8&#x27;)) except Exception as e: print(&quot;&quot;,end=&quot;&quot;) try: b16decode = base64.b16decode(s.encode(encoding=&#x27;utf-8&#x27;)) print(b16decode.decode(encoding=&#x27;utf-8&#x27;)) except Exception as e: print(&quot;&quot;,end=&quot;&quot;)if __name__ == &#x27;__main__&#x27;: try: while True: base64codes() except EOFError: exit()","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"密码学","slug":"python/密码学","permalink":"https://mhuig.github.io/categories/python/%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"密码学","slug":"密码学","permalink":"https://mhuig.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"加解密","slug":"加解密","permalink":"https://mhuig.github.io/tags/%E5%8A%A0%E8%A7%A3%E5%AF%86/"}]},{"title":"Python Baconian","slug":"Python/Python Baconian","date":"2018-12-01T02:10:13.000Z","updated":"2018-12-01T02:10:13.000Z","comments":true,"path":"posts/5efb0a25.html","link":"","permalink":"https://mhuig.github.io/posts/5efb0a25.html","excerpt":"Python Baconian","text":"Python Baconian Baconian.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# coding:utf8import realphabet = [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;,&#x27;e&#x27;,&#x27;f&#x27;,&#x27;g&#x27;,&#x27;h&#x27;,&#x27;i&#x27;,&#x27;j&#x27;,&#x27;k&#x27;,&#x27;l&#x27;,&#x27;m&#x27;,&#x27;n&#x27;,&#x27;o&#x27;,&#x27;p&#x27;,&#x27;q&#x27;,&#x27;r&#x27;,&#x27;s&#x27;,&#x27;t&#x27;,&#x27;u&#x27;,&#x27;v&#x27;,&#x27;w&#x27;,&#x27;x&#x27;,&#x27;y&#x27;,&#x27;z&#x27;]first_cipher = [&quot;aaaaa&quot;,&quot;aaaab&quot;,&quot;aaaba&quot;,&quot;aaabb&quot;,&quot;aabaa&quot;,&quot;aabab&quot;,&quot;aabba&quot;,&quot;aabbb&quot;,&quot;abaaa&quot;,&quot;abaab&quot;,&quot;ababa&quot;,&quot;ababb&quot;,&quot;abbaa&quot;,&quot;abbab&quot;,&quot;abbba&quot;,&quot;abbbb&quot;,&quot;baaaa&quot;,&quot;baaab&quot;,&quot;baaba&quot;,&quot;baabb&quot;,&quot;babaa&quot;,&quot;babab&quot;,&quot;babba&quot;,&quot;babbb&quot;,&quot;bbaaa&quot;,&quot;bbaab&quot;]second_cipher = [&quot;aaaaa&quot;,&quot;aaaab&quot;,&quot;aaaba&quot;,&quot;aaabb&quot;,&quot;aabaa&quot;,&quot;aabab&quot;,&quot;aabba&quot;,&quot;aabbb&quot;,&quot;abaaa&quot;,&quot;abaaa&quot;,&quot;abaab&quot;,&quot;ababa&quot;,&quot;ababb&quot;,&quot;abbaa&quot;,&quot;abbab&quot;,&quot;abbba&quot;,&quot;abbbb&quot;,&quot;baaaa&quot;,&quot;baaab&quot;,&quot;baaba&quot;,&quot;baabb&quot;,&quot;baabb&quot;,&quot;babaa&quot;,&quot;babab&quot;,&quot;babba&quot;,&quot;babbb&quot;]def encode(): upper_flag = False # 用于判断输入是否为大写 string = input(&quot;please input string to encode:\\n&quot;) if string.isupper(): upper_flag = True string = string.lower() e_string1 = &quot;&quot; e_string2 = &quot;&quot; for index in string: for i in range(0,26): if index == alphabet[i]: e_string1 += first_cipher[i] e_string2 += second_cipher[i] break if upper_flag: e_string1 = e_string1.upper() e_string2 = e_string2.upper() print (&quot;first encode method result is:\\n&quot;+e_string1) print (&quot;second encode method result is:\\n&quot;+e_string2) returndef decode(): upper_flag = False # 用于判断输入是否为大写 e_string = input(&quot;please input string to decode:\\n&quot;) if e_string.isupper(): upper_flag = True e_string = e_string.lower() e_array = re.findall(&quot;.&#123;5&#125;&quot;,e_string) d_string1 = &quot;&quot; d_string2 = &quot;&quot; for index in e_array: for i in range(0,26): if index == first_cipher[i]: d_string1 += alphabet[i] if index == second_cipher[i]: d_string2 += alphabet[i] if upper_flag: d_string1 = d_string1.upper() d_string2 = d_string2.upper() print (&quot;first decode method result is:\\n&quot;+d_string1) print (&quot;second decode method result is:\\n&quot;+d_string2) returnif __name__ == &#x27;__main__&#x27;: while True: print (&quot;\\t*******Bacon Encode_Decode System*******&quot;) print (&quot;input should be only lowercase or uppercase,cipher just include a,b(or A,B)&quot;) print (&quot;1.encode\\n2.decode\\n3.exit&quot;) s_number = input(&quot;please input number to choose\\n&quot;) if s_number == &quot;1&quot;: encode() input() elif s_number == &quot;2&quot;: decode() input() elif s_number == &quot;3&quot;: break else: continue decode .py 1234567891011121314151617181920212223242526272829303132333435# -*- coding: utf-8 -*-import reclass Baconian(): alphabet = [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;, &#x27;g&#x27;, &#x27;h&#x27;, &#x27;i&#x27;, &#x27;j&#x27;, &#x27;k&#x27;, &#x27;l&#x27;, &#x27;m&#x27;, &#x27;n&#x27;, &#x27;o&#x27;, &#x27;p&#x27;, &#x27;q&#x27;, &#x27;r&#x27;, &#x27;s&#x27;, &#x27;t&#x27;, &#x27;u&#x27;, &#x27;v&#x27;, &#x27;w&#x27;, &#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;] first_cipher = [&quot;aaaaa&quot;, &quot;aaaab&quot;, &quot;aaaba&quot;, &quot;aaabb&quot;, &quot;aabaa&quot;, &quot;aabab&quot;, &quot;aabba&quot;, &quot;aabbb&quot;, &quot;abaaa&quot;, &quot;abaab&quot;, &quot;ababa&quot;, &quot;ababb&quot;, &quot;abbaa&quot;, &quot;abbab&quot;, &quot;abbba&quot;, &quot;abbbb&quot;, &quot;baaaa&quot;, &quot;baaab&quot;, &quot;baaba&quot;, &quot;baabb&quot;, &quot;babaa&quot;, &quot;babab&quot;, &quot;babba&quot;, &quot;babbb&quot;, &quot;bbaaa&quot;, &quot;bbaab&quot;] second_cipher = [&quot;aaaaa&quot;, &quot;aaaab&quot;, &quot;aaaba&quot;, &quot;aaabb&quot;, &quot;aabaa&quot;, &quot;aabab&quot;, &quot;aabba&quot;, &quot;aabbb&quot;, &quot;abaaa&quot;, &quot;abaaa&quot;, &quot;abaab&quot;, &quot;ababa&quot;, &quot;ababb&quot;, &quot;abbaa&quot;, &quot;abbab&quot;, &quot;abbba&quot;, &quot;abbbb&quot;, &quot;baaaa&quot;, &quot;baaab&quot;, &quot;baaba&quot;, &quot;baabb&quot;, &quot;baabb&quot;, &quot;babaa&quot;, &quot;babab&quot;, &quot;babba&quot;, &quot;babbb&quot;] def __init__(self, str): self.str = str def decode(self): str = self.str.lower() str_array = re.findall(&quot;.&#123;5&#125;&quot;, str) decode_str1 = &quot;&quot; decode_str2 = &quot;&quot; for key in str_array: for i in range(0,26): if key == Baconian.first_cipher[i]: decode_str1 += Baconian.alphabet[i] if key == Baconian.second_cipher[i]: decode_str2 += Baconian.alphabet[i] print(decode_str1) print(decode_str2)if __name__ == &#x27;__main__&#x27;: str = input() bacon = Baconian(str) bacon.decode()","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"密码学","slug":"python/密码学","permalink":"https://mhuig.github.io/categories/python/%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"密码学","slug":"密码学","permalink":"https://mhuig.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"加解密","slug":"加解密","permalink":"https://mhuig.github.io/tags/%E5%8A%A0%E8%A7%A3%E5%AF%86/"}]},{"title":"Python ASCII 字符串 转换","slug":"Python/Python ASCII 字符串 转换","date":"2018-11-30T07:59:17.000Z","updated":"2018-11-30T07:59:17.000Z","comments":true,"path":"posts/2ffb45fa.html","link":"","permalink":"https://mhuig.github.io/posts/2ffb45fa.html","excerpt":"Python ASCII 字符串 转换","text":"Python ASCII 字符串 转换 ASCII转字符.py 1234567891011121314151617def ASCIItostr(): try: s = input() s=s.split() for i in s: print(chr(int(i)),end=&quot;&quot;) print() except Exception as e: print(&quot;&quot;,end=&quot;&quot;)if __name__ == &#x27;__main__&#x27;: try: while True: ASCIItostr() except EOFError: exit() 字符转ASCII.py 1234567891011121314151617def strtoASCII(): try: s = input() for i in s: print(ord(str(i)),end=&quot; &quot;) print() except Exception as e: print(&quot;&quot;,end=&quot;&quot;)if __name__ == &#x27;__main__&#x27;: try: while True: strtoASCII() except EOFError: exit()","categories":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"密码学","slug":"python/密码学","permalink":"https://mhuig.github.io/categories/python/%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"tags":[{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"密码学","slug":"密码学","permalink":"https://mhuig.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"加解密","slug":"加解密","permalink":"https://mhuig.github.io/tags/%E5%8A%A0%E8%A7%A3%E5%AF%86/"}]}],"categories":[{"name":"spark","slug":"spark","permalink":"https://mhuig.github.io/categories/spark/"},{"name":"Spark","slug":"spark","permalink":"https://mhuig.github.io/categories/spark/"},{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/categories/linux/"},{"name":"Ubuntu","slug":"linux/ubuntu","permalink":"https://mhuig.github.io/categories/linux/ubuntu/"},{"name":"笔录","slug":"笔录","permalink":"https://mhuig.github.io/categories/%E7%AC%94%E5%BD%95/"},{"name":"实验性","slug":"实验性","permalink":"https://mhuig.github.io/categories/%E5%AE%9E%E9%AA%8C%E6%80%A7/"},{"name":"BigData","slug":"bigdata","permalink":"https://mhuig.github.io/categories/bigdata/"},{"name":"Time","slug":"time","permalink":"https://mhuig.github.io/categories/time/"},{"name":"Hello","slug":"hello","permalink":"https://mhuig.github.io/categories/hello/"},{"name":"Math","slug":"math","permalink":"https://mhuig.github.io/categories/math/"},{"name":"概率","slug":"math/概率","permalink":"https://mhuig.github.io/categories/math/%E6%A6%82%E7%8E%87/"},{"name":"JavaScript","slug":"javascript","permalink":"https://mhuig.github.io/categories/javascript/"},{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/categories/python/"},{"name":"npm","slug":"npm","permalink":"https://mhuig.github.io/categories/npm/"},{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"NoSQL","slug":"大数据/nosql","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/nosql/"},{"name":"解释器","slug":"python/解释器","permalink":"https://mhuig.github.io/categories/python/%E8%A7%A3%E9%87%8A%E5%99%A8/"},{"name":"windows","slug":"windows","permalink":"https://mhuig.github.io/categories/windows/"},{"name":"gcc","slug":"windows/gcc","permalink":"https://mhuig.github.io/categories/windows/gcc/"},{"name":"密码学","slug":"python/密码学","permalink":"https://mhuig.github.io/categories/python/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"模板","slug":"模板","permalink":"https://mhuig.github.io/categories/%E6%A8%A1%E6%9D%BF/"},{"name":"maven","slug":"模板/maven","permalink":"https://mhuig.github.io/categories/%E6%A8%A1%E6%9D%BF/maven/"},{"name":"Flink","slug":"大数据/flink","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"},{"name":"错误集锦","slug":"错误集锦","permalink":"https://mhuig.github.io/categories/%E9%94%99%E8%AF%AF%E9%9B%86%E9%94%A6/"},{"name":"CentOS7","slug":"错误集锦/centos7","permalink":"https://mhuig.github.io/categories/%E9%94%99%E8%AF%AF%E9%9B%86%E9%94%A6/centos7/"},{"name":"netcat","slug":"windows/netcat","permalink":"https://mhuig.github.io/categories/windows/netcat/"},{"name":"kali","slug":"linux/kali","permalink":"https://mhuig.github.io/categories/linux/kali/"},{"name":"线性代数","slug":"math/线性代数","permalink":"https://mhuig.github.io/categories/math/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"},{"name":"机器学习","slug":"机器学习","permalink":"https://mhuig.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"机器视觉","slug":"机器学习/机器视觉","permalink":"https://mhuig.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"},{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/categories/web/"},{"name":"Nginx","slug":"web/nginx","permalink":"https://mhuig.github.io/categories/web/nginx/"},{"name":"LaTeX","slug":"math/latex","permalink":"https://mhuig.github.io/categories/math/latex/"},{"name":"Django","slug":"web/django","permalink":"https://mhuig.github.io/categories/web/django/"},{"name":"内网穿透","slug":"web/内网穿透","permalink":"https://mhuig.github.io/categories/web/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"CentOS7","slug":"linux/centos7","permalink":"https://mhuig.github.io/categories/linux/centos7/"},{"name":"Python","slug":"linux/centos7/python","permalink":"https://mhuig.github.io/categories/linux/centos7/python/"},{"name":"大数据处理技术","slug":"大数据/大数据处理技术","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Echarts","slug":"大数据/大数据处理技术/echarts","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/echarts/"},{"name":"Azkaban","slug":"大数据/大数据处理技术/azkaban","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/azkaban/"},{"name":"Sqoop","slug":"大数据/大数据处理技术/sqoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/sqoop/"},{"name":"Kafka","slug":"大数据/大数据处理技术/kafka","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/kafka/"},{"name":"Flume","slug":"大数据/大数据处理技术/flume","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/flume/"},{"name":"Yarn","slug":"大数据/大数据处理技术/yarn","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/yarn/"},{"name":"Hive","slug":"大数据/大数据处理技术/hive","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hive/"},{"name":"MapReduce","slug":"大数据/大数据处理技术/mapreduce","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/mapreduce/"},{"name":"HDFS","slug":"大数据/大数据处理技术/hdfs","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hdfs/"},{"name":"Hadoop","slug":"大数据/大数据处理技术/hadoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/hadoop/"},{"name":"Zookeeper","slug":"大数据/大数据处理技术/zookeeper","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/zookeeper/"},{"name":"大数据集群环境准备","slug":"大数据/大数据处理技术/大数据集群环境准备","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"},{"name":"Hadoop","slug":"大数据/hadoop","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/"},{"name":"数学建模","slug":"math/数学建模","permalink":"https://mhuig.github.io/categories/math/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"},{"name":"数据挖掘","slug":"大数据/数据挖掘","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"},{"name":"数据可视化","slug":"大数据/数据可视化","permalink":"https://mhuig.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"会议报告","slug":"会议报告","permalink":"https://mhuig.github.io/categories/%E4%BC%9A%E8%AE%AE%E6%8A%A5%E5%91%8A/"},{"name":"shell","slug":"linux/shell","permalink":"https://mhuig.github.io/categories/linux/shell/"},{"name":"hexo","slug":"web/hexo","permalink":"https://mhuig.github.io/categories/web/hexo/"},{"name":"51","slug":"51","permalink":"https://mhuig.github.io/categories/51/"},{"name":"反编译","slug":"python/反编译","permalink":"https://mhuig.github.io/categories/python/%E5%8F%8D%E7%BC%96%E8%AF%91/"}],"tags":[{"name":"spark","slug":"spark","permalink":"https://mhuig.github.io/tags/spark/"},{"name":"Spark","slug":"spark","permalink":"https://mhuig.github.io/tags/spark/"},{"name":"Linux","slug":"linux","permalink":"https://mhuig.github.io/tags/linux/"},{"name":"Ubuntu","slug":"ubuntu","permalink":"https://mhuig.github.io/tags/ubuntu/"},{"name":"笔录","slug":"笔录","permalink":"https://mhuig.github.io/tags/%E7%AC%94%E5%BD%95/"},{"name":"实验性","slug":"实验性","permalink":"https://mhuig.github.io/tags/%E5%AE%9E%E9%AA%8C%E6%80%A7/"},{"name":"BigData","slug":"bigdata","permalink":"https://mhuig.github.io/tags/bigdata/"},{"name":"Time","slug":"time","permalink":"https://mhuig.github.io/tags/time/"},{"name":"Hello","slug":"hello","permalink":"https://mhuig.github.io/tags/hello/"},{"name":"Math","slug":"math","permalink":"https://mhuig.github.io/tags/math/"},{"name":"概率","slug":"概率","permalink":"https://mhuig.github.io/tags/%E6%A6%82%E7%8E%87/"},{"name":"神经网络","slug":"神经网络","permalink":"https://mhuig.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"JavaScript","slug":"javascript","permalink":"https://mhuig.github.io/tags/javascript/"},{"name":"反调试","slug":"反调试","permalink":"https://mhuig.github.io/tags/%E5%8F%8D%E8%B0%83%E8%AF%95/"},{"name":"Python","slug":"python","permalink":"https://mhuig.github.io/tags/python/"},{"name":"npm","slug":"npm","permalink":"https://mhuig.github.io/tags/npm/"},{"name":"距离","slug":"距离","permalink":"https://mhuig.github.io/tags/%E8%B7%9D%E7%A6%BB/"},{"name":"大数据","slug":"大数据","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PDF","slug":"pdf","permalink":"https://mhuig.github.io/tags/pdf/"},{"name":"NoSQL","slug":"nosql","permalink":"https://mhuig.github.io/tags/nosql/"},{"name":"Neo4j","slug":"neo4j","permalink":"https://mhuig.github.io/tags/neo4j/"},{"name":"MongoDB","slug":"mongodb","permalink":"https://mhuig.github.io/tags/mongodb/"},{"name":"HBase","slug":"hbase","permalink":"https://mhuig.github.io/tags/hbase/"},{"name":"Cassandra","slug":"cassandra","permalink":"https://mhuig.github.io/tags/cassandra/"},{"name":"加解密","slug":"加解密","permalink":"https://mhuig.github.io/tags/%E5%8A%A0%E8%A7%A3%E5%AF%86/"},{"name":"解释器","slug":"解释器","permalink":"https://mhuig.github.io/tags/%E8%A7%A3%E9%87%8A%E5%99%A8/"},{"name":"源码保护","slug":"源码保护","permalink":"https://mhuig.github.io/tags/%E6%BA%90%E7%A0%81%E4%BF%9D%E6%8A%A4/"},{"name":"windows","slug":"windows","permalink":"https://mhuig.github.io/tags/windows/"},{"name":"gcc","slug":"gcc","permalink":"https://mhuig.github.io/tags/gcc/"},{"name":"AES","slug":"aes","permalink":"https://mhuig.github.io/tags/aes/"},{"name":"密码学","slug":"密码学","permalink":"https://mhuig.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"maven","slug":"maven","permalink":"https://mhuig.github.io/tags/maven/"},{"name":"模板","slug":"模板","permalink":"https://mhuig.github.io/tags/%E6%A8%A1%E6%9D%BF/"},{"name":"WebSocket","slug":"websocket","permalink":"https://mhuig.github.io/tags/websocket/"},{"name":"SSM","slug":"ssm","permalink":"https://mhuig.github.io/tags/ssm/"},{"name":"Flink","slug":"flink","permalink":"https://mhuig.github.io/tags/flink/"},{"name":"CentOS7","slug":"centos7","permalink":"https://mhuig.github.io/tags/centos7/"},{"name":"network","slug":"network","permalink":"https://mhuig.github.io/tags/network/"},{"name":"netcat","slug":"netcat","permalink":"https://mhuig.github.io/tags/netcat/"},{"name":"删除注释","slug":"删除注释","permalink":"https://mhuig.github.io/tags/%E5%88%A0%E9%99%A4%E6%B3%A8%E9%87%8A/"},{"name":"kali","slug":"kali","permalink":"https://mhuig.github.io/tags/kali/"},{"name":"线性代数","slug":"线性代数","permalink":"https://mhuig.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"},{"name":"特征向量","slug":"特征向量","permalink":"https://mhuig.github.io/tags/%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/"},{"name":"xrdp","slug":"xrdp","permalink":"https://mhuig.github.io/tags/xrdp/"},{"name":"虚拟内存","slug":"虚拟内存","permalink":"https://mhuig.github.io/tags/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/"},{"name":"视知觉","slug":"视知觉","permalink":"https://mhuig.github.io/tags/%E8%A7%86%E7%9F%A5%E8%A7%89/"},{"name":"操作系统","slug":"操作系统","permalink":"https://mhuig.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"死锁","slug":"死锁","permalink":"https://mhuig.github.io/tags/%E6%AD%BB%E9%94%81/"},{"name":"Github","slug":"github","permalink":"https://mhuig.github.io/tags/github/"},{"name":"进程调度","slug":"进程调度","permalink":"https://mhuig.github.io/tags/%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6/"},{"name":"进程同步","slug":"进程同步","permalink":"https://mhuig.github.io/tags/%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5/"},{"name":"Nginx","slug":"nginx","permalink":"https://mhuig.github.io/tags/nginx/"},{"name":"https","slug":"https","permalink":"https://mhuig.github.io/tags/https/"},{"name":"Web安全","slug":"web安全","permalink":"https://mhuig.github.io/tags/web%E5%AE%89%E5%85%A8/"},{"name":"LaTeX","slug":"latex","permalink":"https://mhuig.github.io/tags/latex/"},{"name":"Django","slug":"django","permalink":"https://mhuig.github.io/tags/django/"},{"name":"mysql","slug":"mysql","permalink":"https://mhuig.github.io/tags/mysql/"},{"name":"内网穿透","slug":"内网穿透","permalink":"https://mhuig.github.io/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"Frp","slug":"frp","permalink":"https://mhuig.github.io/tags/frp/"},{"name":"Jupyter","slug":"jupyter","permalink":"https://mhuig.github.io/tags/jupyter/"},{"name":"Anaconda","slug":"anaconda","permalink":"https://mhuig.github.io/tags/anaconda/"},{"name":"php","slug":"php","permalink":"https://mhuig.github.io/tags/php/"},{"name":"cloud","slug":"cloud","permalink":"https://mhuig.github.io/tags/cloud/"},{"name":"Web","slug":"web","permalink":"https://mhuig.github.io/tags/web/"},{"name":"大数据处理技术","slug":"大数据处理技术","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF/"},{"name":"Echarts","slug":"echarts","permalink":"https://mhuig.github.io/tags/echarts/"},{"name":"Azkaban","slug":"azkaban","permalink":"https://mhuig.github.io/tags/azkaban/"},{"name":"Sqoop","slug":"sqoop","permalink":"https://mhuig.github.io/tags/sqoop/"},{"name":"Kafka","slug":"kafka","permalink":"https://mhuig.github.io/tags/kafka/"},{"name":"Flume","slug":"flume","permalink":"https://mhuig.github.io/tags/flume/"},{"name":"Yarn","slug":"yarn","permalink":"https://mhuig.github.io/tags/yarn/"},{"name":"Hive","slug":"hive","permalink":"https://mhuig.github.io/tags/hive/"},{"name":"MapReduce","slug":"mapreduce","permalink":"https://mhuig.github.io/tags/mapreduce/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://mhuig.github.io/tags/hadoop/"},{"name":"HDFS","slug":"hdfs","permalink":"https://mhuig.github.io/tags/hdfs/"},{"name":"JavaAPI","slug":"javaapi","permalink":"https://mhuig.github.io/tags/javaapi/"},{"name":"历史","slug":"历史","permalink":"https://mhuig.github.io/tags/%E5%8E%86%E5%8F%B2/"},{"name":"Zookeeper","slug":"zookeeper","permalink":"https://mhuig.github.io/tags/zookeeper/"},{"name":"大数据集群环境准备","slug":"大数据集群环境准备","permalink":"https://mhuig.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"},{"name":"数学建模","slug":"数学建模","permalink":"https://mhuig.github.io/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://mhuig.github.io/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"},{"name":"数据可视化","slug":"数据可视化","permalink":"https://mhuig.github.io/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"机器学习","slug":"机器学习","permalink":"https://mhuig.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"机器视觉","slug":"机器视觉","permalink":"https://mhuig.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"},{"name":"分类器","slug":"分类器","permalink":"https://mhuig.github.io/tags/%E5%88%86%E7%B1%BB%E5%99%A8/"},{"name":"特征","slug":"特征","permalink":"https://mhuig.github.io/tags/%E7%89%B9%E5%BE%81/"},{"name":"图像","slug":"图像","permalink":"https://mhuig.github.io/tags/%E5%9B%BE%E5%83%8F/"},{"name":"数学模型","slug":"数学模型","permalink":"https://mhuig.github.io/tags/%E6%95%B0%E5%AD%A6%E6%A8%A1%E5%9E%8B/"},{"name":"进程","slug":"进程","permalink":"https://mhuig.github.io/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"前驱图","slug":"前驱图","permalink":"https://mhuig.github.io/tags/%E5%89%8D%E9%A9%B1%E5%9B%BE/"},{"name":"人工智能","slug":"人工智能","permalink":"https://mhuig.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"脑科学","slug":"脑科学","permalink":"https://mhuig.github.io/tags/%E8%84%91%E7%A7%91%E5%AD%A6/"},{"name":"shell","slug":"shell","permalink":"https://mhuig.github.io/tags/shell/"},{"name":"通配符","slug":"通配符","permalink":"https://mhuig.github.io/tags/%E9%80%9A%E9%85%8D%E7%AC%A6/"},{"name":"glob表达式","slug":"glob表达式","permalink":"https://mhuig.github.io/tags/glob%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"hexo","slug":"hexo","permalink":"https://mhuig.github.io/tags/hexo/"},{"name":"Markdown","slug":"markdown","permalink":"https://mhuig.github.io/tags/markdown/"},{"name":"51","slug":"51","permalink":"https://mhuig.github.io/tags/51/"},{"name":"温湿度","slug":"温湿度","permalink":"https://mhuig.github.io/tags/%E6%B8%A9%E6%B9%BF%E5%BA%A6/"},{"name":"超声波","slug":"超声波","permalink":"https://mhuig.github.io/tags/%E8%B6%85%E5%A3%B0%E6%B3%A2/"},{"name":"按键时钟","slug":"按键时钟","permalink":"https://mhuig.github.io/tags/%E6%8C%89%E9%94%AE%E6%97%B6%E9%92%9F/"},{"name":"秒表","slug":"秒表","permalink":"https://mhuig.github.io/tags/%E7%A7%92%E8%A1%A8/"},{"name":"反编译","slug":"反编译","permalink":"https://mhuig.github.io/tags/%E5%8F%8D%E7%BC%96%E8%AF%91/"}]}