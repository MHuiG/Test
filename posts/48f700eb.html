<!DOCTYPE html><html lang="zh-CN"><head hexo-theme="https://github.com/volantis-x/hexo-theme-volantis/tree/PiKaPiKa"><meta charset="utf-8"><meta name="robots" content="noindex,nofollow"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="preconnect" href="https://api.i-meto.com" crossorigin><link rel="preconnect" href="https://p3.music.126.net" crossorigin><link rel="preconnect" href="https://m7.music.126.net" crossorigin><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="HandheldFriendly" content="True"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><link rel="preload" href="/css/style.css" as="style"><link rel="preload" href="/js/jquery.js" as="script"><link rel="preload" href="https://cdn.jsdelivr.net/npm/mhg@0.0.0/font/VarelaRound-Regular.ttf" as="font" type="font/ttf" crossorigin><link rel="preload" href="https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin><link rel="preload" href="https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin><link rel="preload" href="https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-duotone-900.woff2" as="font" type="font/woff2" crossorigin><title>BERT预训练模型及其应用案例 - MHuiG</title><meta name="keywords" content="NLP"><meta name="description" content="预训练模型最开始是在图像领域提出的，获得了良好的效果，近几年才被广泛应用到自然语言处理各项任务中。

(1)2003年Bengio提出神经网络语言模型NNLM，从此统一了NLP的特征形式——Embedding；

(2)2013年Mikolov提出词向量Word2vec，延续NNLM又引入了大规模预训练（Pret..."><link rel="alternate" href="/atom.xml" title="MHuiG" type="application/atom+xml"><meta name="theme-color" content="skyblue"><link rel="shortcut icon" type="image/x-icon" sizes="16x16 32x32 48x48 64x64" href="https://cdn.jsdelivr.net/npm/mhg@0.0.0/favicon/favicon.ico"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="https://cdn.jsdelivr.net/npm/mhg@0.0.0/favicon/favicon_180.png"><link rel="mask-icon" color="#1BC3FB" href="https://cdn.jsdelivr.net/npm/mhg@0.0.0/favicon/favicon_180.png"><style>#safearea{display:none}@font-face{font-family:'Varela Round';src:url(https://cdn.jsdelivr.net/npm/mhg@0.0.0/font/VarelaRound-Regular.ttf);font-weight:400;font-style:normal;font-display:swap}@font-face{font-family:Cascadia;src:url(https://cdn.jsdelivr.net/npm/mhg@0.0.0/font/Cascadia.ttf);font-weight:400;font-style:normal;font-display:swap}@font-face{font-family:'Font Awesome 5 Pro';font-style:normal;font-weight:900;font-display:block;src:url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-solid-900.eot);src:url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-solid-900.eot?#iefix) format("embedded-opentype"),url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-solid-900.woff2) format("woff2"),url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-solid-900.woff) format("woff"),url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-solid-900.ttf) format("truetype"),url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-solid-900.svg#fontawesome) format("svg")}@font-face{font-family:'Font Awesome 5 Brands';font-style:normal;font-weight:400;font-display:block;src:url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-brands-400.eot);src:url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-brands-400.eot?#iefix) format("embedded-opentype"),url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-brands-400.woff2) format("woff2"),url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-brands-400.woff) format("woff"),url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-brands-400.ttf) format("truetype"),url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-brands-400.svg#fontawesome) format("svg")}@font-face{font-family:'Font Awesome 5 Duotone';font-style:normal;font-weight:900;font-display:block;src:url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-duotone-900.eot);src:url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-duotone-900.eot?#iefix) format("embedded-opentype"),url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-duotone-900.woff2) format("woff2"),url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-duotone-900.woff) format("woff"),url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-duotone-900.ttf) format("truetype"),url(https://cdn.jsdelivr.net/npm/mhg@0.0.1/fa5/webfonts/fa-duotone-900.svg#fontawesome) format("svg")}@media (prefers-color-scheme:dark){:root{--color-mode:'dark'}:root:not([data-user-color-scheme]){--color-site-body:black;--color-site-bg:#21232f;--color-site-inner:#efefef;--color-site-footer:#666;--color-card:#252d38;--color-text:#fff;--color-block:rgba(68,68,68,0.65);--color-codeblock:rgba(33,150,243,0.2);--color-inlinecode:#d56d28;--color-h1:#eee;--color-h2:#eee;--color-h3:#ddd;--color-h4:#ddd;--color-h5:#ddd;--color-h6:#ddd;--color-p:#bbb;--color-list:#aaa;--color-list-hl:#4dabf5;--color-meta:#888;--color-link:#888}:root:not([data-user-color-scheme]) #l_body{background-color:#000!important}:root:not([data-user-color-scheme]) .lazyload{filter:brightness(70%)!important}:root:not([data-user-color-scheme]) #wrapper .title{color:var(--color-meta)}:root:not([data-user-color-scheme]) .l_header ul.nav-list-h>li>a,:root:not([data-user-color-scheme]) ul.list-v>li>a{color:var(--color-list)}:root:not([data-user-color-scheme]) .blur{background:var(--color-site-bg)!important}:root:not([data-user-color-scheme]) .nav-main .u-search-input{background:var(--color-card)!important}}@supports (backdrop-filter:blur(20px)){.blur{background:rgba(255,255,255,.9)!important;backdrop-filter:saturate(200%) blur(20px)}}.shadow{box-shadow:0 1px 2px 0 rgba(0,0,0,.1)}.shadow.floatable{transition:all .28s ease;-moz-transition:all .28s ease;-webkit-transition:all .28s ease;-o-transition:all .28s ease}:root{--color-site-body:#87ceeb;--color-site-bg:#87ceeb;--color-site-inner:#555;--color-site-footer:#666;--color-card:#fff;--color-text:#444;--color-block:#f6f6f6;--color-inlinecode:#d56d28;--color-codeblock:#fff7ea;--color-h1:#444;--color-h2:#444;--color-h3:#444;--color-h4:#444;--color-h5:#444;--color-h6:#444;--color-p:#444;--color-list:#666;--color-list-hl:#1a78c2;--color-meta:#888}*{box-sizing:border-box;outline:0;margin:0;padding:0}html{color:var(--color-text);width:100%;height:100%;font-family:"Varela Round","PingFang SC","Microsoft YaHei",Helvetica,Arial,Menlo,Monaco,monospace,sans-serif;font-size:16px}html>::-webkit-scrollbar{height:4px;width:4px}html>::-webkit-scrollbar-track-piece{background:0 0}html>::-webkit-scrollbar-thumb{background:#2196f3;cursor:pointer;border-radius:2px}body{background-color:var(--color-site-body);text-rendering:optimizelegibility;-webkit-tap-highlight-color:transparent;line-height:1.6;-webkit-text-size-adjust:100%;-ms-text-size-adjust:100%}a{color:#2196f3;cursor:pointer;text-decoration:none;transition:all .28s ease;-moz-transition:all .28s ease;-webkit-transition:all .28s ease;-o-transition:all .28s ease}a:not([href]){cursor:default}ol,ul{padding-left:0}ol li,ul li{list-style:none}article,aside,details,figcaption,figure,footer,header,hgroup,main,menu,nav,section,summary{display:block}button,input,optgroup,select,textarea{color:inherit;font:inherit;margin:0}.fa,.fab,.fad,.fal,.far,.fas{-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;display:inline-block;font-style:normal;font-variant:normal;text-rendering:auto;line-height:1}.fa-fw{text-align:center;width:1.25em}.fa-spin{-webkit-animation:fa-spin 2s infinite linear;animation:fa-spin 2s infinite linear}.fab{font-family:'Font Awesome 5 Brands';font-weight:400}.fad{position:relative;font-family:'Font Awesome 5 Duotone';font-weight:900}.fad:before{position:absolute;color:var(--fa-primary-color,inherit);opacity:1;opacity:var(--fa-primary-opacity,1)}.fad:after{color:var(--fa-secondary-color,inherit);opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.fad.fa-fw:before,.fad.fa-stack-1x:before,.fad.fa-stack-2x:before{left:50%;-webkit-transform:translateX(-50%);transform:translateX(-50%)}.fa,.fas{font-family:'Font Awesome 5 Pro';font-weight:900}.fa-list-alt:before{content:"\f022"}.fa-link:before{content:"\f0c1"}.fa-paper-plane:before{content:"\f1d8"}.fa-fan:before{content:"\f863"}.fa-comments:before{content:"\f086"}.fa-github:before{content:"\f09b"}.fa-search:before{content:"\f002"}.fa-user-tie:before{content:"\f508"}.fa-chevron-down:before{content:"\f078"}.fa-user-tie:before{content:"\f508"}.fad.fa-list-alt:after{content:"\10f022"}.fad.fa-link:after{content:"\10f0c1"}.fad.fa-paper-plane:after{content:"\10f1d8"}.fad.fa-fan:after{content:"\10f863"}.fad.fa-comments:after{content:"\10f086"}.fad.fa-search:after{content:"\10f002"}.fad.fa-user-tie:after{content:"\10f508"}#l_cover{min-height:64px}.cover-wrapper{top:0;left:0;max-width:100%;height:100vh;display:flex;flex-wrap:nowrap;flex-direction:column;align-items:center;align-self:center;align-content:center;color:var(--color-site-inner);padding:0 16px;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none;user-select:none;position:relative;overflow:hidden;margin-bottom:-100px}.cover-wrapper #cover-backstretch,.cover-wrapper .cover-bg{position:absolute;width:100%;height:100%;background-position:center;background-size:cover}.cover-wrapper #cover-backstretch.lazyload:not(.loaded),.cover-wrapper .cover-bg.lazyload:not(.loaded){opacity:0}.cover-wrapper .cover-body{z-index:1;position:relative;width:100%;height:100%}.cover-wrapper#full{height:calc(100vh + 100px);padding-bottom:100px}.cover-wrapper #scroll-down{width:100%;height:64px;position:absolute;bottom:100px;text-align:center;cursor:pointer}.cover-wrapper #scroll-down .scroll-down-effects{color:#fff;font-size:24px;line-height:64px;position:absolute;width:24px;left:calc(50% - 12px);text-shadow:0 1px 2px rgba(0,0,0,.1);animation:scroll-down-effect 1.5s infinite}.cover-wrapper .cover-body{margin-top:64px;margin-bottom:100px}.cover-wrapper .cover-body,.cover-wrapper .cover-body .bottom,.cover-wrapper .cover-body .top{display:flex;flex-direction:column;align-items:center;justify-content:center;max-width:100%}.cover-wrapper .cover-body .bottom{margin-top:32px}.cover-wrapper .cover-body .title{font-family:"Varela Round","PingFang SC","Microsoft YaHei",Helvetica,Arial,Helvetica,monospace;font-size:3.125rem;line-height:1.2;text-shadow:0 1px 2px rgba(0,0,0,.1)}.cover-wrapper .cover-body .subtitle{font-size:.875rem}.cover-wrapper .list-h{display:flex;flex-direction:row;flex-wrap:wrap;align-items:stretch;border-radius:4px;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none;user-select:none}.cover-wrapper .list-h a{flex:1;display:flex;font-weight:600}.cover-wrapper{max-width:100%}.cover-wrapper.dock .menu,.cover-wrapper.featured .menu,.cover-wrapper.focus .menu{border-radius:6px}.cover-wrapper.dock .menu .list-h a,.cover-wrapper.featured .menu .list-h a,.cover-wrapper.focus .menu .list-h a{flex-direction:column;align-items:center;padding:12px;line-height:24px;border-radius:4px;border-bottom:none;text-align:center;align-content:flex-end;color:rgba(68,68,68,.7);font-size:1.5rem}@media screen and (max-width:500px){.cover-wrapper.dock .menu .list-h a,.cover-wrapper.featured .menu .list-h a,.cover-wrapper.focus .menu .list-h a{padding:12px 8px}}.cover-wrapper.dock .menu .list-h a i,.cover-wrapper.featured .menu .list-h a i,.cover-wrapper.focus .menu .list-h a i{margin:8px}.cover-wrapper.dock .menu .list-h a p,.cover-wrapper.featured .menu .list-h a p,.cover-wrapper.focus .menu .list-h a p{font-size:.875rem}.cover-wrapper.featured .menu .list-h{margin:-2px}.cover-wrapper.featured .menu .list-h a{margin:2px;background:rgba(255,255,255,.5)}@supports (backdrop-filter:blur(20px)){.cover-wrapper.featured .menu .list-h a{background:rgba(255,255,255,.5);backdrop-filter:saturate(200%) blur(20px)}}#safearea{margin:16px 16px 0}#l_body{position:relative;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}ul.m-pc>li>a{color:inherit;border-bottom:2px solid transparent}ul.nav-list-h{display:flex;align-items:stretch}ul.nav-list-h>li{position:relative;justify-content:center;height:100%;line-height:2.4;border-radius:4px}ul.nav-list-h>li>a{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;font-weight:600}ul.list-v{z-index:1;display:none;position:absolute;background:var(--color-card);box-shadow:0 2px 4px 0 rgba(0,0,0,.08),0 4px 8px 0 rgba(0,0,0,.08),0 8px 16px 0 rgba(0,0,0,.08);margin-top:-6px;border-radius:4px;padding:8px 0}#wrapper{max-width:1080px;margin:auto}@media screen and (min-width:2048px){#wrapper{max-width:55vw}}#wrapper .menu{flex:1 1 auto;margin:0 16px 0 0}.l_header{position:fixed;z-index:1000;top:0;width:100%;height:64px;background:var(--color-card);box-shadow:0 1px 2px 0 rgba(0,0,0,.1)}.l_header.auto{transition:opacity .4s ease;visibility:hidden}.l_header.auto.show{opacity:1!important;visibility:visible}.l_header .container{margin-left:16px;margin-right:16px}.l_header #wrapper{height:100%;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none;user-select:none}.l_header #wrapper .nav-main,.l_header #wrapper .nav-sub{display:flex;flex-wrap:nowrap;justify-content:space-between;align-items:center}.l_header #wrapper .nav-main{transition:all .28s ease;-moz-transition:all .28s ease;-webkit-transition:all .28s ease;-o-transition:all .28s ease}.l_header #wrapper .nav-sub{transition:all .28s ease;-moz-transition:all .28s ease;-webkit-transition:all .28s ease;-o-transition:all .28s ease;opacity:0;height:64px;width:calc(100% - 2 * 16px);position:absolute}@media screen and (min-width:2048px){.l_header #wrapper .nav-sub{max-width:55vw;margin:auto}}.l_header #wrapper .title{position:relative;color:var(--color-text);padding-left:24px;max-height:64px}.l_header #wrapper .nav-main .title{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;flex-shrink:0;line-height:64px;padding:0 24px;font-size:1.25rem;font-family:"Varela Round","PingFang SC","Microsoft YaHei",Helvetica,Arial,Helvetica,monospace}.l_header .nav-sub{max-width:1080px;margin:auto}.l_header .nav-sub .title{font-weight:700;font-family:"Varela Round","PingFang SC","Microsoft YaHei",Helvetica,Arial,Menlo,Monaco,monospace,sans-serif;line-height:1.2;max-height:64px;white-space:normal;flex-shrink:1}.l_header .switcher{display:none;line-height:64px;align-items:center}.l_header .switcher>li{height:48px;transition:all .28s ease;-moz-transition:all .28s ease;-webkit-transition:all .28s ease;-o-transition:all .28s ease;margin:2px}@media screen and (max-width:500px){.l_header .switcher>li{margin:0 1px;height:48px}}.l_header .switcher>li>a{display:flex;justify-content:center;align-items:center;width:48px;height:48px;padding:.85em 1.1em;border-radius:100px;border:none;transition:all .28s ease;-moz-transition:all .28s ease;-webkit-transition:all .28s ease;-o-transition:all .28s ease;color:#2196f3}.l_header .nav-sub .switcher{display:flex}.l_header .m_search{display:flex;height:64px;width:240px;transition:all .28s ease;-moz-transition:all .28s ease;-webkit-transition:all .28s ease;-o-transition:all .28s ease}@media screen and (max-width:1024px){.l_header .m_search{width:44px;min-width:44px}.l_header .m_search input::placeholder{opacity:0}.l_header .m_search:hover{width:240px}.l_header .m_search:hover input::placeholder{opacity:1}}@media screen and (min-width:500px){.l_header .m_search:hover .input{width:100%}.l_header .m_search:hover .input::placeholder{opacity:1}}@media screen and (max-width:500px){.l_header .m_search{min-width:0}.l_header .m_search input::placeholder{opacity:1}}.l_header .m_search .form{position:relative;display:flex;width:100%;align-items:center}.l_header .m_search .icon{position:absolute;width:36px;left:5px;color:var(--color-meta)}@media screen and (max-width:500px){.l_header .m_search .icon{display:none}}.l_header .m_search .input{display:block;padding-top:8px;padding-bottom:8px;line-height:1.3;width:100%;color:var(--color-text);background:#fafafa;box-shadow:none;box-sizing:border-box;padding-left:40px;font-size:.875rem;border-radius:8px;border:none;transition:all .28s ease;-moz-transition:all .28s ease;-webkit-transition:all .28s ease;-o-transition:all .28s ease}@media screen and (min-width:500px){.l_header .m_search .input:focus{box-shadow:0 4px 8px 0 rgba(0,0,0,.1)}}@media screen and (max-width:500px){.l_header .m_search .input{background:var(--color-block);padding-left:8px;border:none}.l_header .m_search .input:focus,.l_header .m_search .input:hover{border:none}}@media (max-width:500px){.l_header .m_search{left:0;width:0;overflow:hidden;position:absolute;background:#fff;transition:all .28s ease;-moz-transition:all .28s ease;-webkit-transition:all .28s ease;-o-transition:all .28s ease}.l_header .m_search .input{border-radius:32px;margin-left:16px;padding-left:16px}.l_header.z_search-open .m_search{width:100%}.l_header.z_search-open .m_search .input{width:calc(100% - 120px)}}ul.m-pc>li>a{color:inherit;border-bottom:2px solid transparent}ul.m-pc>li>a.active,ul.m-pc>li>a:active{border-bottom:2px solid #2196f3}ul.nav-list-h{display:flex;align-items:stretch}ul.nav-list-h>li{position:relative;justify-content:center;height:100%;line-height:2.4;border-radius:4px}ul.nav-list-h>li>a{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;font-weight:600}ul.list-v{z-index:1;display:none;position:absolute;background:var(--color-card);box-shadow:0 2px 4px 0 rgba(0,0,0,.08),0 4px 8px 0 rgba(0,0,0,.08),0 8px 16px 0 rgba(0,0,0,.08);margin-top:-6px;border-radius:4px;padding:8px 0}.l_header .menu>ul>li>a{display:block;padding:0 8px}.l_header .menu>ul>li>a>i{margin-right:4px}.l_header ul.nav-list-h>li{color:var(--color-list);line-height:62px}.l_header ul.nav-list-h>li>a{max-height:62px;overflow:hidden;color:inherit}.l_header ul.nav-list-h>li>a.active,.l_header ul.nav-list-h>li>a:active{color:#2196f3}.l_header{max-width:65vw;left:calc((100% - 65vw) * .5);border-bottom-left-radius:8px;border-bottom-right-radius:8px}@media screen and (max-width:2048px){.l_header{max-width:1112px;left:calc((100% - 1112px) * .5)}}@media screen and (max-width:1112px){.l_header{left:0;border-radius:0;max-width:100%}}@media screen and (max-width:500px){.l_header .container{margin-left:0;margin-right:0}.l_header #wrapper .nav-main .title{padding-left:16px;padding-right:16px}.l_header #wrapper .nav-sub{width:100%}.l_header #wrapper .nav-sub .title{overflow-y:scroll;margin-top:2px;padding:8px 16px}.l_header #wrapper .switcher{display:flex;margin-right:8px}.l_header .menu{display:none}}</style><link rel="stylesheet" href="/css/style.css" media="print" onload='this.media="all",this.onload=null'><noscript><link rel="stylesheet" href="/css/style.css"></noscript><script id="loadcss"></script></head><body><header id="l_header" class="l_header auto shadow floatable blur show" style="opacity:0"><div class="container"><div id="wrapper"><div class="nav-sub"><p class="title"></p><ul class="switcher nav-list-h m-phone" id="pjax-header-nav-list"><li><a id="s-comment" class="fad fa-comments fa-fw" target="_self" href="javascript:void(0)"></a></li><li><a id="s-toc" class="s-toc fad fa-list fa-fw" target="_self" href="javascript:void(0)"></a></li></ul></div><div class="nav-main"> <a class="title flat-box" target="_self" href="/">MHuiG's Blog</a><div class="menu navigation"><ul class="nav-list-h m-pc"><li><a class="menuitem flat-box faa-parent animated-hover" href="/archives/" id="archives"><i class="fad fa-list-alt fa-fw"></i> 索引</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/" id="categories"><i class="fad fa-folder-open fa-fw"></i> 分类</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/tags/" id="tags"><i class="fad fa-tags fa-fw"></i> 标签</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/archives/" id="archives"><i class="fad fa-archive fa-fw"></i> 归档</a></li></ul></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/friends/" id="friends"><i class="fad fa-link fa-fw"></i> 友链</a><ul class="list-v"><li class="header"><i class="fad fa-share fa-fw"></i> 友链接力</li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://travellings.now.sh/" id="https:travellingsnowsh" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-paper-plane fa-fw"></i> Travelling</a></li></ul></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/about/" id="about"><i class="fad fa-user-tie fa-fw"></i> 关于</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover" href="/time-machine/" id="time-machine"><i class="fad fa-clock fa-fw"></i> 时光机</a></li></ul></li><li><a class="menuitem flat-box faa-parent animated-hover"><i class="fad fa-fan fa-spin fa-fw"></i> 更多</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover"><i class="fad fa-user-shield fa-fw"></i> 博客管理</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover" href="https://inf.mhuig.top" id="https:infmhuigtop" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-comments fa-fw"></i> 评论管理</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://www.yuque.com/mhuig" id="https:wwwyuquecommhuig" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-edit fa-fw"></i> 云端编辑</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://status.mhuig.top/" id="https:statusmhuigtop" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-telescope fa-fw"></i> Monitors</a></li></ul></li><hr><li><a class="menuitem flat-box faa-parent animated-hover"><i class="fad fa-tools fa-fw"></i> 工具箱</a><ul class="list-v"><li><a class="menuitem flat-box header toggle-mode-btn"><i class="fad fa-moon fa-fw"></i> 暗黑模式</a></li><li></li><li><a class="menuitem flat-box"><i class="fad fa-compact-disc fa-spin fa-fw music"></i> Music</a><ul class="list-v"><li><div class="aplayer-container"><meting-js theme="#1BCDFC" volume="0.7" loop="all" order="list" fixed="false" list-max-height="320px" server="netease" type="song" id="412785957" list-folded="true"></meting-js></div></li></ul></li><li></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/atom.xml" id="atomxml"><i class="fad fa-rss fa-fw"></i> RSS订阅</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/sitemap.xml" id="sitemapxml"><i class="fad fa-sitemap fa-fw"></i> 站点地图</a></li></ul></li><hr><li><a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/MHuiG" id="https:githubcomMHuiG" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></li></ul></li></ul></div><div class="m_search"><form name="searchform" class="form u-search-form"><i class="icon fad fa-search fa-fw"></i> <input type="text" class="input u-search-input" placeholder="Search..."></form></div><ul class="switcher nav-list-h m-phone"><li><a class="s-search fad fa-search fa-fw" target="_self" href="javascript:void(0)"></a></li><li><a class="s-menu fad fa-bars fa-fw" target="_self" href="javascript:void(0)"></a><ul class="menu-phone list-v navigation white-box"><li><a class="menuitem flat-box faa-parent animated-hover" href="/archives/" id="archives"><i class="fad fa-list-alt fa-fw"></i> 索引</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/" id="categories"><i class="fad fa-folder-open fa-fw"></i> 分类</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/tags/" id="tags"><i class="fad fa-tags fa-fw"></i> 标签</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/archives/" id="archives"><i class="fad fa-archive fa-fw"></i> 归档</a></li></ul></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/friends/" id="friends"><i class="fad fa-link fa-fw"></i> 友链</a><ul class="list-v"><li class="header"><i class="fad fa-share fa-fw"></i> 友链接力</li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://travellings.now.sh/" id="https:travellingsnowsh" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-paper-plane fa-fw"></i> Travelling</a></li></ul></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/about/" id="about"><i class="fad fa-user-tie fa-fw"></i> 关于</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover" href="/time-machine/" id="time-machine"><i class="fad fa-clock fa-fw"></i> 时光机</a></li></ul></li><li><a class="menuitem flat-box faa-parent animated-hover"><i class="fad fa-fan fa-spin fa-fw"></i> 更多</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover"><i class="fad fa-user-shield fa-fw"></i> 博客管理</a><ul class="list-v"><li><a class="menuitem flat-box faa-parent animated-hover" href="https://inf.mhuig.top" id="https:infmhuigtop" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-comments fa-fw"></i> 评论管理</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://www.yuque.com/mhuig" id="https:wwwyuquecommhuig" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-edit fa-fw"></i> 云端编辑</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="https://status.mhuig.top/" id="https:statusmhuigtop" rel="external nofollow noopener noreferrer" target="_blank"><i class="fad fa-telescope fa-fw"></i> Monitors</a></li></ul></li><hr><li><a class="menuitem flat-box faa-parent animated-hover"><i class="fad fa-tools fa-fw"></i> 工具箱</a><ul class="list-v"><li><a class="menuitem flat-box header toggle-mode-btn"><i class="fad fa-moon fa-fw"></i> 暗黑模式</a></li><li></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/atom.xml" id="atomxml"><i class="fad fa-rss fa-fw"></i> RSS订阅</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/sitemap.xml" id="sitemapxml"><i class="fad fa-sitemap fa-fw"></i> 站点地图</a></li></ul></li><hr><li><a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/MHuiG" id="https:githubcomMHuiG" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></li></ul></li></ul></li></ul></div></div></div></header><div id="l_body"><div id="l_cover"><div id="full" class="cover-wrapper post featured" style="display:none"><div class="cover-bg lazyload placeholder" data-bg></div><div class="cover-body"><div class="top"><p class="title">MHuiG</p><p class="subtitle">「Be Yourself, Make a Difference.」</p></div><div class="bottom"><div class="menu navigation"><div class="list-h"><a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/MHuiG" id="https:githubcomMHuiG"><i class="fab fa-github fa-fw" style="color:#000"></i><p>Github</p></a><a href="/friends/" id="friends"><i class="fad fa-link fa-fw" style="color:#d31ee9"></i><p>友链</p></a><a href="/about/" id="about"><i class="fad fa-user-tie fa-fw" style="color:#0095ff"></i><p>关于</p></a><a target="_blank" rel="external nofollow noopener noreferrer" href="https://travellings.now.sh/" id="https:travellingsnowsh"><i class="fad fa-paper-plane fa-fw" style="color:#734ae6"></i><p>Travelling</p></a></div></div></div></div><div id="scroll-down" style="display:none"><i class="fa fa-chevron-down scroll-down-effects"></i></div></div></div><div id="safearea"><div class="body-wrapper" id="pjax-container"><div class="l_main"><article class="article post white-box reveal md shadow floatable blur article-type-post" id="post" itemscope itemprop="blogPost"><div class="headimg-div"> <a class="headimg-a"><img class="headimg lazyload" src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020116102430.jpeg" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020116102430.jpeg" srcset="data:image/png;base64,666"></a></div><div class="article-meta" id="top"><h1 class="title"> BERT预训练模型及其应用案例</h1><div class="new-meta-box"><div class="new-meta-item category"><a class="notlink"><i class="fad fa-folder-open fa-fw" aria-hidden="true"></i> <a class="category-link" href="/categories/nlp/">NLP</a></a></div><div class="new-meta-item date"><a class="notlink"><i class="fad fa-calendar-alt fa-fw" aria-hidden="true"></i><p>发布于：2020年11月5日</p></a></div><div class="new-meta-item wordcount"><a class="notlink"><i class="fad fa-keyboard fa-fw" aria-hidden="true"></i><p>字数：6.8k字</p></a></div><div class="new-meta-item readtime"><a class="notlink"><i class="fad fa-hourglass-half fa-fw" aria-hidden="true"></i><p>时长：25分钟</p></a></div></div></div><p>预训练模型最开始是在图像领域提出的，获得了良好的效果，近几年才被广泛应用到自然语言处理各项任务中。</p><ul><li><p>(1)2003年Bengio提出神经网络语言模型NNLM，从此统一了NLP的特征形式——Embedding；</p></li><li><p>(2)2013年Mikolov提出词向量Word2vec，延续NNLM又引入了大规模预训练（Pretrain）的思路；</p></li><li><p>(3)2017年Vaswani提出Transformer模型，实现用一个模型处理多种NLP任务。</p></li><li><p>(4) 基于Transformer架构，2018年底开始出现一大批预训练语言模型(3个预训练代表性模型BERT[2018]、XLNet[2019]和MPNet[2020])，刷新众多NLP任务，形成新的里程碑事件。</p></li></ul><a id="more"></a><p>预训练模型的应用通常分为两步:</p><ul><li><p>第一步：在计算性能满足的情况下用某个较大的数据集训练出一个较好的模型。</p></li><li><p>第二步：根据不同的任务，改造预训练模型，用新任务的数据集在预训练模型上进行微调。</p></li></ul><p>预训练模型的好处是训练代价较小，配合下游任务可以实现更快的收敛速度，并且能够有效地提高模型性能，尤其是对一些训练数据比较稀缺的任务。换句话说，预训练方法可以认为是让模型基于一个更好的初始状态进行学习，从而能够达到更好的性能。</p><p>要讲自然语言的预训练，得先从图像领域的预训练说起。</p><h2 id="图像领域的预训练"><a href="#图像领域的预训练" class="headerlink" title="图像领域的预训练"></a>图像领域的预训练</h2><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115152532.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115152532.png" srcset="data:image/png;base64,666"></p><p>设计好网络结构以后，对于图像来说一般是CNN的多层叠加网络结构，可以先用某个训练集合比如训练集合A或者训练集合B对这个网络进行预先训练，在A任务上或者B任务上学会网络参数，然后存起来以备后用。假设我们面临第三个任务C，网络结构采取相同的网络结构，在比较浅的几层CNN结构，网络参数初始化的时候可以加载A任务或者B任务学习好的参数，其它CNN高层参数仍然随机初始化。</p><p>之后我们用C任务的训练数据来训练网络，此时有两种做法，一种是浅层加载的参数在训练C任务过程中不动，这种方法被称为“Frozen”;</p><p>另外一种是底层网络参数尽管被初始化了，在C任务训练过程中仍然随着训练的进程不断改变，这种一般叫“Fine-Tuning”，顾名思义，就是更好地把参数进行调整使得更适应当前的C任务。</p><p>对于层级的CNN结构来说，不同层级的神经元学习到了不同类型的图像特征，由底向上特征形成层级结构。</p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115152735.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115152735.png" srcset="data:image/png;base64,666"></p><p> 如果我们手头是个人脸识别任务，训练好网络后，把每层神经元学习到的特征可视化肉眼看一看每层学到了啥特征，你会看到最底层的神经元学到的是线段等特征，图示的第二个隐层学到的是人脸五官的轮廓，第三层学到的是人脸的轮廓，通过三步形成了特征的层级结构，越是底层的特征越是所有不论什么领域的图像都会具备的比如边角线弧线等底层基础特征，越往上抽取出的特征越与手头任务相关。</p><p>正因为此，所以预训练好的网络参数，尤其是底层的网络参数抽取出特征跟具体任务越无关，越具备任务的通用性，所以这是为何一般用底层预训练好的参数初始化新任务网络参数的原因。</p><p>而高层特征跟任务关联较大，实际可以不用使用，或者采用Fine-tuning用新数据集合清洗掉高层无关的特征抽取器。</p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115152826.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115152826.png" srcset="data:image/png;base64,666"></p><p> 一般我们用ImageNet来做网络的预训练，主要有两点，一方面ImageNet是图像领域里有超多事先标注好训练数据的数据集合，分量足是个很大的优势，量越大训练出的参数越靠谱；另外一方面因为ImageNet有1000类，类别多，算是通用的图像数据，跟领域没太大关系，所以通用性好。</p><h2 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h2><p>现有的机器学习方法往往无法直接处理文本数据，因此需要找到合适的方法，将文本数据转换为数值型数据，由此引出了Word Embedding的概念，Word Embedding算法携带了语义信息且维度经过压缩便于运算。</p><h3 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h3><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115152917.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115152917.png" srcset="data:image/png;base64,666"></p><p>为了能够量化地衡量哪个句子更像一句人话，可以设计如上图所示函数，核心函数P的思想是根据句子里面前面的一系列前导单词预测后面单词的概率大小。</p><h3 id="神经网络语言模型"><a href="#神经网络语言模型" class="headerlink" title="神经网络语言模型"></a>神经网络语言模型</h3><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115152938.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115152938.png" srcset="data:image/png;base64,666"></p><p>NNLM是从语言模型出发(即计算概率角度)，构建神经网络针对目标函数对模型进行最优化，训练的起点是使用神经网络去搭建语言模型实现词的预测任务，并且在优化过程后模型的副产品就是词向量。</p><h3 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h3><p>2013年最火的用语言模型做Word Embedding的工具是Word2Vec，后来又出了Glove。</p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115152959.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115152959.png" srcset="data:image/png;base64,666"></p><p>Word2Vec有两种训练方法，一种叫CBOW，核心思想是从一个句子里面把一个词抠掉，用这个词的上文和下文去预测被抠掉的这个词；</p><p>第二种叫做Skip-gram，和CBOW正好反过来，输入某个单词，要求网络预测它的上下文单词。</p><p>使用Word2Vec或者Glove，通过做语言模型任务，就可以获得每个单词的Word Embedding。</p><h3 id="Word-Embedding的使用"><a href="#Word-Embedding的使用" class="headerlink" title="Word Embedding的使用"></a>Word Embedding的使用</h3><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153022.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153022.png" srcset="data:image/png;base64,666"></p><p>我们有个NLP的下游任务，比如QA，就是问答问题，所谓问答问题，指的是给定一个问题X，给定另外一个句子Y,要判断句子Y是否是问题X的正确答案。</p><p>句子中每个单词以Onehot形式作为输入，然后乘以Word Embedding矩阵Q，就直接取出单词对应的Word Embedding。</p><p>使用Word Embedding等价于把Onehot层到embedding层的网络用预训练好的参数矩阵Q初始化。</p><p>这跟前面讲的图像领域的低层预训练过程其实是一样的，区别无非Word Embedding只能初始化第一层网络参数，再高层的参数就无能为力了。</p><p>下游NLP任务在使用Word Embedding的时候也类似图像有两种做法，一种是Frozen，就是Word Embedding那层网络参数固定不动；另外一种是Fine-Tuning，就是使用新的训练集合训练，在训练过程中，更新Word Embedding这层参数。</p><h3 id="Word-Embedding的问题"><a href="#Word-Embedding的问题" class="headerlink" title="Word Embedding的问题"></a>Word Embedding的问题</h3><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153044.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153044.png" srcset="data:image/png;base64,666"></p><p>是多义词问题。多义词是自然语言中经常出现的现象，也是语言灵活性和高效性的一种体现。</p><p>多义词对Word Embedding来说有什么负面影响？如上图所示，比如多义词Bank，有两个常用含义，但是Word Embedding在对bank这个单词进行编码的时候，是区分不开这两个含义的，因为它们尽管上下文环境中出现的单词不同，但是在用语言模型训练的时候，不论什么上下文的句子经过word2vec，都是预测相同的单词bank，而同一个单词占的是同一行的参数空间，这导致两种不同的上下文信息都会编码到相同的word embedding空间里去。所以word embedding无法区分多义词的不同语义，这就是它的一个比较严重的问题。</p><h2 id="从Word-Embedding到ELMO"><a href="#从Word-Embedding到ELMO" class="headerlink" title="从Word Embedding到ELMO"></a>从Word Embedding到ELMO</h2><p>ELMO是“Embedding from Language Models”的简称。在此之前的Word Embedding本质上是个静态的方式，所谓静态指的是训练好之后每个单词的表达就固定住了，以后使用的时候，不论新句子上下文单词是什么，这个单词的Word Embedding不会跟着上下文场景的变化而改变。</p><p>ELMO的本质思想是：事先用语言模型学好一个单词的Word Embedding，此时多义词无法区分，实际使用Word Embedding的时候，单词已经具备了特定的上下文了，这个时候可以根据上下文单词的语义去调整单词的Word Embedding表示，这样经过调整后的Word Embedding更能表达在这个上下文中的具体含义，自然也就解决了多义词的问题了。所以ELMO本身的思路是根据当前上下文对Word Embedding动态调整。</p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/202011515317.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/202011515317.png" srcset="data:image/png;base64,666"></p><p>ELMO采用了典型的两阶段过程，第一个阶段是利用语言模型进行预训练；第二个阶段是在做下游任务时，从预训练网络中提取对应单词的网络各层的Word Embedding作为新特征补充到下游任务中。</p><p>使用这个网络结构利用大量语料做语言模型任务就能预先训练好这个网络，如果训练好这个网络后，输入一个新句子 ，句子中每个单词都能得到对应的三个Embedding:最底层是单词的Word Embedding，往上走是第一层双向LSTM中对应单词位置的Embedding，这层编码单词的句法信息更多一些；再往上走是第二层LSTM中对应单词位置的Embedding，这层编码单词的语义信息更多一些。也就是说，ELMO的预训练过程不仅仅学会单词的Word Embedding，还学会了一个双层双向的LSTM网络结构，而这两者后面都有用。</p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153133.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153133.png" srcset="data:image/png;base64,666"></p><p> 上图展示了下游任务的使用过程，比如我们的下游任务仍然是QA问题，此时对于问句X，我们可以先将句子X作为预训练好的ELMO网络的输入，这样句子X中每个单词在ELMO网络中都能获得对应的三个Embedding，之后给予这三个Embedding中的每一个Embedding一个权重a，这个权重可以学习得来，根据各自权重累加求和，将三个Embedding整合成一个。然后将整合后的这个Embedding作为X句在自己任务的那个网络结构中对应单词的输入，以此作为补充的新特征给下游任务使用。对于上图所示下游任务QA中的回答句子Y来说也是如此处理。因为ELMO给下游提供的是每个单词的特征形式，所以这一类预训练的方法被称为“Feature-based Pre-Training”。</p><h2 id="从Word-Embedding到GPT"><a href="#从Word-Embedding到GPT" class="headerlink" title="从Word Embedding到GPT"></a>从Word Embedding到GPT</h2><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153159.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153159.png" srcset="data:image/png;base64,666"></p><p>GPT是“Generative Pre-Training”的简称，从名字看其含义是指的生成式的预训练。GPT也采用两阶段过程，第一个阶段是利用语言模型进行预训练，第二阶段通过Fine-tuning的模式解决下游任务。</p><h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p>Transformer是个叠加的“自注意力机制（Self Attention）”构成的深度网络，是目前NLP里最强的特征提取器。</p><p>Transformer 是一种基于 encoder-decoder 结构的模型. 在机器翻译任务上的表现超过了 RNN，CNN，只用 encoder-decoder 和 attention 机制就能达到很好的效果，最大的优点是可以高效地并行化。</p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153231.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153231.png" srcset="data:image/png;base64,666"></p><h3 id="自注意力机制模型"><a href="#自注意力机制模型" class="headerlink" title="自注意力机制模型"></a>自注意力机制模型</h3><p>人类视觉通过快速扫描全局图像，获得需要重点关注的目标区域，也就是一般所说的注意力焦点，而后对这一区域投入更多注意力资源，以获取更多所需要关注目标的细节信息，而抑制其他无用信息。</p><p>这是人类利用有限的注意力资源从大量信息中快速筛选出高价值信息的手段.</p><p>深度学习中的注意力机制从本质上讲和人类的选择性视觉注意力机制类似，核心目标也是从众多信息中选择出对当前任务目标更关键的信息。</p><p>Attention在同一个英语句子内单词间产生的联系。</p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/202011515330.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/202011515330.png" srcset="data:image/png;base64,666"></p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153319.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153319.png" srcset="data:image/png;base64,666"></p><p>Self Attention可以捕获同一个句子中单词之间的一些句法特征（比如图展示的有一定距离的短语结构）或者语义特征（比如图展示的its的指代对象Law）。</p><p>很明显，引入Self Attention后会更容易捕获句子中长距离的相互依赖的特征，因为如果是RNN或者LSTM，需要依次序序列计算，对于远距离的相互依赖的特征，要经过若干时间步步骤的信息累积才能将两者联系起来，而距离越远，有效捕获的可能性越小。</p><p>SelfAttention在计算过程中会直接将句子中任意两个单词的联系通过一个计算步骤直接联系起来，所以远距离依赖特征之间的距离被极大缩短，有利于有效地利用这些特征。除此外，SelfAttention对于增加计算的并行性也有直接帮助作用。这是为何Self Attention逐渐被广泛使用的主要原因。</p><h3 id="GPT如何使用"><a href="#GPT如何使用" class="headerlink" title="GPT如何使用"></a>GPT如何使用</h3><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153347.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153347.png" srcset="data:image/png;base64,666"></p><p>把任务的网络结构改造成和GPT的网络结构是一样的。然后，在做下游任务的时候，利用第一步预训练好的参数初始化GPT的网络结构，对网络参数进行Fine-tuning，使得这个网络更适合解决手头的问题。</p><h2 id="从GPT和ELMO及word2Vec到Bert"><a href="#从GPT和ELMO及word2Vec到Bert" class="headerlink" title="从GPT和ELMO及word2Vec到Bert"></a>从GPT和ELMO及word2Vec到Bert</h2><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153419.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153419.png" srcset="data:image/png;base64,666"></p><p>Bert采用和GPT完全相同的两阶段模型，首先是语言模型预训练；其次是使用Fine-Tuning模式解决下游任务。和GPT的最主要不同在于在预训练阶段采用了类似ELMO的双向语言模型，当然另外一点是语言模型的数据规模要比GPT大。</p><p>BERT本质上是一个自编码（Auto Encoder）语言模型，为了能见多识广，BERT使用3亿多词语训练，采用12层双向Transformer架构。注意，BERT只使用了Transformer的编码器部分，可以理解为BERT旨在学习庞大文本的内部语义信息。</p><p>具体训练目标之一，是被称为掩码语言模型的MLM。即输入一句话，给其中15%的字打上“mask”标记，经过Embedding输入和12层Transformer深度理解，来预测“mask”标记的地方原本是哪个字。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input:   欲把西[mask]比西子，淡[mask]浓抹总相宜</span><br><span class="line">output:  欲把西[湖]比西子，淡[妆]浓抹总相宜</span><br></pre></td></tr></table></figure><p>例如我们输入“欲把西[mask]比西子，淡[mask]浓抹总相宜”给BERT，它需要根据没有被“mask”的上下文，预测出掩盖的地方是“湖”和“妆”。</p><p>MLM任务的灵感来自于人类做完形填空。挖去文章中的某些片段，需要通过上下文理解来猜测这些被掩盖位置原先的内容。</p><p>训练目标之二，是预测输入的两句话之间是否为上下文（NSP）的二分类问题。继续输入“ 欲把西[湖]比西子，淡[妆]浓抹总相宜”，BERT将预测这两句话的组合是否合理（这个例子是“yes”）。（随后的研究者对预训练模型探索中证明，NSP任务过于简单，对语言模型的训练作用并不是很大）</p><p>通过这两个任务和大规模语料训练，BERT语言模型可以很好学习到文本之间的蕴含的关系。</p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153516.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153516.png" srcset="data:image/png;base64,666"></p><h2 id="NLP的四大任务"><a href="#NLP的四大任务" class="headerlink" title="NLP的四大任务"></a>NLP的四大任务</h2><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153626.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153626.png" srcset="data:image/png;base64,666"></p><p>绝大部分NLP问题可以归入上图所示的四类任务中：</p><p>一类是序列标注，这是最典型的NLP任务，比如中文分词，词性标注，命名实体识别，语义角色标注等都可以归入这一类问题，它的特点是句子中每个单词要求模型根据上下文都要给出一个分类类别。</p><p>第二类是分类任务，比如我们常见的文本分类，情感计算等都可以归入这一类。它的特点是不管文章有多长，总体给出一个分类类别即可。</p><p>第三类任务是句子关系判断，比如Entailment，QA，语义改写，自然语言推理等任务都是这个模式，它的特点是给定两个句子，模型判断出两个句子是否具备某种语义关系；</p><p>第四类是生成式任务，比如机器翻译，文本摘要，写诗造句，看图说话等都属于这一类。它的特点是输入文本内容后，需要自主生成另外一段文字。</p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153650.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153650.png" srcset="data:image/png;base64,666"></p><p>根据任务选择不同的预训练数据初始化encoder和decoder即可。这是相当直观的一种改造方法。当然，也可以更简单一点，比如直接在单个Transformer结构上加装隐层产生输出也是可以的。不论如何，从这里可以看出，NLP四大类任务都可以比较方便地改造成Bert能够接受的方式。这其实是Bert的非常大的优点，这意味着它几乎可以做任何NLP的下游任务，具备普适性，这是很强的。</p><h2 id="BERT的应用案例"><a href="#BERT的应用案例" class="headerlink" title="BERT的应用案例"></a>BERT的应用案例</h2><h3 id="下载bert预训练模型"><a href="#下载bert预训练模型" class="headerlink" title="下载bert预训练模型"></a>下载bert预训练模型</h3><p>Google - BERT源码<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/google-research/bert%E4%B8%8B%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E3%80%82">https://github.com/google-research/bert下载预训练模型。</a></p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153710.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153710.png" srcset="data:image/png;base64,666"></p><p>我这里选择中文的BERT，下载解压后的目录如下：</p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153734.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153734.png" srcset="data:image/png;base64,666"></p><h3 id="安装bert-as-service"><a href="#安装bert-as-service" class="headerlink" title="安装bert-as-service"></a>安装bert-as-service</h3><p>顾名思义，将BERT模型直接封装成一个服务，堪称上手最快的BERT工具。作者是肖涵博士。</p><p>使用pip安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install bert-serving-server # server</span><br><span class="line">pip install bert-serving-client # client, independent of `bert-serving-server</span><br></pre></td></tr></table></figure><p>开启BERT service</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bert-serving-start -model_dir E:\nlp\chinese_L-12_H-768_A-12</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153752.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153752.png" srcset="data:image/png;base64,666"></p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153813.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153813.png" srcset="data:image/png;base64,666"></p><p>使用客户端获取句子编码</p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153830.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153830.png" srcset="data:image/png;base64,666"></p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153851.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153851.png" srcset="data:image/png;base64,666"></p><h3 id="案例一-查找最相近的句子"><a href="#案例一-查找最相近的句子" class="headerlink" title="案例一 查找最相近的句子"></a>案例一 查找最相近的句子</h3><p>根据bert获取句子向量，并计算出句子之间的余弦相似度，找出最相似的句子。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入bert客户端</span></span><br><span class="line"><span class="keyword">from</span> bert_serving.client <span class="keyword">import</span> BertClient</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimilarModel</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.bert_client = BertClient()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_bert</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.bert_client .close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_sentence_vec</span>(<span class="params">self,sentence</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        根据bert获取句子向量</span></span><br><span class="line"><span class="string">        :param sentence:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> self.bert_client .encode([sentence])[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cos_similar</span>(<span class="params">self,sen_a_vec, sen_b_vec</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        计算两个句子的余弦相似度</span></span><br><span class="line"><span class="string">        :param sen_a_vec:</span></span><br><span class="line"><span class="string">        :param sen_b_vec:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        vector_a = np.mat(sen_a_vec)</span><br><span class="line">        vector_b = np.mat(sen_b_vec)</span><br><span class="line">        num = float(vector_a * vector_b.T)</span><br><span class="line">        denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)</span><br><span class="line">        cos = num / denom</span><br><span class="line">        <span class="keyword">return</span> cos</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 从候选集condinates 中选出与sentence_a 最相近的句子</span></span><br><span class="line">    condinates = [<span class="string">&#x27;为什么天空是蔚蓝色的&#x27;</span>,<span class="string">&#x27;太空为什么是黑的？&#x27;</span>,<span class="string">&#x27;天空怎么是蓝色的&#x27;</span>,<span class="string">&#x27;明天去爬山如何&#x27;</span>]</span><br><span class="line">    sentence_a = <span class="string">&#x27;天空为什么是蓝色的&#x27;</span></span><br><span class="line">    bert_client = SimilarModel()</span><br><span class="line">    max_cos_similar = <span class="number">0</span></span><br><span class="line">    most_similar_sentence = <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> sentence_b <span class="keyword">in</span> condinates:</span><br><span class="line">        sentence_a_vec = bert_client.get_sentence_vec(sentence_a)</span><br><span class="line">        sentence_b_vec = bert_client.get_sentence_vec(sentence_b)</span><br><span class="line">        cos_similar = bert_client.cos_similar(sentence_a_vec,sentence_b_vec)</span><br><span class="line">        <span class="keyword">if</span> cos_similar &gt; max_cos_similar:</span><br><span class="line">            max_cos_similar = cos_similar</span><br><span class="line">            most_similar_sentence = sentence_b</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;最相似的句子：&#x27;</span>,most_similar_sentence)</span><br><span class="line">    bert_client .close_bert()</span><br><span class="line">    <span class="comment"># 为什么天空是蔚蓝色的</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="案例二-简单模糊搜索"><a href="#案例二-简单模糊搜索" class="headerlink" title="案例二 简单模糊搜索"></a>案例二 简单模糊搜索</h3><p>将问题编码为向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bert_serving.client <span class="keyword">import</span> BertClient</span><br><span class="line">doc_vecs = bc.encode(questions)</span><br></pre></td></tr></table></figure><p>最后，我们准备接收新查询并针对现有问题执行简单的“模糊”搜索。为此，每次出现新查询时，我们都将其编码为向量，并使用来计算其点积doc_vecs。将结果递减排序；并返回前k个类似的问题，如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    query = input(<span class="string">&#x27;your question: &#x27;</span>)</span><br><span class="line">    query_vec = bc.encode([query])[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># compute normalized dot product as score</span></span><br><span class="line">    score = np.sum(query_vec * doc_vecs, axis=<span class="number">1</span>) / np.linalg.norm(doc_vecs, axis=<span class="number">1</span>)</span><br><span class="line">    topk_idx = np.argsort(score)[::<span class="number">-1</span>][:topk]</span><br><span class="line">    print(<span class="string">&#x27;top %d questions similar to &quot;%s&quot;&#x27;</span> % (topk, query))</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> topk_idx:</span><br><span class="line">        print(<span class="string">&#x27;&gt; %s\t%s&#x27;</span> % (<span class="string">&#x27;%.1f&#x27;</span> % score[idx], questions[idx]))</span><br></pre></td></tr></table></figure><p>现在运行代码并键入查询，查看此搜索引擎如何处理模糊匹配：</p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/202011515405.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/202011515405.png" srcset="data:image/png;base64,666"></p><h3 id="案例三-法条推荐"><a href="#案例三-法条推荐" class="headerlink" title="案例三 法条推荐"></a>案例三 法条推荐</h3><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>根据刑事法律文书中的案情描述和事实部分，预测本案涉及的相关法条；</p><h4 id="数据说明"><a href="#数据说明" class="headerlink" title="数据说明"></a>数据说明</h4><p>所使用的数据集是来自“中国裁判文书网”公开的刑事法律文书，其中每份数据由法律文书中的案情描述和事实部分组成，同时也包括每个案件所涉及的法条、被告人被判的罪名和刑期长短等要素。</p><p>数据集共包括268万刑法法律文书，共涉及202条罪名，183条法条，刑期长短包括0-25年、无期、死刑。</p><p>数据利用json格式储存，每一行为一条数据，每条数据均为一个字典。</p><p>fact: 事实描述</p><p>meta: 标注信息，标注信息中包括:</p><p>criminals: 被告(数据中均只含一个被告)</p><p>punish_of_money: 罚款(单位：元)</p><p>accusation: 罪名</p><p>relevant_articles: 相关法条</p><p>term_of_imprisonment: 刑期</p><p>刑期格式(单位：月)</p><p>death_penalty: 是否死刑</p><p>life_imprisonment: 是否无期</p><p>imprisonment: 有期徒刑刑期</p><p>这里是简单的一条数据展示:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   <span class="string">&quot;fact&quot;</span>: <span class="string">&quot;2015年11月5日上午，被告人胡某在平湖市乍浦镇的嘉兴市多凌金牛制衣有限公司车间内，与被害人孙某因工作琐事发生口角，后被告人胡某用木制坐垫打伤被害人孙某左腹部。经平湖公安司法鉴定中心鉴定：孙某的左腹部损伤已达重伤二级。&quot;</span>,  </span><br><span class="line">   <span class="string">&quot;meta&quot;</span>: </span><br><span class="line">   &#123; </span><br><span class="line">       <span class="string">&quot;relevant_articles&quot;</span>: [<span class="number">234</span>], </span><br><span class="line">       <span class="string">&quot;accusation&quot;</span>: [<span class="string">&quot;故意伤害&quot;</span>], </span><br><span class="line">       <span class="string">&quot;criminals&quot;</span>: [<span class="string">&quot;胡某&quot;</span>], </span><br><span class="line">       <span class="string">&quot;term_of_imprisonment&quot;</span>:</span><br><span class="line">       &#123; </span><br><span class="line">          <span class="string">&quot;death_penalty&quot;</span>: false, </span><br><span class="line">          <span class="string">&quot;imprisonment&quot;</span>: <span class="number">12</span>, </span><br><span class="line">          <span class="string">&quot;life_imprisonment&quot;</span>: false</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="实现流程"><a href="#实现流程" class="headerlink" title="实现流程"></a>实现流程</h4><p>进入 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/thunlp/OpenCLaP">OpenCLaP</a> 下载刑事文书BERT，并运行bert-as-service服务。</p><h5 id="创建一个连接到BertServer的BertClient"><a href="#创建一个连接到BertServer的BertClient" class="headerlink" title="创建一个连接到BertServer的BertClient"></a>创建一个连接到BertServer的BertClient</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bert_serving.client <span class="keyword">import</span> ConcurrentBertClient</span><br><span class="line">bc = ConcurrentBertClient()</span><br></pre></td></tr></table></figure><h5 id="获取编码向量和标签"><a href="#获取编码向量和标签" class="headerlink" title="获取编码向量和标签"></a>获取编码向量和标签</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_encodes</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="comment"># x 是 batch_size 大小的行 ，每行都是一个json对象</span></span><br><span class="line">    samples = [json.loads(l) <span class="keyword">for</span> l <span class="keyword">in</span> x] <span class="comment"># 一个 batch_size 大小的连续样本</span></span><br><span class="line">    text = [s[<span class="string">&#x27;fact&#x27;</span>][:<span class="number">50</span>] + s[<span class="string">&#x27;fact&#x27;</span>][<span class="number">-50</span>:] <span class="keyword">for</span> s <span class="keyword">in</span> samples] <span class="comment"># 获取案情描述和事实部分文字</span></span><br><span class="line">    features = bc.encode(text) <span class="comment"># 使用bert将字符串列表编码为向量列表</span></span><br><span class="line">    <span class="comment"># 随机选择一个标签</span></span><br><span class="line">    labels = [[str(random.choice(s[<span class="string">&#x27;meta&#x27;</span>][<span class="string">&#x27;relevant_articles&#x27;</span>]))] <span class="keyword">for</span> s <span class="keyword">in</span> samples]</span><br><span class="line">    <span class="keyword">return</span> features, labels</span><br></pre></td></tr></table></figure><h5 id="构建TensorFlow-DNN-模型的分类器"><a href="#构建TensorFlow-DNN-模型的分类器" class="headerlink" title="构建TensorFlow DNN 模型的分类器"></a>构建TensorFlow DNN 模型的分类器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">estimator = DNNClassifier(</span><br><span class="line">    hidden_units=[<span class="number">512</span>], <span class="comment"># 每层隐藏单元的 Iterable 数.所有层都完全连接.</span></span><br><span class="line">    feature_columns=[tf.feature_column.numeric_column(<span class="string">&#x27;feature&#x27;</span>, shape=(<span class="number">768</span>,))], <span class="comment"># 包含模型使用的所有特征列的iterable.集合中的所有项目都应该是从 _FeatureColumn 派生的类的实例.</span></span><br><span class="line">    n_classes=len(laws), <span class="comment"># 标签类的数量.默认为 2,即二进制分类,必须大于1.</span></span><br><span class="line">    config=run_config, <span class="comment"># RunConfig 对象配置运行时设置</span></span><br><span class="line">    label_vocabulary=laws_str, <span class="comment"># 字符串列表,表示可能的标签值.如果给定,标签必须是字符串类型,并且 label_vocabulary 具有任何值.如果没有给出,这意味着标签已经被编码为整数或者在[0,1]内浮动, n_classes=2 ；并且被编码为&#123;0,1,...,n_classes-1&#125;中的整数值,n_classes&gt; 2.如果没有提供词汇表并且标签是字符串,也会出现错误.</span></span><br><span class="line">    optimizer=tf.train.AdamOptimizer(),<span class="comment"># 优化函数</span></span><br><span class="line">    dropout=<span class="number">0.1</span> <span class="comment"># 当不是 None 时,我们将放弃给定坐标的概率.</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure><h5 id="训练和评估"><a href="#训练和评估" class="headerlink" title="训练和评估"></a>训练和评估</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入函数</span></span><br><span class="line">input_fn = <span class="keyword">lambda</span> fp: (tf.data.TextLineDataset(fp) <span class="comment"># TextLineDataset接口提供了一种方法从数据文件中读取。只需要提供文件名（1个或者多个）。这个接口会自动构造一个dataset，类中保存的元素：文中一行，就是一个元素，是string类型的tenser。</span></span><br><span class="line">                       <span class="comment"># map将分别对Dataset的每个元素执行一个函数，而apply将立即对整个Dataset执行一个函数</span></span><br><span class="line">                       .apply(tf.contrib.data.shuffle_and_repeat(buffer_size=<span class="number">10000</span>)) <span class="comment"># repeat重复和shuffle重排 tf.data.Dataset.repeat 转换会将输入数据重复有限（或无限）次；每次数据重复通常称为一个周期。tf.data.Dataset.shuffle 转换会随机化数据集样本的顺序。</span></span><br><span class="line">                       <span class="comment"># 将此数据集的连续元素合并为批。</span></span><br><span class="line">                       .batch(batch_size)</span><br><span class="line">                       <span class="comment"># tf.py_func()接收的是tensor，然后将其转化为numpy array送入我们自定义的get_encodes函数，最后再将get_encodes函数输出的numpy array转化为tensor返回</span></span><br><span class="line">                       .map(<span class="keyword">lambda</span> x: tf.py_func(get_encodes, [x], [tf.float32, tf.string], name=<span class="string">&#x27;bert_client&#x27;</span>),</span><br><span class="line">                            num_parallel_calls=num_parallel_calls)</span><br><span class="line">                       .map(<span class="keyword">lambda</span> x, y: (&#123;<span class="string">&#x27;feature&#x27;</span>: x&#125;, y))</span><br><span class="line">                       .prefetch(<span class="number">20</span>)) <span class="comment"># 创建一个从该数据集中预提取元素的Dataset 大多数数据集输入管道应以调用结束prefetch。这允许在处理当前元素时准备以后的元素。这通常会提高延迟和吞吐量，但以使用额外的内存存储预取元素为代价。</span></span><br><span class="line"><span class="comment"># TrainSpec确定训练的输入数据以及持续时间</span></span><br><span class="line">train_spec = TrainSpec(input_fn=<span class="keyword">lambda</span>: input_fn(train_fp))</span><br><span class="line"><span class="comment"># EvalSpec结合了训练模型的计算和输出的详细信息.计算由计算指标组成,用以判断训练模型的性能.输出将训练好的模型写入外部存储.</span></span><br><span class="line">eval_spec = EvalSpec(input_fn=<span class="keyword">lambda</span>: input_fn(eval_fp), throttle_secs=<span class="number">0</span>) <span class="comment"># 第一次评估发生在throttle_secs秒后</span></span><br><span class="line"><span class="comment"># 训练和评估</span></span><br><span class="line">train_and_evaluate(estimator, train_spec, eval_spec)</span><br></pre></td></tr></table></figure><h5 id="运行tensorboard可视化训练过程"><a href="#运行tensorboard可视化训练过程" class="headerlink" title="运行tensorboard可视化训练过程"></a>运行tensorboard可视化训练过程</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=law-model</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153921.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115153921.png" srcset="data:image/png;base64,666"></p><p> <img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115154036.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115154036.png" srcset="data:image/png;base64,666"></p><h3 id="案例四-互联网新闻情感分析"><a href="#案例四-互联网新闻情感分析" class="headerlink" title="案例四 互联网新闻情感分析"></a>案例四 互联网新闻情感分析</h3><h4 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h4><p>对新闻情绪进行分类，0代表正面情绪、1代表中性情绪、2代表负面情绪。</p><h4 id="数据说明-1"><a href="#数据说明-1" class="headerlink" title="数据说明"></a>数据说明</h4><table><thead><tr><th><strong>Field</strong></th><th><strong>Type</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td><strong>id</strong></td><td>String</td><td>新闻ID News ID</td></tr><tr><td><strong>text</strong></td><td>String</td><td>新闻正文内容 Content of news text</td></tr><tr><td><strong>label</strong></td><td>String</td><td>新闻情感标签 Emotional label in news</td></tr></tbody></table><h4 id="实现流程-1"><a href="#实现流程-1" class="headerlink" title="实现流程"></a>实现流程</h4><h5 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span>(<span class="params">filepath</span>):</span></span><br><span class="line">    dataset_list = []</span><br><span class="line">    f = open(filepath, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    r = csv.reader(f)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> r:</span><br><span class="line">        <span class="keyword">if</span> r.line_num == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        dataset_list.append(item)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 空元素补0</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> dataset_list:</span><br><span class="line">        <span class="keyword">if</span> item[<span class="number">1</span>].strip() == <span class="string">&#x27;&#x27;</span>:</span><br><span class="line">            item[<span class="number">1</span>] = <span class="string">&#x27;0&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset_list</span><br></pre></td></tr></table></figure><h5 id="网络类，全连接层"><a href="#网络类，全连接层" class="headerlink" title="网络类，全连接层"></a>网络类，全连接层</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># in_dim=768, out_dim=3</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, out_dim</span>):</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.linear1 = nn.Linear(in_dim, <span class="number">500</span>)</span><br><span class="line">        self.linear2 = nn.Linear(<span class="number">500</span>, <span class="number">400</span>)</span><br><span class="line">        self.linear3 = nn.Linear(<span class="number">400</span>, <span class="number">300</span>)</span><br><span class="line">        self.linear4 = nn.Linear(<span class="number">300</span>, <span class="number">200</span>)</span><br><span class="line">        self.linear5 = nn.Linear(<span class="number">200</span>, out_dim)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.linear1(x)</span><br><span class="line">        x = self.linear2(x)</span><br><span class="line">        x = self.linear3(x)</span><br><span class="line">        x = self.linear4(x)</span><br><span class="line">        x = self.linear5(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h5 id="计算每个batch的准确率"><a href="#计算每个batch的准确率" class="headerlink" title="计算每个batch的准确率"></a>计算每个batch的准确率</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span>  <span class="title">batch_accuracy</span>(<span class="params">pre, label</span>):</span></span><br><span class="line">    pre = pre.argmax(dim=<span class="number">1</span>)</span><br><span class="line">    correct = torch.eq(pre, label).sum().float().item()</span><br><span class="line">    accuracy = correct / float(len(label))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> accuracy</span><br></pre></td></tr></table></figure><h5 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(EPOCHS):</span><br><span class="line">    step = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> text, label <span class="keyword">in</span> train_loader:</span><br><span class="line">        <span class="comment"># tuple转list</span></span><br><span class="line">        text = list(text)</span><br><span class="line">        label = list(label)</span><br><span class="line">        label = list(map(int, label))</span><br><span class="line">        <span class="comment"># 使用中文bert，生成句向量</span></span><br><span class="line">        sen_vec = bertclient.encode(text)</span><br><span class="line">        sen_vec = torch.tensor(sen_vec)</span><br><span class="line">        label = torch.LongTensor(label)</span><br><span class="line">        label = label.cuda()</span><br><span class="line">        <span class="comment"># 输入到网络中，反向传播</span></span><br><span class="line">        pre = net(sen_vec).cuda()</span><br><span class="line">        loss = criterion(pre, label)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># 更新loss曲线，并计算准确率</span></span><br><span class="line">        step = step + <span class="number">1</span></span><br><span class="line">        flag = flag + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            acc = batch_accuracy(pre, label)</span><br><span class="line">            print(<span class="string">&#x27;epoch:&#123;&#125; | batch:&#123;&#125; | acc:&#123;&#125; | loss:&#123;&#125;&#x27;</span>.format(epoch, step, acc, loss.item()))</span><br></pre></td></tr></table></figure><h5 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">net.load_state_dict(torch.load(<span class="string">&#x27;net.pt&#x27;</span>))</span><br><span class="line"></span><br><span class="line">test_result = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> test_dataset:</span><br><span class="line"></span><br><span class="line">    sen_vec = bertclient.encode([item[<span class="number">1</span>]])</span><br><span class="line">    sen_vec = torch.tensor(sen_vec)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        pre = net(sen_vec).cuda()</span><br><span class="line">        pre = pre.argmax(dim=<span class="number">1</span>)</span><br><span class="line">        pre = pre.item()</span><br><span class="line">        test_result.append([item[<span class="number">0</span>], pre])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 写入csv文件</span></span><br><span class="line">        df = pd.DataFrame(test_result)</span><br><span class="line">        df.to_csv(<span class="string">&#x27;test_result.csv&#x27;</span>,index=<span class="literal">False</span>, header=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;label&#x27;</span>])</span><br></pre></td></tr></table></figure><h5 id="训练可视化"><a href="#训练可视化" class="headerlink" title="训练可视化"></a>训练可视化</h5><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115154120.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115154120.png" srcset="data:image/png;base64,666"></p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115154146.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115154146.png" srcset="data:image/png;base64,666"></p><p><img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115154159.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115154159.png" srcset="data:image/png;base64,666"></p><h5 id="控制台输出"><a href="#控制台输出" class="headerlink" title="控制台输出"></a>控制台输出</h5><p> <img src="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115154221.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/MHuiG/imgbed/data/2020115154221.png" srcset="data:image/png;base64,666"></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://zhuanlan.zhihu.com/p/49271699">从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史</a></p><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://www.jianshu.com/p/e7d8caa13b21">Transformer</a></p><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://zhuanlan.zhihu.com/p/37601161">深度学习中的注意力模型</a></p><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/google-research/bert">谷歌的bert</a></p><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/hanxiao/bert-as-service">肖涵博士的bert-as-service</a></p><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://hanxiao.io/2019/01/02/Serving-Google-BERT-in-Production-using-Tensorflow-and-ZeroMQ/">Serving-Google-BERT-in-Production-using-Tensorflow-and-ZeroMQ</a></p><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/thunlp/CAIL">CAIL2018数据集</a></p><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/thunlp/OpenCLaP">刑事文书BERT:</a></p><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://zhuanlan.zhihu.com/p/115802478">tensorboard使用详解</a></p><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://www.cnblogs.com/fanghao/p/10256287.html">Visdom可视化工具</a></p><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://www.datafountain.cn/competitions/350">互联网新闻情感分析</a></p><div class="footer"><div class="copyright"><blockquote><p>博客内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</p><p>本文永久链接是：<a href="https://mhuig.github.io/posts/48f700eb.html">https://mhuig.github.io/posts/48f700eb.html</a></p></blockquote></div></div><div class="article-meta" id="bottom"><div class="new-meta-box"><div class="new-meta-item date" itemprop="dateUpdated" datetime="2020-11-05T15:47:27+08:00"><a class="notlink"><i class="fad fa-edit fa-fw" aria-hidden="true"></i><p>更新于：2020年11月5日</p></a></div><div class="new-meta-item browse valine"><a class="notlink"><i class="fad fa-eye fa-fw" aria-hidden="true"></i><span id="/posts/48f700eb.html" class="leancloud_visitors" data-flag-title="BERT预训练模型及其应用案例"><p><span class="leancloud-visitors-count"></span></p></span></a></div><div class="new-meta-item meta-tags"><a class="tag" href="/tags/nlp/" rel="nofollow"><i class="fad fa-hashtag fa-fw" aria-hidden="true"></i><p>NLP</p></a></div></div></div><div class="prev-next"><a class="prev" href="/posts/92a4ae9.html"><p class="title"><i class="fad fa-chevron-left" aria-hidden="true"></i>宇宙的本质是计算</p><p class="content">想象一下，一望无际的大平面被分成了许许多多方格子。每个格子里正好能放下一个“细胞”。这个细胞不能运动，它可以是死的，也可以是活的；但它的状态，是由它周围8个细胞的死活决定。 规则至于决定的规...</p></a><a class="next" href="/posts/618ec98d.html"><p class="title">自然语言处理研究报告[存档备用]<i class="fad fa-chevron-right" aria-hidden="true"></i></p><p class="content"> NLP</p></a></div></article><article class="post white-box reveal shadow floatable blur" id="comments"><p ct><i class="fad fa-comments"></i> 评论</p><div id="minivaline_container"><i class="fad fa-cog fa-spin fa-fw fa-2x"></i></div></article></div><aside class="l_side"><section class="widget toc-wrapper shadow floatable blur desktop mobile" id="toc-div"><header><i class="fad fa-list fa-fw" aria-hidden="true"></i> <span class="name">本文目录</span></header><div class="content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E9%A2%86%E5%9F%9F%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83"><span class="toc-text">图像领域的预训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Word-Embedding"><span class="toc-text">Word Embedding</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-text">语言模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-text">神经网络语言模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Word2Vec"><span class="toc-text">Word2Vec</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Word-Embedding%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-text">Word Embedding的使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Word-Embedding%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">Word Embedding的问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8EWord-Embedding%E5%88%B0ELMO"><span class="toc-text">从Word Embedding到ELMO</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8EWord-Embedding%E5%88%B0GPT"><span class="toc-text">从Word Embedding到GPT</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Transformer"><span class="toc-text">Transformer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%A8%A1%E5%9E%8B"><span class="toc-text">自注意力机制模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GPT%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8"><span class="toc-text">GPT如何使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8EGPT%E5%92%8CELMO%E5%8F%8Aword2Vec%E5%88%B0Bert"><span class="toc-text">从GPT和ELMO及word2Vec到Bert</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NLP%E7%9A%84%E5%9B%9B%E5%A4%A7%E4%BB%BB%E5%8A%A1"><span class="toc-text">NLP的四大任务</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BERT%E7%9A%84%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B"><span class="toc-text">BERT的应用案例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BDbert%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-text">下载bert预训练模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85bert-as-service"><span class="toc-text">安装bert-as-service</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E4%B8%80-%E6%9F%A5%E6%89%BE%E6%9C%80%E7%9B%B8%E8%BF%91%E7%9A%84%E5%8F%A5%E5%AD%90"><span class="toc-text">案例一 查找最相近的句子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E4%BA%8C-%E7%AE%80%E5%8D%95%E6%A8%A1%E7%B3%8A%E6%90%9C%E7%B4%A2"><span class="toc-text">案例二 简单模糊搜索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E4%B8%89-%E6%B3%95%E6%9D%A1%E6%8E%A8%E8%8D%90"><span class="toc-text">案例三 法条推荐</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AF%B4%E6%98%8E"><span class="toc-text">数据说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E6%B5%81%E7%A8%8B"><span class="toc-text">实现流程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%BF%9E%E6%8E%A5%E5%88%B0BertServer%E7%9A%84BertClient"><span class="toc-text">创建一个连接到BertServer的BertClient</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E7%BC%96%E7%A0%81%E5%90%91%E9%87%8F%E5%92%8C%E6%A0%87%E7%AD%BE"><span class="toc-text">获取编码向量和标签</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9E%84%E5%BB%BATensorFlow-DNN-%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-text">构建TensorFlow DNN 模型的分类器</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E5%92%8C%E8%AF%84%E4%BC%B0"><span class="toc-text">训练和评估</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BF%90%E8%A1%8Ctensorboard%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="toc-text">运行tensorboard可视化训练过程</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E5%9B%9B-%E4%BA%92%E8%81%94%E7%BD%91%E6%96%B0%E9%97%BB%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90"><span class="toc-text">案例四 互联网新闻情感分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D-1"><span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AF%B4%E6%98%8E-1"><span class="toc-text">数据说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E6%B5%81%E7%A8%8B-1"><span class="toc-text">实现流程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">加载数据集</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%B1%BB%EF%BC%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82"><span class="toc-text">网络类，全连接层</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%AF%8F%E4%B8%AAbatch%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87"><span class="toc-text">计算每个batch的准确率</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-text">训练</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95"><span class="toc-text">测试</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-text">训练可视化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8E%A7%E5%88%B6%E5%8F%B0%E8%BE%93%E5%87%BA"><span class="toc-text">控制台输出</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-text">参考文献</span></a></li></ol></div></section></aside><script>window.pdata={},pdata.ispage=!0,pdata.postTitle="BERT预训练模型及其应用案例",pdata.commentPath="",pdata.commentPlaceholder="";var l_header=document.getElementById("l_header");l_header.classList.add("show")</script></div><footer class="footer clearfix"><br><br><div class="aplayer-container"><meting-js theme="#1BCDFC" volume="0.7" loop="all" order="list" fixed="false" list-max-height="320px" server="netease" type="song" id="412785957" list-folded="true"></meting-js></div><br><div class="social-wrapper"><a href="/atom.xml" class="social fad fa-rss flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a><a href="mailto:mhuig1998@gmail.com" class="social fad fa-envelope flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a><a href="https://github.com/MHuiG" class="social fab fa-github flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a><a href="https://music.163.com/#/user/home?id=63035382" class="social fad fa-headphones-alt flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a></div><div><p>博客内容遵循 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p></div><div class="copyright"><p><a href="https://icp.gov.moe" target="_blank" rel="external nofollow noopener noreferrer">萌ICP备</a> <a href="https://icp.gov.moe/?keyword=2020012138" target="_blank" rel="external nofollow noopener noreferrer">2020012138号</a><br><a href="https://mhuig.github.io/">Copyright © 2018-2020 MHuiG</a></p></div></footer><a id="s-top" class="fad fa-arrow-up fa-fw" href="javascript:void(0)"></a></div></div><div><script src="/js/jquery.js" defer="defer"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script></div></body></html>